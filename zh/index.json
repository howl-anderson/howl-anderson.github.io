[{"content":"TL:DR OpenAI çš„ ChatGPT åœ¨å…¶å®˜æ–¹æ–‡æ¡£ï¼ˆhttps://platform.openai.com/docs/api-reference/chat/createï¼‰ä¸­ç»™å‡ºäº†å„ç§å‚æ•°çš„èŒƒå›´å’Œå«ä¹‰ã€‚æˆ‘ä»¬å°†è®¨è®º ChatGPT çš„ç”Ÿæˆè¿‡ç¨‹å’Œè¿™äº›å‚æ•°æ˜¯å¦‚ä½•å®ç°å…¶ç”Ÿæˆçš„æ•ˆæœçš„ã€‚\nChatGPT çš„è§£ç è¿‡ç¨‹ æˆ‘ä»¬å‡è®¾ minGPT ï¼ˆç­‰åŒäº GPT-2ï¼‰ å’Œ ChatGPT æ‹¥æœ‰ä¸€æ ·çš„è§£ç è¿‡ç¨‹ï¼šhttps://github.com/karpathy/minGPT/blob/master/mingpt/model.py#LL283C12-L283C12 ã€‚\næ€»ä½“è¿‡ç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š\nå°†ç”¨æˆ·çš„è¯·æ±‚ï¼Œä» 1 ä¸ªæ‰©å……æˆ num_samples å¤§å°çš„ batch è¿›è¡Œæ¨¡å‹æ¨ç†ï¼Œå¾—åˆ° logits è¿›è¡Œ temperature æ˜ å°„ï¼šlogits = logits / temperature [å¯é€‰] è¿›è¡Œ topk å¤„ç†ï¼šlogits = topk_func(logits, top_k) logits åˆ° æ¦‚ç‡çš„è½¬æ¢ï¼šprobs = softmax(logits) æ˜¯å¦ sampleï¼š è¿›è¡Œ sampleï¼šidx_next = multinomial_sample(probs, num_samples=1) ä¸è¿›è¡Œ sampleï¼šidx_next = topk_func(probs, k=1) é‡å¤ä¸Šè¿°è¿‡ç¨‹ max_new_tokens æ¬¡ ChatGPT çš„è§£ç å‚æ•° temperature temperature å‚æ•°çš„å®˜æ–¹å®šä¹‰å¦‚ä¸‹ï¼š\ntemperature number Optional Defaults toÂ 1\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this orÂ top_pÂ but not both.\nè¿™ä¸€éƒ¨åˆ†å¯¹åº”ç€è§£ç è¿‡ç¨‹çš„æ­¥éª¤ 3.\nä¸‹é¢æˆ‘ä»¬å°†ç»“åˆæ¨¡å‹è§£ç è¿‡ç¨‹ï¼Œä½¿ç”¨æ•°æ®ç¤ºä¾‹æ¥æ¼”ç¤ºå…¶æ•ˆæœï¼ˆä¸ºäº†ç®€åŒ–é€»è¾‘è¿‡ç¨‹ï¼Œæˆ‘ä»¬ä¸è¿›è¡Œ topk å¤„ç†ï¼‰ï¼š\nå‡è®¾æŸä¸ªæ¨¡å‹çš„ vocabulary çš„å¤§å°ä¸º 2ï¼Œåœ¨æŸä¸ªæ—¶åˆ»ï¼Œæ¨¡å‹çš„è¾“å‡ºä¸º logits = [0.8, 0.2]ã€‚ å¦‚æœä¸è¿›è¡Œ temperature æ˜ å°„ï¼ˆç­‰ä»·äºå°† temperature è®¾ç½®ä¸º 1ï¼Œ ä¹Ÿå°±æ˜¯é»˜è®¤å€¼ï¼‰ï¼š æ¦‚ç‡è½¬æ¢ï¼šprobs = softmax(logits) = [0.65, 0.35] å¦‚æœ temperature è®¾ç½®ä¸º 1.8ï¼Œé‚£ä¹ˆ logits = logits / temperature = [0.44, 0.11], ä¸‹ä¸€æ­¥è¿›è¡Œæ¦‚ç‡è½¬æ¢ï¼šprobs = softmax(logits) = [0.58, 0.42] å¦‚æœ temperature è®¾ç½®ä¸º 0.2ï¼Œé‚£ä¹ˆ logits = logits / temperature = [4, 1], ä¸‹ä¸€æ­¥è¿›è¡Œæ¦‚ç‡è½¬æ¢ï¼šprobs = softmax(logits) = [0.95, 0.05] æ€»ç»“ï¼šä»ä¸Šé¢çš„æ•°æ®å¯ä»¥çœ‹å‡ºï¼Œtemperature è¶Šå¤§ï¼Œlogits æ•°å€¼ä¸åŒçš„ token ç»è¿‡æ˜ å°„åå…¶æ¦‚ç‡å·®å¼‚è¶Šå°ï¼Œä»è€Œåœ¨åç»­çš„ sample éƒ¨åˆ†è¢« sample çš„æ¦‚ç‡å·®å¼‚è¶Šå°ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œtemperature è¶Šå¤§ï¼Œæ¨¡å‹ç”Ÿæˆçš„ç»“æœè¶Šéšæœºã€‚åä¹‹äº¦ç„¶ã€‚\nå€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒGPT æ¨¡å‹çš„ temperature å–å€¼èŒƒå›´æ˜¯ 0ï¼ˆåŒ…å«ï¼‰ åˆ° 2ï¼ˆåŒ…å«ï¼‰ã€‚ä½†æ˜¯ temperature=0ï¼Œè¿™ä¸ªåœ¨æ•°å€¼ä¸Šæ˜¯æ— æ³•ä½œä¸ºè¢«é™¤æ•°çš„ï¼ŒChatGPT å¿…ç„¶é‡‡ç”¨äº†æŸç§ trick æˆ–è€…å˜æ¢ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚\næˆ‘ä»¬ç”»ä¸€å¼ å›¾ç”¨æ¥æ¼”ç¤ºï¼Œä¸åŒ temperature åœ¨ä¸åŒ logits ä¸Šçš„è¡¨ç°ï¼š\n# importing package import matplotlib.pyplot as plt import numpy as np import math # x axis index and values data = list(enumerate(zip(np.arange(0.1, 0.6, 0.1), np.arange(0.9, 0.4, -0.1)))) # colors for each temperature, from low to high temperature, from yellow to dark red # reference: https://colorbrewer2.org/#type=sequential\u0026amp;scheme=YlOrRd\u0026amp;n=5 colors = [\u0026#34;#ffffb2\u0026#34;, \u0026#34;#fecc5c\u0026#34;, \u0026#34;#fd8d3c\u0026#34;, \u0026#34;#f03b20\u0026#34;, \u0026#34;#bd0026\u0026#34;] for t_idx, temperature in enumerate(np.arange(0.4, 1.6 + 0.0001, 0.3)): # each line for each temperature # get x and y values x = [] y = [] for x_idx, (a, b) in data: logits = np.array([a, b]) probs = softmax(logits / temperature) x.append(x_idx) y.append(probs[1] / probs[0]) # max prob / min prob # plot circle_color = colors[t_idx] if math.isclose(temperature, 1.0): # plot the line for temperature 1.0 with black circles plt.scatter(x, y, label=f\u0026#34;{temperature:.1f}\u0026#34;, facecolors=\u0026#34;black\u0026#34;, edgecolors=\u0026#34;black\u0026#34;) else: # other lines with colorful lines plt.scatter(x, y, label=f\u0026#34;{temperature:.1f}\u0026#34;, facecolors=circle_color, edgecolors=\u0026#34;gray\u0026#34;) plt.legend() # set x and y axis plt.xlabel(\u0026#39;logits\u0026#39;) plt.xticks([x for x, _ in data], [f\u0026#34;[{a:.1f}, {b:.1f}]\u0026#34; for _, (a, b) in data]) plt.ylabel(\u0026#39;ratio of max/min prob\u0026#39;) plt.show() å°†ä¼šè¾“å‡ºå¦‚ä¸‹çš„å›¾ï¼š\nåœ¨ä¸Šå›¾ä¸­ï¼Œæ¨ªåæ ‡ä¸º logitsï¼ˆç”±ä¸¤ä¸ªç±»åˆ«æ„æˆï¼‰ï¼Œçºµåæ ‡ä¸º max prob / min probï¼Œä¹Ÿå°±æ˜¯æ¦‚ç‡æœ€å¤§çš„ token çš„æ¦‚ç‡ä¸æ¦‚ç‡æœ€å°çš„ token çš„æ¦‚ç‡çš„æ¯”å€¼ï¼Œè¿™ä¸ªæ¯”å€¼å¯ä»¥ç”¨äºè¡¡é‡å·®å¼‚çš„å¤§å°ã€‚\nåœ¨æ²¡æœ‰å¼•å…¥ temperature æ—¶ï¼Œæ¦‚ç‡çš„æ¯”å€¼å’Œ logits å­˜åœ¨ä¸¥æ ¼ç›¸å…³çš„ï¼Œlogits çš„å€¼é€šè¿‡ softmax å‡½æ•°å¯ä»¥æ˜ å°„å¾—åˆ°æ¦‚ç‡å€¼ã€‚åœ¨ä¸Šå›¾ä¸­ï¼Œtemperature = 0 çš„æƒ…å†µï¼Œç­‰ä»·äºæ²¡æœ‰å¼•å…¥ temperature çš„æƒ…å†µï¼Œåœ¨å›¾ä¸­ä½¿ç”¨ç©ºå¿ƒåœ†åœˆ â—¯ è¡¨ç¤ºã€‚ã€‚\né€šè¿‡è§‚å¯Ÿï¼Œå¯çŸ¥æ— è®ºæˆ‘ä»¬é€‰æ‹©å“ªä¸€ä¸ª logitsï¼Œæˆ‘ä»¬éƒ½å¯ä»¥çœ‹åˆ°ï¼štemperature è¶Šå¤§ï¼Œæ¦‚ç‡ä¹‹é—´çš„å·®å¼‚ï¼ˆä¹Ÿå°±æ˜¯ max prob / min prob æ¯”å€¼ï¼‰è¶Šå°ï¼Œä¹Ÿå°±æ˜¯æ¦‚ç‡å·®å¼‚è¶Šå°ã€‚åä¹‹äº¦ç„¶ã€‚å› æ­¤ï¼Œå¯ä»¥å¾—å‡ºç»“è®ºï¼štemperature è¶Šå¤§ï¼Œæ¨¡å‹ç”Ÿæˆçš„ç»“æœè¶Šéšæœºï¼Œtemperature è¶Šå°ï¼Œæ¨¡å‹ç”Ÿæˆçš„ç»“æœè¶Šç¡®å®šã€‚\ntop_p top_p å‚æ•°çš„å®˜æ–¹å®šä¹‰å¦‚ä¸‹ï¼š\ntop_p number Optional Defaults toÂ 1\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\nWe generally recommend altering this orÂ temperatureÂ but not both.\nè¿™ä¸€éƒ¨åˆ†å¯¹åº”ç€è§£ç è¿‡ç¨‹çš„æ­¥éª¤ 4.\nä¸ minGPT ä¸åŒçš„æ˜¯ï¼ŒminGPT ä½¿ç”¨ç»å¯¹å€¼ï¼ˆtop_nï¼‰æ¥è¿›è¡Œé€‰æ‹©ï¼Œè€Œ OpenAI GPT ä½¿ç”¨ç™¾åˆ†æ¯”ï¼ˆtop_pï¼‰ã€‚\nè¿™ä¸€éƒ¨åˆ†ä¼šå°†ä¸åˆæ ¼ï¼ˆæ¯”åœ¨ top_n ä»¥å†…çš„ï¼Œæˆ–è€… top_p æ¯”ä¾‹ä»¥å¤–çš„ï¼‰çš„ token æ¸…ç†æ‰ï¼Œé€šè¿‡å°†å…¶ logits å€¼è®¾ç½®ä¸º float(\u0026lsquo;Inf\u0026rsquo;) æ¥å®ç°ã€‚\nstop stop å‚æ•°çš„å®˜æ–¹å®šä¹‰å¦‚ä¸‹ï¼š\nstop string or array Optional Defaults toÂ null\nUp to 4 sequences where the API will stop generating further tokens.\nè¿™ä¸€éƒ¨åˆ†åœ¨ MinGPT ä¸­æ²¡æœ‰å¯¹åº”çš„æ­¥éª¤ã€‚ è¿™ä¸€éƒ¨åˆ†æ‰€è¦è¡¨è¾¾çš„å«ä¹‰ä¹Ÿæ˜¯æ¸…æ™°æ˜äº†ï¼Œåœ¨ç›‘æµ‹åˆ°è¾“å‡ºä¸­å­˜åœ¨æŸäº›å®šä¹‰çš„å­—ç¬¦ä¸²åï¼Œå°†ä¼šåœæ­¢ç”Ÿæˆã€‚è¿™ä¸€ç‰¹æ€§å¯èƒ½åœ¨æœ‰äº›è½¯ä»¶ä¸­å¾—åˆ°äº†åº”ç”¨ã€‚æ¯”å¦‚ https://github.com/microsoft/guidance ä¸­çš„ {{gen 'rewrite' stop=\u0026quot;\\\\n-\u0026quot;}}\nn n å‚æ•°çš„å®˜æ–¹å®šä¹‰å¦‚ä¸‹ï¼š\nn integer Optional Defaults to 1\nHow many chat completion choices to generate for each input message.\nè¿™ä¸€éƒ¨åˆ†å¯¹åº”ç€è§£ç è¿‡ç¨‹çš„æ­¥éª¤1ã€‚\nç”±äºå¤§å°ä¸º n çš„ batch ä¸­æ¯ä¸€ä¸ªæ–‡æœ¬éƒ½æ˜¯ç‹¬ç«‹é‡‡æ ·çš„ï¼Œå› æ­¤åœ¨åŒä¸€ä½ç½®å¯èƒ½ä¼šé€‰æ‹©ä¸åŒçš„ tokenï¼Œè¿™äº›æ–‡æœ¬ä¸Šçš„å˜å¼‚éšç€ä½ç½®çš„ä¸æ–­å»¶ä¼¸è€Œè¿›ä¸€æ­¥æ‰©å¤§ï¼Œæœ€ç»ˆç”Ÿæˆäº†ä¸åŒçš„æ–‡æœ¬ã€‚å½“ç„¶äº†ï¼Œä¹Ÿæœ‰ä¸€å®šæ¦‚ç‡ç”Ÿæˆå®Œå…¨ä¸€æ ·çš„æ–‡æœ¬ã€‚\nmax_tokens max_tokens å‚æ•°çš„å®˜æ–¹å®šä¹‰å¦‚ä¸‹ï¼š\nmax_tokens integer Optional Defaults toÂ inf\nThe maximum number ofÂ tokensÂ to generate in the chat completion.\nThe total length of input tokens and generated tokens is limited by the model\u0026rsquo;s context length.\nè¿™ä¸€éƒ¨åˆ†å¯¹åº”ç€è§£ç è¿‡ç¨‹ä¸­çš„æ­¥éª¤7.\nè¿™ä¸€éƒ¨åˆ†å†³å®šäº†è§£ç çš„æœ€é«˜è¿è¡Œæ¬¡æ•°ã€‚åœ¨ minGPT ä¸­ï¼Œè¿™ä¸€è§£ç æ¬¡æ•°æ˜¯ç¡®å®šçš„ï¼Œæ¨¡å‹ä¸€å®šä¼šç”Ÿæˆ max_tokens ä¸ª tokenã€‚è€Œåœ¨ OpenAI GPT ä¸­åˆ™ä¸ä¸€å®šäº†ï¼Œæœ‰å‡ ä¸ªå› ç´ ï¼š\nstop å‚æ•°çš„è®¾ç½®ï¼Œè¯¦æƒ…è¯·è§ä¸Šæ–‡ã€‚ å¯èƒ½çš„ç‰¹æ®Šçš„ä¼‘æ­¢ç¬¦ tokenã€‚é€šè¿‡å®é™…ä½¿ç”¨ ChatGPTï¼Œå¯ä»¥å‘ç° ChatGPT å¹¶ä¸ä¼šæœºæ¢°çš„è¾“å‡ºæŒ‡å®šçš„æ–‡æœ¬é•¿åº¦ï¼Œåœ¨å……åˆ†å›ç­”é—®é¢˜åï¼Œå°±ä¼šè‡ªè¡Œåœæ­¢ã€‚ å®éªŒä»£ç å¦‚ä¸‹ï¼š import openai openai.api_key = \u0026#34;sk-xxx\u0026#34; completion = openai.ChatCompletion.create( model=\u0026#34;gpt-4\u0026#34;, messages=[{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;ä½ å¸®æˆ‘è¾“å‡º1åˆ°10ä¹‹é—´çš„å¶æ•°ï¼Œè¾“å‡ºæ—¶ï¼Œæ¯ä¸ªæ•°å­—ä¹‹é—´ç”¨ä¸€ä¸ªç©ºæ ¼éš”å¼€ã€‚é™¤äº†æ•°å­—ï¼Œå…¶ä»–çš„éƒ½ä¸è¦è¾“å‡ºã€‚\u0026#34;}], temperature=0, max_tokens=100, ) response = completion.choices[0].message[\u0026#34;content\u0026#34;] print(\u0026#34;length: \u0026#34;, len(response)) # å°†ä¼šè¾“å‡ºï¼šlength: 10 print(response) # å°†ä¼šè¾“å‡ºï¼š2 4 6 8 10 presence_penalty presence_penalty å‚æ•°çš„å®˜æ–¹å®šä¹‰å¦‚ä¸‹ï¼š\nfrequency_penalty number Optional Defaults to 0\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model\u0026rsquo;s likelihood to repeat the same line verbatim.\nè¿™ä¸€éƒ¨åˆ†åœ¨ MinGPT ä¸­æ²¡æœ‰å¯¹åº”çš„æ­¥éª¤ã€‚\nè¿™ä¸€éƒ¨åˆ†çš„è¯¦å°½è§£é‡Šåœ¨ https://platform.openai.com/docs/api-reference/parameter-details ä¸­æœ‰æåŠã€‚\nå…·ä½“æ¥è¯´ï¼Œå°±æ˜¯åœ¨è§£ç çš„æŸä¸ªæ—¶åˆ»ï¼Œtoken j çš„ logit å€¼ä¸º mu[j] ï¼Œc[j] è¡¨ç¤ºåœ¨å½“å‰å·²ç»ç”Ÿæˆçš„æ–‡æœ¬ä¸­ï¼Œå‡ºç°è¿‡å¤šå°‘ä¸ª j è¿™ä¸ª tokenã€‚c[j] \u0026gt; 0 è¿™ä¸ªè¡¨è¾¾å¼çš„å€¼åªèƒ½ä¸º1ï¼ˆä¹‹å‰ j å‡ºç°è¿‡è‡³å°‘ä¸€æ¬¡ï¼‰æˆ–è€…0ï¼ˆæ²¡æœ‰å‡ºç°è¿‡ï¼‰ã€‚åœ¨ OpenAI çš„è§£é‡Šä¸­ï¼Œå®ƒä½¿ç”¨äº† alpha_presence æ¥æŒ‡ä»£ presence_penaltyï¼Œä¸¤è€…å®Œå…¨æ˜¯åŒä¸€äº‹ç‰©çš„ä¸åŒç¬¦å·è€Œå·²ã€‚ä¸ºäº†ä¿æŒå’Œæ–‡æ¡£ä¸€è‡´ï¼Œè¿™é‡Œéƒ½ä½¿ç”¨æ–‡æ¡£ä¸­çš„ç¬¦å·ã€‚åœ¨åŠ å…¥ presence_penalty æœºåˆ¶åï¼Œå…¶å€¼ä¿®è®¢ä¸º mu[j] - float(c[j] \u0026gt; 0) * alpha_presence ã€‚è¿™å°±æ„å‘³ç€åœ¨ alpha_presence ä¸ºæ­£çš„æƒ…å†µä¸‹ï¼Œj è¿™ä¸ª token çš„ logit ä¼šå› ä¸ºä¹‹å‰æ–‡æœ¬ä¸­ç”Ÿæˆè¿‡ j è€Œæœ‰æ‰€é™ä½ã€‚logit çš„é™ä½ä¹Ÿæ„å‘³ç€è¢« sample çš„æ¦‚ç‡é™ä½ã€‚å› æ­¤é€šè¿‡æä¾›æ­£å€¼ presence_penaltyï¼Œå°±ä¼šä½¿æ¨¡å‹ç”Ÿæˆé‡å¤ token çš„æ¦‚ç‡é™ä½ï¼Œæ¢è¨€ä¹‹ï¼Œè¿›è¡Œäº†æƒ©ç½šã€‚å¦‚æœ alpha_presence ä¸ºè´Ÿå€¼ï¼Œé‚£ä¹ˆåŒç†å¯å¾—ï¼Œä¼šå¯¹æ¨¡å‹ç”Ÿæˆé‡å¤ token çš„è¡Œä¸ºè¿›è¡Œå¥–åŠ±ã€‚\npresence_penalty åå­—ä¸­è™½ç„¶å¸¦ç€ penaltyï¼Œä½†ç”±äºå…¶å–å€¼èŒƒå›´å¯èƒ½æ˜¯æ­£æ•°ä¹Ÿå¯èƒ½æ˜¯è´Ÿæ•°ï¼Œå› æ­¤å¹¶ä¸ä¸€å®šæ˜¯æƒ©ç½š token çš„åå¤å‡ºç°ï¼Œä¹Ÿæœ‰å¯èƒ½æ˜¯é¼“åŠ±åå¤å‡ºç°ã€‚\nfrequency_penalty frequency_penalty å‚æ•°çš„å®˜æ–¹å®šä¹‰å¦‚ä¸‹ï¼š\nfrequency_penalty number Optional Defaults to 0\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model\u0026rsquo;s likelihood to repeat the same line verbatim.\nè¿™ä¸€éƒ¨åˆ†åœ¨ MinGPT ä¸­æ²¡æœ‰å¯¹åº”çš„æ­¥éª¤ã€‚\nè¿™ä¸ªå‚æ•°å’Œ presence_penalty é«˜åº¦ç›¸ä¼¼ã€‚åŒæ ·åœ¨ https://platform.openai.com/docs/api-reference/parameter-details ä¸­æœ‰è¯¦ç»†çš„è§£é‡Šã€‚\nå…·ä½“æ¥è¯´ï¼Œtoken j çš„ logit å€¼ä¸º mu[j] ï¼Œåœ¨åŠ å…¥ frequency_penalty ä¼šä¿®è®¢æˆ mu[j] -\u0026gt; mu[j] - c[j] * alpha_frequency ã€‚å…¶ä¸­ c[j] æ˜¯å½“å‰å·²ç»ç”Ÿæˆçš„æ–‡æœ¬ä¸­ï¼Œå‡ºç°è¿‡å¤šå°‘ä¸ª j è¿™ä¸ª tokenã€‚è€Œ alpha_frequency å°±æ˜¯ frequency_penalty ã€‚è¿™å°±æ„å‘³ç€åœ¨ frequency_penalty ä¸ºæ­£çš„æƒ…å†µä¸‹ï¼Œj è¿™ä¸ª token çš„ logit ä¼šå› ä¸ºä¹‹å‰æ–‡æœ¬ä¸­ç”Ÿæˆè¿‡ j è€Œæœ‰æ‰€é™ä½ï¼Œè€Œä¸”ä¹‹å‰ç”Ÿæˆè¿‡çš„ j è¶Šå¤šï¼ˆä¹Ÿå°±æ˜¯c[j] æ•°å€¼è¶Šå¤§ï¼‰ï¼Œæƒ©ç½šè¶Šä¸¥é‡ã€‚è¿™é‡Œå¯ä»¥çœ‹å‡º frequency_penalty å’Œ presence_penalty çš„ä¸åŒç‚¹åœ¨äº frequency_penalty çš„æƒ©ç½šä¼šéšç€ token å‡ºç°çš„æ¬¡æ•°å¢åŠ è€Œä¸æ–­åŠ å¼ºï¼Œè€Œ presence_penalty åˆ™åªä¼šåŒºåˆ†æ˜¯å¦å‡ºç°ï¼Œè¿™æ ·çš„åŒºåˆ«å……åˆ†ä½“ç°åœ¨äº†å…¶åå­—å·®å¼‚ä¸Šï¼šfrequency å’Œ presenceã€‚\nå’Œ presence ç±»ä¼¼ï¼Œfrequency_penalty çš„å–å€¼å¯æ­£å¯è´Ÿï¼Œä»è€Œå®ç°æƒ©ç½šæˆ–è€…å¥–åŠ±åå¤å‡ºç°çš„ tokenã€‚\nlogit_bias logit_bias å‚æ•°çš„å®˜æ–¹å®šä¹‰å¦‚ä¸‹ï¼š\nlogit_bias map Optional Defaults to null\nModify the likelihood of specified tokens appearing in the completion.\nAccepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.\nè¿™ä¸€éƒ¨åˆ†åœ¨ MinGPT ä¸­æ²¡æœ‰å¯¹åº”çš„æ­¥éª¤ã€‚\nè¿™ä¸€å‚æ•°ç”¨äºæ— æ¡ä»¶çš„ä¿®æ”¹æŸä¸ªæˆ–è€…å¤šä¸ª token çš„ logitï¼Œä»è€Œå¢åŠ æˆ–è€…å‡å°‘å…¶å‡ºç°çš„å¯èƒ½æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºå˜é‡ token j ï¼Œå…¶ logit å€¼ä¸º mu[j] ï¼Œé‚£ä¹ˆåœ¨ä½¿ç”¨ logit_bias åï¼Œå…¶å€¼å°†ä¼šè¢«ä¿®æ”¹æˆï¼šmu[j] -\u0026gt; mu[j] + logit_bias[j] .\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/the-decoding-process-of-chatgpt-and-the-various-parameters-in-it/","summary":"TL:DR OpenAI çš„ ChatGPT åœ¨å…¶å®˜æ–¹æ–‡æ¡£ï¼ˆhttps://platform.openai.com/docs/api-reference/chat/createï¼‰ä¸­ç»™å‡ºäº†å„ç§å‚æ•°çš„èŒƒå›´å’Œå«ä¹‰ã€‚æˆ‘ä»¬å°†è®¨è®º ChatGPT çš„ç”Ÿæˆè¿‡ç¨‹å’Œè¿™äº›å‚æ•°æ˜¯å¦‚ä½•å®ç°å…¶ç”Ÿæˆçš„æ•ˆæœçš„ã€‚\nChatGPT çš„è§£ç è¿‡ç¨‹ æˆ‘ä»¬å‡è®¾ minGPT ï¼ˆç­‰åŒäº GPT-2ï¼‰ å’Œ ChatGPT æ‹¥æœ‰ä¸€æ ·çš„è§£ç è¿‡ç¨‹ï¼šhttps://github.com/karpathy/minGPT/blob/master/mingpt/model.py#LL283C12-L283C12 ã€‚\næ€»ä½“è¿‡ç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š\nå°†ç”¨æˆ·çš„è¯·æ±‚ï¼Œä» 1 ä¸ªæ‰©å……æˆ num_samples å¤§å°çš„ batch è¿›è¡Œæ¨¡å‹æ¨ç†ï¼Œå¾—åˆ° logits è¿›è¡Œ temperature æ˜ å°„ï¼šlogits = logits / temperature [å¯é€‰] è¿›è¡Œ topk å¤„ç†ï¼šlogits = topk_func(logits, top_k) logits åˆ° æ¦‚ç‡çš„è½¬æ¢ï¼šprobs = softmax(logits) æ˜¯å¦ sampleï¼š è¿›è¡Œ sampleï¼šidx_next = multinomial_sample(probs, num_samples=1) ä¸è¿›è¡Œ sampleï¼šidx_next = topk_func(probs, k=1) é‡å¤ä¸Šè¿°è¿‡ç¨‹ max_new_tokens æ¬¡ ChatGPT çš„è§£ç å‚æ•° temperature temperature å‚æ•°çš„å®˜æ–¹å®šä¹‰å¦‚ä¸‹ï¼š\ntemperature number Optional Defaults toÂ 1","title":"ChatGPT çš„è§£ç è¿‡ç¨‹å’Œå…¶ä¸­çš„å„ç§å‚æ•°"},{"content":"æœ¬æ–‡å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨ Rasa NLU å’Œ Rasa Core æ¥æ„å»ºä¸€ä¸ªç®€å•çš„å¸¦ Web UI ç•Œé¢çš„ä¸­æ–‡å¤©æ°”æƒ…å†µé—®è¯¢æœºå™¨äºº(chatbot)ã€‚\næºä»£ç åœ°å€ https://github.com/howl-anderson/WeatherBot\nåŠŸèƒ½ è¿™ä¸ªæœºå™¨äººå¯ä»¥æ ¹æ®ä½ æä¾›çš„åŸå¸‚ï¼ˆåŒ—äº¬ã€ä¸Šæµ·ç­‰ï¼‰å’Œæ—¥æœŸï¼ˆæ˜å¤©ã€åå¤©ç­‰ï¼‰ï¼ŒæŸ¥è¯¢å‡ºç›¸åº”çš„å¤©æ°”é¢„æŠ¥ã€‚\nåŠŸèƒ½æˆªå›¾ ç‰¹æ€§ ä½¿ç”¨ Frame-based å¯¹è¯ç®¡ç†æ–¹æ¡ˆï¼Œå¦‚æœä¸Šè¿°ä¸¤ä¸ª Slot (æ—¢åŸå¸‚å’Œå¤©æ°”)ï¼Œæœ‰ä»»æ„ä¸€ä¸ªç”¨æˆ·æœªæä¾›ï¼Œå¯¹è¯ç®¡ç†ç³»ç»Ÿä¼šè´Ÿè´£è®©ä½ æ¾„æ¸…ç›¸å…³ Slot çš„å€¼ã€‚\nèƒ½åŠ›èŒƒå›´ å—é™äºå¤©æ°”æ•°æ®æä¾›æ–¹çš„èƒ½åŠ›ï¼Œè¿™ä¸ªæœºå™¨äººåªèƒ½æŸ¥è¯¢ ä¸­å›½å¤§é™†åœ°åŒºå¸‚çº§åŸå¸‚ ä¸‰å¤©ä»¥å†… ï¼ˆä»Šå¤©ï¼Œæ˜å¤©ï¼Œåå¤©ï¼‰ çš„æ°”è±¡æ•°æ®ï¼Œä¸èƒ½æŸ¥è¯¢è¿‡å»ï¼ˆæ˜¨å¤©ï¼Œå‰å¤©ï¼‰ç­‰å†å²æ•°æ®ã€‚ å—é™äºå¼€å‘æ—¶é—´ï¼Œè¿™ä¸ªæœºå™¨äºº ä¸æä¾› è¯¸å¦‚ è¿™ä¸ªæ˜ŸæœŸäº”ã€ä¸‹ä¸ªæ˜ŸæœŸä¸€ è¿™ç§éœ€è¦è®¡ç®—æ‰èƒ½å¾—åˆ°æ—¥æœŸç»™å®šæ–¹å¼ã€‚ä¹Ÿ ä¸èƒ½æä¾› è¯¸å¦‚ ç»å¯¹æ—¥æœŸï¼šä¸‰æœˆä¸€å·ã€å…­ä¸€å„¿ç«¥èŠ‚æ—¥ è¿™ç§æ—¥æœŸçš„æŸ¥è¯¢èƒ½åŠ›ã€‚ å› ä¸ºä½¿ç”¨çš„æ˜¯å…è´¹çš„å¤©æ°”æŸ¥è¯¢æ¥å£ï¼Œæ‰€ä»¥ ä¼šæœ‰é…é¢é™åˆ¶ï¼Œå¯èƒ½ä¼šå› ä¸º è¶…å‡ºè°ƒç”¨æ¬¡æ•° ï¼Œè€Œåœ¨ä¸€ä¸ªå°æ—¶å†…ä¸èƒ½ç”¨ã€‚åŒæ—¶ç½‘ç»œæŸ¥è¯¢æ¥å£å¯èƒ½å­˜åœ¨ä¸ç¨³å®šå› ç´ ï¼Œå¯¼è‡´ æ²¡æœ‰ç»“æœè¿”å›æˆ–è€…å‡ºç°å¼‚å¸¸ï¼Œå°è¯•å¤šæ¬¡é‡æ–°å‘é€è¯·æ±‚å¯è§£å†³é—®é¢˜ã€‚ åœ¨çº¿æ¼”ç¤º Demo for å¤©æ°”é¢„æŠ¥æŸ¥è¯¢æœºå™¨äºº\nRasa NLU Rasa NLU æä¾›äº†æå–ç”¨æˆ·æ„å›¾å’Œè¯æ§½çš„åŠŸèƒ½ã€‚å…·ä½“åŸç†å’Œä½¿ç”¨ç­‰ä¸åœ¨è¿™é‡Œè¯¦è¿°ï¼Œè¯·è®¿é—®æ–‡ç«  TODOã€‚ è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨çš„ Rasa NLU çš„ pipeline é…ç½®ï¼ˆåœ¨é¡¹ç›®æ–‡ä»¶ nlu_model_config.yaml ä¸­ï¼‰å¦‚ä¸‹:\nlanguage: \u0026#34;zh\u0026#34; pipeline: - name: \u0026#34;nlp_mitie\u0026#34; model: \u0026#34;data/total_word_feature_extractor.dat\u0026#34; - name: \u0026#34;tokenizer_jieba\u0026#34; - name: \u0026#34;ner_mitie\u0026#34; - name: \u0026#34;ner_synonyms\u0026#34; - name: \u0026#34;intent_featurizer_mitie\u0026#34; - name: \u0026#34;intent_classifier_sklearn\u0026#34; æ‰€ç”¨çš„è®­ç»ƒæ•°æ® ï¼ˆåœ¨é¡¹ç›®æ–‡ä»¶ nlu.json ä¸­ï¼‰å¦‚ä¸‹ï¼ˆå†…å®¹è¿‡é•¿ï¼Œå·²åšæˆªæ–­ï¼‰ï¼š\n{ \u0026#34;rasa_nlu_data\u0026#34;: { \u0026#34;common_examples\u0026#34;: [ { \u0026#34;intent\u0026#34;: \u0026#34;weather_address_date-time\u0026#34;, \u0026#34;entities\u0026#34;: [ { \u0026#34;start\u0026#34;: 2, \u0026#34;end\u0026#34;: 4, \u0026#34;value\u0026#34;: \u0026#34;ä¸Šæµ·\u0026#34;, \u0026#34;entity\u0026#34;: \u0026#34;address\u0026#34; }, { \u0026#34;start\u0026#34;: 4, \u0026#34;end\u0026#34;: 6, \u0026#34;value\u0026#34;: \u0026#34;æ˜å¤©\u0026#34;, \u0026#34;entity\u0026#34;: \u0026#34;date-time\u0026#34; } ], \u0026#34;text\u0026#34;: \u0026#34;æˆ‘è¦ä¸Šæµ·æ˜å¤©çš„å¤©æ°”\u0026#34; }, { \u0026#34;intent\u0026#34;: \u0026#34;weather_address_date-time\u0026#34;, \u0026#34;entities\u0026#34;: [ { \u0026#34;start\u0026#34;: 0, \u0026#34;end\u0026#34;: 2, \u0026#34;value\u0026#34;: \u0026#34;ä¸Šæµ·\u0026#34;, \u0026#34;entity\u0026#34;: \u0026#34;address\u0026#34; }, { \u0026#34;start\u0026#34;: 2, \u0026#34;end\u0026#34;: 4, \u0026#34;value\u0026#34;: \u0026#34;æ˜å¤©\u0026#34;, \u0026#34;entity\u0026#34;: \u0026#34;date-time\u0026#34; } ], \u0026#34;text\u0026#34;: \u0026#34;ä¸Šæµ·æ˜å¤©çš„å¤©æ°”\u0026#34; }, ... } } è®­ç»ƒæ‰€ç”¨çš„å‘½ä»¤ä¸º (åœ¨é¡¹ç›®æ–‡ä»¶ train_NLU.bash ä¸­):\npython -m rasa_nlu.train -c nlu_model_config.yaml -d nlu.json --fixed_model_name current -o models Rasa Core Rasa Core è´Ÿè´£å¯¹è¯ç®¡ç†ã€‚å…·ä½“åŸç†å’Œä½¿ç”¨ç­‰ä¸åœ¨è¿™é‡Œè¯¦è¿°ï¼Œè¯·è®¿é—®æ–‡ç«  TODOã€‚ Rasa core éœ€è¦æä¾›ä¸€ä¸ª domain æ–‡ä»¶ï¼Œé‡Œé¢è®¾å®šäº†æ•´ä¸ªå¯¹è¯æœºå™¨äººçš„å°å®‡å®™ï¼Œå®ƒèƒ½çŸ¥é“çš„æ‰€æœ‰çš„æ„å›¾ã€è¯æ§½å’ŒåŠ¨ä½œã€‚\næœ¬é¡¹ç›®æ‰€ç”¨çš„ domain (åœ¨é¡¹ç›®æ–‡ä»¶ domain.yml ä¸­)ï¼Œå…¶å†…å®¹ä¸ºï¼š\nintents: - greet - goodbye - weather_address_date-time - weather_address - weather_date-time slots: address: type: text date-time: type: text matches: type: unfeaturized entities: - address - date-time actions: - utter_greet - utter_ask_address - utter_ask_date-time - utter_working_on_it - bot.ActionReportWeather - utter_report_weather - utter_goodbye templates: utter_greet: - text: \u0026#34;ä½ å¥½ï¼Œè¯·è¯´å‡ºéœ€è¦æä¾›å¤©æ°”é¢„æµ‹æœåŠ¡çš„åœ°ç‚¹å’Œæ—¶é—´\u0026#34; utter_working_on_it: - text: \u0026#34;æ­£åœ¨æŸ¥è¯¢ä¸­ï¼Œè¯·ç¨å ...\u0026#34; utter_goodbye: - text: \u0026#34;å†è§ï¼\u0026#34; utter_ask_address: - text: \u0026#34;å“ªé‡Œå‘¢ï¼Ÿ\u0026#34; utter_ask_date-time: - text: \u0026#34;ä»€ä¹ˆæ—¶å€™ï¼Ÿ\u0026#34; utter_report_weather: - text: \u0026#34;{matches}\u0026#34; utter_other: - text: \u0026#34;ç³»ç»Ÿä¸æ˜ç™½æ‚¨è¯´çš„è¯\u0026#34; Rasa Core è¿˜éœ€è¦é€šè¿‡ æ•…äº‹(story) çš„å½¢å¼è®©æ¡†æ¶å­¦ä¹ æ­£ç¡®çš„å¯¹è¯ç®¡ç†æ ·æœ¬ï¼Œæ ¼å¼ä¸º Markdown æ ¼å¼ã€‚æœ¬é¡¹ç›®ä¸­çš„ Story ï¼ˆåœ¨é¡¹ç›®æ–‡ä»¶ stories.md ä¸­ï¼‰å®šä¹‰å¦‚ä¸‹ï¼ˆå†…å®¹è¿‡é•¿ï¼Œå·²åšæˆªæ–­ï¼‰ï¼š\n## simple path with greet * greet - utter_greet * weather_address_date-time{\u0026#34;address\u0026#34;: \u0026#34;ä¸Šæµ·\u0026#34;, \u0026#34;date-time\u0026#34;: \u0026#34;æ˜å¤©\u0026#34;} - utter_working_on_it - action_report_weather - utter_report_weather ## simple path * weather_address_date-time{\u0026#34;address\u0026#34;: \u0026#34;ä¸Šæµ·\u0026#34;, \u0026#34;date-time\u0026#34;: \u0026#34;æ˜å¤©\u0026#34;} - utter_working_on_it - action_report_weather - utter_report_weather ## address + date-time path with greet * greet - utter_greet * weather_address{\u0026#34;address\u0026#34;: \u0026#34;ä¸Šæµ·\u0026#34;} - utter_ask_date-time * weather_date-time{\u0026#34;date-time\u0026#34;: \u0026#34;æ˜å¤©\u0026#34;} - utter_working_on_it - action_report_weather - utter_report_weather ... è®­ç»ƒæ‰€ç”¨çš„å‘½ä»¤ä¸º (åœ¨é¡¹ç›®æ–‡ä»¶ train_CORE.bash ä¸­):\npython -m rasa_core.train -s stories.md -d domain.yml -o models/dialogue --epochs 500 ä¾èµ– python ç‰ˆæœ¬ python 3\npython ä¾èµ– pip install -r requirements.txt ä¸‹è½½æ•°æ®å’Œæ¨¡å‹ data/total_word_feature_extractor.dat: ä» https://github.com/howl-anderson/MITIE_Chinese_Wikipedia_corpus ä¸‹è½½ï¼Œè§£å‹ç¼©åæ”¾ç½®åˆ°å¯¹åº”ä½ç½® models/default/currentï¼šé€šè¿‡è¿è¡Œ train_NLU.bash ç”Ÿæˆ models/dialogueï¼šé€šè¿‡è¿è¡Œ train_CORE.bash ç”Ÿæˆ åŠŸèƒ½å…¥å£ ç”³è¯· API key æœ¬é¡¹ç›®ç›®å‰ä½¿ç”¨ å¿ƒçŸ¥å¤©æ°” æä¾›å¤©æ°”æ•°æ®ï¼Œè¯¥å¹³å°ä¸ºä¸ªäººæä¾›å…è´¹çš„ APIï¼Œä½†ä»»ç„¶éœ€è¦ç”¨æˆ·æ³¨å†Œå¹¶ç”³è¯· API key æ‰èƒ½ä½¿ç”¨ã€‚ç”¨æˆ·æ³¨å†Œåå¯ä»¥è‡ªè¡Œæ‰¾åˆ° æˆ‘çš„APIå¯†é’¥ã€‚\nå¯åŠ¨æœåŠ¡ å°†å¦‚ä¸‹çš„ xxx æ›¿æ¢æˆä½ çš„ API keyï¼Œç„¶åæ‰§è¡Œå³å¯\nSENIVERSE_KEY=xxx python ./webchat.py å¯åŠ¨æˆåŠŸåï¼Œè¯·ç”¨æµè§ˆå™¨è®¿é—® http://localhost:5500 , ä½ å°†å¾—åˆ° web é¡µé¢ï¼Œhave fun!\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/creating-a-weather-query-bot-using-rasa/","summary":"\u003cp\u003eæœ¬æ–‡å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨ Rasa NLU å’Œ Rasa Core æ¥æ„å»ºä¸€ä¸ªç®€å•çš„å¸¦ Web UI ç•Œé¢çš„ä¸­æ–‡å¤©æ°”æƒ…å†µé—®è¯¢æœºå™¨äºº(chatbot)ã€‚\u003c/p\u003e","title":"ä½¿ç”¨ Rasa æ„å»ºå¤©æ°”æŸ¥è¯¢æœºå™¨äºº"},{"content":"æœ¬æ–‡å°†è¯¦ç»†ä»‹ç» Rasa NLU çš„ pipeline å’Œ componentï¼Œä»‹ç»å…¶åŸç†å’Œå¦‚ä½•ä½¿ç”¨ã€‚\nå…¼å®¹æ€§è¯´æ˜ï¼š\næœ¬æ–‡ä»‹ç»çš„ Rasa NLU çŸ¥è¯†éƒ½æ˜¯åŸºäº v0.13.2, ä¸åŒç‰ˆæœ¬ä¹‹é—´å¯èƒ½ä¼šæœ‰å·®å¼‚ï¼Œä¸è¿‡ä¸ç”¨æ‹…å¿ƒï¼Œæ ¹æ®å®˜æ–¹æ¶ˆæ¯ï¼ŒRasa NLU å·²ç»è¿›å…¥æ¯”è¾ƒæˆç†Ÿçš„é˜¶æ®µï¼Œåç»­å‡ºç°è¾ƒå¤§ç»“æ„å˜åŠ¨çš„å¯èƒ½æ€§ä¸å¤§ï¼Œå› æ­¤æœ¬æ–‡ä»‹ç»çš„çŸ¥è¯†åœ¨åç»­ç‰ˆæœ¬ï¼Œç”šè‡³ v1.x ä¾ç„¶æœ‰æ•ˆã€‚\nRasa NLU æ˜¯ä¸€ä¸ªåŸºäº pipeline çš„é€šç”¨æ¡†æ¶ã€‚è¿™æ ·å¯ä»¥è·å¾—æœ€å¤§çš„çµæ´»æ€§ã€‚\npipeline å®šä¹‰äº†å„ä¸ªç»„ä»¶ä¹‹é—´æ•°æ®çš„å‰åæµåŠ¨å…³ç³»ï¼Œç»„ä»¶ä¹‹é—´æ˜¯å­˜åœ¨ä¾èµ–å…³ç³»çš„ï¼Œä»»æ„ä¸€ä¸ªç»„ä»¶çš„ä¾èµ–éœ€æ±‚æ²¡æœ‰è¢«æ»¡è¶³éƒ½å°†å¯¼è‡´ pipeline å‡ºé”™ï¼ˆRasa NLU ä¼šåœ¨å¯åŠ¨çš„æ—¶å€™æ£€æŸ¥æ˜¯å¦æ¯ä¸€ä¸ªç»„ä»¶çš„ä¾èµ–éƒ½è¢«æ»¡è¶³ï¼Œå¦‚æœæ²¡æœ‰æ»¡è¶³ï¼Œåˆ™ç»ˆæ­¢è¿è¡Œå¹¶ç»™å‡ºç›¸å…³çš„æç¤ºæ¶ˆæ¯ï¼‰ã€‚å…·æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š\nç»„ä»¶ä¹‹é—´çš„é¡ºåºå…³ç³»è‡³å…³é‡è¦ï¼Œæ¯”å¦‚ NER ç»„ä»¶éœ€è¦å‰é¢çš„ç»„ä»¶æä¾›åˆ†è¯ç»“æœæ‰èƒ½æ­£å¸¸å·¥ä½œï¼Œé‚£ä¹ˆå‰é¢çš„ç»„ä»¶ä¸­æœ‰å¿…é¡»æœ‰ä¸€ä¸ªåˆ†è¯å™¨ã€‚ ç»„ä»¶æ˜¯å¯ä»¥ç›¸äº’æ›¿æ¢çš„ï¼Œæ¯”å¦‚åŒæ ·æ˜¯æä¾›åˆ†è¯ç»“æœï¼ŒåŒæ—¶æœ‰å‡ ä¸ª component å¯ä»¥é€‰æ‹©ï¼Œæ¯”å¦‚ä¸­æ–‡çš„å¯ä»¥é€‰æ‹©æ¸…åçš„åˆ†è¯å™¨ã€åŒ—å¤§çš„åˆ†è¯å™¨çš„ã€‚ æœ‰äº›ç»„ä»¶æ˜¯äº’æ–¥çš„ï¼Œæ¯”å¦‚ï¼šåˆ†è¯å™¨æ˜¯äº’æ–¥çš„ï¼Œåˆ†è¯ç»“æœä¸èƒ½åŒæ—¶ç”±ä¸¤ä¸ªç»„ä»¶æä¾›ï¼Œå¦åˆ™ä¼šå‡ºç°æ··ä¹±ã€‚ æœ‰äº›ç»„ä»¶æ˜¯å¯ä»¥åŒæ—¶ä½¿ç”¨çš„ï¼Œæ¯”å¦‚ï¼šæå–æ–‡æœ¬ç‰¹å¾çš„ç»„ä»¶å¯ä»¥åŒæ—¶ä½¿ç”¨åŸºäºè§„åˆ™çš„å’ŒåŸºäºæ–‡æœ¬åµŒå…¥å‘é‡çš„ã€‚ ä¸€ä¸ª NLU åº”ç”¨é€šå¸¸åŒ…æ‹¬ å‘½åå®ä½“è¯†åˆ« å’Œ æ„å›¾è¯†åˆ« ä¸¤ä¸ªä»»åŠ¡ã€‚ä¸ºäº†å®Œæˆè¿™äº›ä»»åŠ¡ï¼Œä¸€ä¸ª å…¸å‹ çš„ Rasa NLU pipeline é€šå¸¸å…·æœ‰ä»¥ä¸‹çš„ pattern:\nåˆå§‹åŒ–ç±»ç»„ä»¶ï¼šä¸ºäº†åŠ è½½æ¨¡å‹æ–‡ä»¶ï¼Œä¸ºåç»­çš„ç»„ä»¶æä¾›æ¡†æ¶æ”¯æŒï¼Œå¦‚åˆå§‹åŒ– SpaCy å’Œ MITIE åˆ†è¯ç»„ä»¶ï¼šå°†æ–‡æœ¬åˆ†å‰²æˆè¯è¯­åºåˆ—ï¼Œä¸ºåç»­çš„é«˜çº§ NLP ä»»åŠ¡æä¾›åŸºç¡€æ•°æ® æå–ç‰¹å¾ï¼šæå–è¯è¯­åºåˆ—çš„æ–‡æœ¬ç‰¹å¾ï¼Œé€šå¸¸é‡‡ç”¨ Word Embedding çš„æ–¹å¼ï¼Œæå–ç‰¹å¾çš„ç»„ä»¶å¯ä»¥åŒæ—¶ä½¿ç”¨ï¼ŒåŒæ—¶æ­é…çš„è¿˜å¯èƒ½æœ‰åŸºäºæ­£åˆ™è¡¨è¾¾å¼çš„æå–ç‰¹å¾çš„æ–¹æ³•ã€‚ NER ç»„ä»¶ï¼šæ ¹æ®å‰é¢æä¾›çš„ç‰¹å¾å¯¹æ–‡æœ¬è¿›è¡Œå‘½åå®ä½“çš„è¯†åˆ« æ„å›¾åˆ†ç±»ï¼šæŒ‰ç…§è¯­ä¹‰å¯¹æ–‡æœ¬è¿›è¡Œæ„å›¾çš„åˆ†ç±»ï¼Œä¹Ÿç§°æ„å›¾è¯†åˆ« åˆå§‹åŒ–ç»„ä»¶ åˆå§‹åŒ–ç»„ä»¶æä¾›åŠ è½½æ¨¡å‹æ–‡ä»¶ä¸ºåç»­ç»„ä»¶æ‰€ç”¨çš„ç»„ä»¶æä¾›åˆå§‹åŒ–ã€‚ç›®å‰åªæœ‰ä¸¤ä¸ªåˆå§‹åŒ–ç»„ä»¶ï¼šnlp_spacy å’Œ nlp_mitieï¼Œåˆ†åˆ«å¯¹åº” SpaCyï¼ˆhttps://spacy.io/ï¼‰ å’Œ MITIEï¼ˆhttps://github.com/mit-nlp/MITIEï¼‰ æ¡†æ¶ã€‚\nåŸºäº MITIE çš„ç»„ä»¶ï¼Œå¦‚ï¼š tokenizer_mitieã€intent_featurizer_mitieã€ner_mitie å’Œ intent_classifier_mitie éƒ½å°†ä¾èµ– nlp_mitie æä¾›çš„å¯¹è±¡ã€‚\nåŸºäº SpaCy çš„ç»„ä»¶ï¼Œå¦‚ï¼štokenizer_spacyã€intent_featurizer_spacy å’Œ ner_spacy éƒ½å°†ä¾èµ– nlp_spacy æä¾›çš„å¯¹è±¡ã€‚\nåˆ†è¯ç»„ä»¶ ä»€ä¹ˆæ˜¯åˆ†è¯ï¼Ÿ è‡ªç„¶è¯­è¨€å¤„ç†åœ¨é€šå¸¸æƒ…å†µä¸‹éƒ½éœ€è¦è¿›è¡Œè¿›è¡Œåˆ†è¯æ“ä½œï¼Œé‚£ä¹ˆä»€ä¹ˆæ˜¯è¯ï¼Œä¸ºä»€ä¹ˆè¦åˆ†è¯å‘¢ï¼Ÿ\næŒ‰ç…§ç»´åŸºç™¾ç§‘ï¼ˆhttps://zh.wikipedia.org/wiki/è¯ï¼‰çš„å®šä¹‰ï¼š\nåœ¨è¯­è¨€å­¦ä¸­ï¼Œè¯ï¼ˆè‹±è¯­ï¼šwordï¼‰ï¼Œåˆç§°ä¸ºå•è¯ï¼Œæ˜¯èƒ½ç‹¬ç«‹è¿ç”¨å¹¶å«æœ‰è¯­ä¹‰å†…å®¹æˆ–è¯­ç”¨å†…å®¹ï¼ˆå³å…·æœ‰è¡¨é¢å«ä¹‰æˆ–å®é™…å«ä¹‰ï¼‰çš„æœ€å°å•ä½ã€‚\nå¾ˆå¤šé€šç”¨çš„ NLP ç®—æ³•ã€è¯­æ³•è¯­ä¹‰åˆ†æå’Œ End-to-End åº”ç”¨éƒ½æ˜¯ä»¥è¯ä½œä¸ºåŸºæœ¬è¾“å…¥å•å…ƒã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†çš„ä»»åŠ¡ä¸­ï¼ŒæŠŠè¿ç»­çš„å­—ï¼ˆè‹±è¯­ï¼šcharacterï¼‰åˆ†éš”æˆæ›´å…·æœ‰è¯­è¨€è¯­ä¹‰å­¦ä¸Šæ„ä¹‰çš„è¯ï¼ˆè‹±è¯­ï¼šwordï¼‰ã€‚è¿™ä¸ªè¿‡ç¨‹å°±å«åšåˆ†è¯ï¼ˆè‹±è¯­ï¼štokenize /segmentï¼‰ã€‚\nä¸¾ä¾‹æ¥è¯´ï¼š\nç‹å°æ˜åœ¨åŒ—äº¬çš„æ¸…åå¤§å­¦è¯»ä¹¦ã€‚\nå¯ä»¥è¢«åˆ†è¯æˆ\nç‹å°æ˜ åœ¨ åŒ—äº¬ çš„ æ¸…åå¤§å­¦ è¯»ä¹¦ ã€‚\nRasa åˆ†è¯ç»„ä»¶ Rasa åˆ†è¯ç»„ä»¶ä¸­ï¼Œç›®å‰ç›´æ¥æ”¯æŒä¸­æ–‡çš„ç»„ä»¶æ˜¯ tokenizer_jieba ä½¿ç”¨åŸºäº MIT å¼€æºåè®®çš„æµè¡Œä¸­æ–‡åˆ†è¯å™¨ jieba (https://github.com/fxsjy/jieba) ä½œä¸ºåº•å±‚å¼•æ“ï¼Œç»è¿‡æ”¹é€ å¯ä»¥æ”¯æŒä¸­æ–‡åˆ†è¯çš„ç»„ä»¶æ˜¯ tokenizer_mitieï¼Œæš‚ä¸æ”¯æŒä¸­æ–‡åˆ†è¯ä½†æœªæ¥ä¼šæ”¯æŒä¸­æ–‡åˆ†è¯çš„ç»„ä»¶æ˜¯ tokenizer_spacyã€‚æƒ³ç”¨å…¶ä»–çš„åˆ†è¯å™¨ï¼Ÿå½“ç„¶æ²¡é—®é¢˜ï¼Œå› ä¸º Rasa NLU é‡‡ç”¨ pipeline æœºåˆ¶ï¼Œæ‰©å±•èµ·æ¥éå¸¸å®¹æ˜“ï¼Œä½ åªéœ€è¦è‡ªå·±å®ç°ä¸€ä¸ªåˆ†è¯ç»„ä»¶å°±å¯ä»¥äº†ï¼Œåé¢çš„ç« èŠ‚æˆ‘å°†æ¼”ç¤ºå¦‚ä½•è‡ªå®šä¹‰è‡ªå·±çš„ä¸­æ–‡åˆ†è¯å™¨ï¼Œæœ¬ç« èŠ‚å°†ä¸ç ”ç©¶å¦‚ä½•å®ç°è‡ªå·±çš„ç»„ä»¶ã€‚\næå–ç‰¹å¾ æ— è®ºæ˜¯å‘½åå®ä½“è¯†åˆ«è¿˜æ˜¯æ„å›¾åˆ†ç±»ï¼Œéƒ½éœ€è¦ä¸Šæ¸¸çš„ç»„ä»¶æä¾›ç‰¹å¾ã€‚å¸¸è§çš„ç‰¹å¾é€‰æ‹©ä¸ºï¼šè¯å‘é‡ã€Bag-of-words å’Œ N-grams ç­‰ã€‚ç”¨æˆ·å¯ä»¥é€‰æ‹©åŒæ—¶ä½¿ç”¨ä»»æ„çš„ä¸Šè¿°ç»„ä»¶æå–ç‰¹å¾ï¼Œè¿™äº›ç»„ä»¶åœ¨å®ç°å±‚é¢ä¸Šåšäº†åˆå¹¶ç‰¹æ€§çš„æ“ä½œï¼Œå› æ­¤å¯ä»¥ä»»æ„å’Œå’Œæå–ç‰¹å¾çš„ç»„ä»¶ä¸€èµ·ä½¿ç”¨ã€‚ä¸‹é¢é€ä¸€ä»‹ç»å„ä¸ªç»„ä»¶ã€‚\nè¯å‘é‡ç‰¹å¾ TODO\nBag-of-words TODO\nN-grams TODO\næ­£åˆ™è¡¨è¾¾å¼ç‰¹å¾ TODO\nNER SpaCy æ”¯æŒå¤šç§ NER ç»„ä»¶ï¼šner_crf ã€ner_mitie ã€ner_spacy ã€ner_duckling ã€ner_duckling_http å’Œ ner_synonymsã€‚\nner_crf è¿™ä¸ªç»„ä»¶å¦‚å…¶åï¼Œä½¿ç”¨ CRF æ¨¡å‹æ¥åš ENR, CRF æ¨¡å‹åªä¾èµ– tokens æœ¬èº«ï¼Œå¦‚æœæƒ³åœ¨ feature function ä¸­ä½¿ç”¨ POS ç‰¹æ€§ é‚£ä¹ˆåˆ™éœ€è¦ nlp_spacy ç»„ä»¶æä¾› spacy_doc å¯¹è±¡æ¥æä¾› POS ä¿¡æ¯ã€‚å…³äº CRF æ¨¡å‹çš„åŸç†å’Œä½¿ç”¨ï¼Œè¯·ç§»æ­¥ç« èŠ‚ TODO\nner_mitie åˆ©ç”¨ MITIE æ¨¡å‹æä¾›çš„ language modelï¼Œåªéœ€è¦ tokens å°±å¯ä»¥è¿›è¡Œ NERã€‚TODO: å…·ä½“åŸç†å¾…ç ”ç©¶\nner_spacy åˆ©ç”¨ SpaCy æ¨¡å‹è‡ªå¸¦çš„ NER åŠŸèƒ½ï¼Œæ¨¡å‹çš„è®­ç»ƒéœ€è¦åœ¨ SpaCy æ¡†æ¶ä¸‹è¿›è¡Œï¼Œå½“å‰ SpaCy æ¨¡å‹ä¸æ”¯æŒç”¨æˆ·è®­ç»ƒè‡ªå·±çš„æ¨¡å‹ï¼Œè€Œ SpaCy å®˜æ–¹çš„æ¨¡å‹åªæ”¯æŒå¸¸è§çš„å‡ ç§å®ä½“ï¼Œå…·ä½“æƒ…å†µè§å®˜æ–¹æ–‡æ¡£ã€‚\nner_duckling å’Œ ner_duckling_http Duckling æ˜¯ Facebook å‡ºå“çš„ä¸€æ¬¾ç”¨ Haskell è¯­è¨€å†™æˆçš„ NER åº“ï¼ŒåŸºäºè§„åˆ™å’Œæ¨¡å‹ã€‚Duckling æ”¯æŒå¤šç§å®ä½“çš„æå–ï¼Œå¦‚ä¸‹è¡¨ï¼ˆTODO: æ ‡æ³¨ Duckling çš„ç‰ˆæœ¬ï¼‰ï¼š\nDimension Example input Example value output AmountOfMoney \u0026ldquo;42â‚¬\u0026rdquo; {\u0026quot;value\u0026quot;:42,\u0026quot;type\u0026quot;:\u0026quot;value\u0026quot;,\u0026quot;unit\u0026quot;:\u0026quot;EUR\u0026quot;} Distance \u0026ldquo;6 miles\u0026rdquo; {\u0026quot;value\u0026quot;:6,\u0026quot;type\u0026quot;:\u0026quot;value\u0026quot;,\u0026quot;unit\u0026quot;:\u0026quot;mile\u0026quot;} Duration \u0026ldquo;3 mins\u0026rdquo; {\u0026quot;value\u0026quot;:3,\u0026quot;minute\u0026quot;:3,\u0026quot;unit\u0026quot;:\u0026quot;minute\u0026quot;,\u0026quot;normalized\u0026quot;:{\u0026quot;value\u0026quot;:180,\u0026quot;unit\u0026quot;:\u0026quot;second\u0026quot;}} Email \u0026ldquo;duckling-team@fb.com\u0026rdquo; {\u0026quot;value\u0026quot;:\u0026quot;duckling-team@fb.com\u0026quot;} Numeral \u0026ldquo;eighty eight\u0026rdquo; {\u0026quot;value\u0026quot;:88,\u0026quot;type\u0026quot;:\u0026quot;value\u0026quot;} Ordinal \u0026ldquo;33rd\u0026rdquo; {\u0026quot;value\u0026quot;:33,\u0026quot;type\u0026quot;:\u0026quot;value\u0026quot;} PhoneNumber \u0026ldquo;+1 (650) 123-4567\u0026rdquo; {\u0026quot;value\u0026quot;:\u0026quot;(+1) 6501234567\u0026quot;} Quantity \u0026ldquo;3 cups of sugar\u0026rdquo; {\u0026quot;value\u0026quot;:3,\u0026quot;type\u0026quot;:\u0026quot;value\u0026quot;,\u0026quot;product\u0026quot;:\u0026quot;sugar\u0026quot;,\u0026quot;unit\u0026quot;:\u0026quot;cup\u0026quot;} Temperature \u0026ldquo;80F\u0026rdquo; {\u0026quot;value\u0026quot;:80,\u0026quot;type\u0026quot;:\u0026quot;value\u0026quot;,\u0026quot;unit\u0026quot;:\u0026quot;fahrenheit\u0026quot;} Time \u0026ldquo;today at 9am\u0026rdquo; {\u0026quot;values\u0026quot;:[{\u0026quot;value\u0026quot;:\u0026quot;2016-12-14T09:00:00.000-08:00\u0026quot;,\u0026quot;grain\u0026quot;:\u0026quot;hour\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;value\u0026quot;}],\u0026quot;value\u0026quot;:\u0026quot;2016-12-14T09:00:00.000-08:00\u0026quot;,\u0026quot;grain\u0026quot;:\u0026quot;hour\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;value\u0026quot;} Url \u0026ldquo;https://api.wit.ai/message?q=hi\u0026quot; {\u0026quot;value\u0026quot;:\u0026quot;https://api.wit.ai/message?q=hi\u0026quot;,\u0026quot;domain\u0026quot;:\u0026quot;api.wit.ai\u0026quot;} Volume \u0026ldquo;4 gallons\u0026rdquo; {\u0026quot;value\u0026quot;:4,\u0026quot;type\u0026quot;:\u0026quot;value\u0026quot;,\u0026quot;unit\u0026quot;:\u0026quot;gallon\u0026quot;} TODO: è€ƒè™‘ç¿»è¯‘ä¸Šè¡¨ä¸ºä¸­æ–‡\nè¿™é‡Œéœ€è¦æé†’çš„æ˜¯ Duckling å¯¹ä¸­æ–‡çš„æ”¯æŒå¹¶ä¸æ˜¯å¾ˆå…¨é¢ï¼Œåªæ”¯æŒä¸Šé¢è¯¸å¤šå®ä½“ç±»å‹ä¸­çš„å‡ ç§ã€‚\nåœ¨ Rssa ä¸­æœ‰ä¸¤ç§æ–¹å¼å»è°ƒç”¨ Duckling ï¼Œä¸€ç§æ˜¯é€šè¿‡ duckling è¿™ä¸ªåŒ…ä½¿ç”¨ wrap çš„æ–¹å¼è®¿é—®ï¼Œå¦ä¸€ç§æ˜¯é€šè¿‡ HTTP è®¿é—®ã€‚ä¸Šè¿°ä¸¤ç§è®¿é—®æ–¹å¼åˆ†åˆ«å¯¹åº” ner_duckling å’Œ ner_duckling_http è¿™ä¸¤ä¸ªç»„ä»¶ã€‚ä¸Šè¿°ä¸¤ç§ç»„ä»¶å¦‚ä½•èµ·æ¥å¹¶ä¸å›°éš¾ï¼Œå…·ä½“è¯·æŸ¥é˜…å®˜æ–¹æ–‡æ¡£ã€‚\nner_synonyms æ­£ç¡®æ¥è¯´ ner_synonyms ä¸æ˜¯ä¸€ä¸ªå‘½åå®ä½“çš„æå–ç»„ä»¶ï¼Œæ›´åƒæ˜¯ä¸€ä¸ªå½’ä¸€åŒ–çš„ç»„ä»¶ã€‚ner_synonyms ä¸»è¦æ˜¯è®²å„ç§åŒä¹‰è¯ï¼ˆsynonymsï¼‰æ˜ å°„æˆä¸ºæ ‡å‡†è¯æ±‡ï¼Œæ¯”å¦‚å°†å®ä½“ KFC çš„å€¼æ”¹å†™æˆ è‚¯å¾·åŸºï¼Œè¿™ç§å½’ä¸€åŒ–çš„æ“ä½œä¸ºåç»­ä¸šåŠ¡å¤„ç†æä¾›ä¾¿åˆ©ã€‚\næ„å›¾åˆ†ç±» æ„å›¾è¯†åˆ«ä¹Ÿç§°æ„å›¾åˆ†ç±»ï¼ŒRasa ä¸­çš„å†…å»ºç»„ä»¶æœ‰ intent_classifier_mitieã€intent_classifier_sklearnã€intent_classifier_tensorflow_embedding å’Œ intent_classifier_keywordã€‚\nintent_classifier_mitie TODO\nintent_classifier_sklearn TODO\nintent_classifier_tensorflow_embedding TODO\nintent_classifer_keyword TODO\nç»“æ„åŒ–è¾“å‡º Rasa NLU é€šè¿‡ç»“æ„åŒ–è¾“å‡ºç»„ä»¶å°†ç»“æœè¾“å‡ºï¼Œåœ¨Rasa NLU ä¸­ç»“æ„åŒ–è¾“å‡ºç»„ä»¶æ˜¯æ¡†æ¶æä¾›çš„ï¼Œä¸å±äº Pipeline çš„å¯å˜åŠ¨éƒ¨åˆ†ï¼Œå› æ­¤ä¹Ÿä¸éœ€è¦ç”¨æˆ·å»é…ç½®ï¼ˆä¹Ÿæ— æ³•ç›´æ¥é…ç½®ï¼‰ã€‚\nTODOï¼šè§£é‡Šè¾“å‡ºçš„ç»“æ„ï¼ŒåŒ…æ‹¬ç»„ä»¶ä¸åŒçš„æƒ…å†µä¸‹ï¼Œå¯èƒ½çš„ç»“æœ\né…ç½® Pipeline Rasa NLU çš„é…ç½®æ–‡ä»¶ä½¿ç”¨çš„æ˜¯ YAML (YAML Ain\u0026rsquo;t Markup Language) æ ¼å¼ã€‚ä¸‹é¢ä¸¤ä¸ªæ˜¯Rasa NLU é…ç½®çš„æ–‡ä»¶çš„æ ·ä¾‹ã€‚\nlanguage: \u0026#34;en\u0026#34; pipeline: - name: \u0026#34;nlp_mitie\u0026#34; model: \u0026#34;data/total_word_feature_extractor.dat\u0026#34; - name: \u0026#34;tokenizer_mitie\u0026#34; - name: \u0026#34;ner_mitie\u0026#34; - name: \u0026#34;ner_synonyms\u0026#34; - name: \u0026#34;intent_entity_featurizer_regex\u0026#34; - name: \u0026#34;intent_classifier_mitie\u0026#34; å¤§ä½“ä¸Š Rasa NLU çš„é…ç½®æ–‡ä»¶å¯ä»¥åˆ†ä¸ºä¸¤ä¸ªä¸»è¦çš„ Keyï¼šlanguage å’Œ pipeline\nlanguage ç”¨äºæŒ‡å®š Rasa NLU å°†è¦å¤„ç†çš„è¯­è¨€ã€‚å› ä¸ºæŸäº›ç§ç±»çš„ç»„ä»¶ï¼Œæ¯”å¦‚åˆ†è¯ç»„ä»¶ï¼Œæ˜¯å¯¹è¯­è¨€æ•æ„Ÿçš„ã€‚æ¯”å¦‚è¯´ jieba åˆ†è¯å°±ä¸èƒ½æ­£ç¡®çš„å¤„ç†æ—¥æ–‡çš„åˆ†è¯ï¼Œåä¹‹äº¦ç„¶ã€‚æ‰€æœ‰çš„ Rasa NLU ç»„ä»¶éƒ½æœ‰ä¸€ä¸ªè¯­è¨€å…¼å®¹æ€§åˆ—è¡¨ã€‚å¦‚æœæŸä¸ªç»„ä»¶ä¸æ”¯æŒå½“å‰è®¾ç½®çš„è¯­è¨€ï¼Œåˆ™ä¼šåœ¨ Pipeline å¯åŠ¨å‰è¢«æ¡†æ¶æ£€æµ‹åˆ°ã€‚å¦å¤–è¿™ç§è¯­è¨€ä¿¡æ¯ä¹Ÿå¯ä»¥è¢«å…¶ä»–ç»„ä»¶ä½œä¸ºé…ç½®å˜é‡ï¼Œæ¯”å¦‚åœ¨ä½¿ç”¨ SpaCy çš„æ—¶å€™ï¼Œé»˜è®¤å°±ä¼šè½½å…¥å’Œ language åŒåçš„è¯­è¨€æ¨¡å‹ã€‚å¦‚æœçœç•¥è¯¥å­—æ®µï¼Œåˆ™é»˜è®¤ä¸º enã€‚\npipeline æ˜¯é…ç½®æ–‡ä»¶çš„æ ¸å¿ƒï¼Œpipeline ç”±åˆ—è¡¨æ„æˆï¼ˆè¡¨ç°åœ¨ YAML ä¸­ å°±æ˜¯ä½¿ç”¨ - å¼€å¤´ï¼‰ï¼Œåˆ—è¡¨çš„æ¯ä¸€ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªå­—å…¸(è¡¨ç°åœ¨ YAML ä¸­ç±»ä¼¼äº name: xxx)ï¼Œè¿™äº›å­—å…¸ç›´æ¥å¯¹åº”ç€ pipeline çš„ç»„ä»¶ã€‚æ¯ä¸ªç»„ä»¶å…·ä½“æ˜¯ä»€ä¹ˆéƒ½ç”±å­—å…¸çš„ name é”®æ¥æŒ‡å®šï¼Œå‡ºç°åœ¨å­—å…¸ä¸­çš„å…¶ä»–çš„é”®éƒ½æ˜¯å¯¹è¿™ä¸ªç»„ä»¶çš„é…ç½®ï¼Œè¿è¡Œæ—¶å°†ä¼ é€’ç»™å„ä¸ªç»„ä»¶ï¼Œå…·ä½“æœ‰ä»€ä¹ˆé”®å’Œä»€ä¹ˆæ„ä¹‰éƒ½ç”±å„ä¸ªç»„ä»¶è‡ªè¡Œå®šä¹‰ã€‚\nåœ¨ä¸Šä¾‹ä¸­ï¼Œå…±æœ‰ç»„ä»¶ 6 ä¸ªï¼Œåˆ†åˆ«æ˜¯ nlp_mitieã€ tokenizer_mitieã€ ner_mitieã€ ner_synonyms ã€intent_entity_featurizer_regex å’Œ intent_classifier_mitieã€‚å…¶ä¸­ nlp_mitie ç»„ä»¶æ‹¥æœ‰ä¸€ä¸ªé…ç½®é¡¹ï¼šé”®ï¼ˆkeyï¼‰ä¸º modelï¼Œå€¼ï¼ˆvalueï¼‰ä¸º data/total_word_feature_extractor.datï¼Œè¿™ä¸ªé…ç½®é¡¹æŒ‡å®šäº† MITIE æ¨¡å‹æ–‡ä»¶æ‰€åœ¨æ˜¯ä½ç½®ã€‚\nä¸ºäº†æœ€å¤§åŒ–çš„æ–¹ä¾¿ç”¨æˆ·ï¼ŒRasa NLU çš„é…ç½®è¿˜å¯ä»¥é‡‡ç”¨é¢„å®šä¹‰çš„ pipeline çš„æ–¹å¼ï¼Œå¦‚ä¸‹\npipeline: tensorflow_embedding ç›´æ¥ç»™ pipeline èµ‹å€¼ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¿™ä¸ªå­—ç¬¦ä¸²ä»£è¡¨äº†é¢„å®šä¹‰çš„ pipelineï¼Œåœ¨ä¸Šä¾‹ä¸­é¢„å®šä¹‰çš„ pipeline åä¸º tensorflow_embeddingã€‚\né¢„å®šä¹‰ Pipeline Rasa NLU é¢„å®šä¹‰äº†å‡ ä¸ªå¸¸ç”¨çš„ pipeline\ntensorflow_embedding TODO\nspacy_sklearn TODO\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/pipeline-and-components-in-rasa-nlu/","summary":"\u003cp\u003eæœ¬æ–‡å°†è¯¦ç»†ä»‹ç» Rasa NLU çš„ pipeline å’Œ componentï¼Œä»‹ç»å…¶åŸç†å’Œå¦‚ä½•ä½¿ç”¨ã€‚\u003c/p\u003e","title":"Rasa NLU çš„ pipeline å’Œ component"},{"content":"åˆ©ç”¨ éšé©¬å°”ç§‘å¤«æ¨¡å‹ï¼ˆHMMï¼‰ çš„è§£ç èƒ½åŠ›ï¼Œèƒ½ä»ä¸€ä¸ªè§‚å¯Ÿåºåˆ—ï¼ˆå­—ç¬¦ä¸²åºåˆ—ï¼‰è§£ç æˆå¦ä¸€ä¸ªéšè—çŠ¶æ€åºåˆ—ï¼ˆåˆ†è¯ç¬¦å·åºåˆ—ï¼‰ã€‚\nè§£é‡Š å°†è®­ç»ƒæ•°æ®æŒ‰ç…§ BMES æ ‡è®°é›†åˆè½¬æ¢æˆéšè—çŠ¶æ€åºåˆ—ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ä½¿ç”¨ BMES æ ‡è®°ä½“ç³»ä½œä¸ºéšè—åºåˆ—çš„ä½“ç³»ã€‚\nBMES æ ‡è®°ä½“ç³» BMES åˆ†åˆ«æ˜¯ Begin / Middle / End / Single çš„ç¼©å†™ï¼Œåˆ†åˆ«ä»£è¡¨ç€æ‰€æ ‡è®°çš„å­—ç¬¦æ˜¯ä¸€ä¸ªè¯è¯­çš„ å¼€å§‹å­—ç¬¦ / ä¸­é—´å­—ç¬¦ / ç»“å°¾å­—ç¬¦ / å•ä¸ªå­—ç¬¦ï¼ˆä¹Ÿå°±æ˜¯è¯´è¿™ä¸ªè¯åªç”±ä¸€ä¸ªå­—ç¬¦æ„æˆï¼‰ã€‚\nä¸¾ä¾‹æ¥è¯´ï¼š\næˆ‘ è¿™ä¸ªè¯å¯¹åº”çš„ BMES æ ‡è®°ä¸º S æˆ‘ä»¬ è¿™ä¸ªè¯å¯¹åº”çš„ BMES æ ‡è®°ä¸º BE è€çˆ·çˆ· è¿™ä¸ªè¯å¯¹åº”çš„ BMES æ ‡è®°ä¸º BME é£è°ƒé›¨é¡º è¿™ä¸ªè¯å¯¹åº”çš„ BMES æ ‡è®°ä¸º BMME å¾—åˆ°è®­ç»ƒæ•°æ®åï¼Œå¯ä»¥ç»Ÿè®¡å‡º HMM çš„ä¸¤ä¸ªå‚æ•°è¡¨ã€‚å¾—åˆ°çš„ HMM å‚æ•°åå¯ä»¥åˆ©ç”¨ Viterbi ç®—æ³•è§£ç å‡ºéšè—çŠ¶æ€åºåˆ—ï¼Œå†æŒ‰ç…§éšè—çŠ¶æ€åºåˆ—åå‘å°†å­—ç¬¦ä¸²åˆ†å‰²æˆè¯è¯­\nç¤ºä¾‹ ä»¥ æˆ‘ä»¬åœ¨é‡ç”ŸåŠ¨ç‰©å›­ç© ä¸ºä¾‹, å‡è®¾ HMM è§£ç å¾—åˆ°çš„éšè—çŠ¶æ€åºåˆ—ä¸º BESBMMMES\nåˆ™ä¼šè¢«åˆ†æˆ æˆ‘ä»¬(BE) / åœ¨(S) / é‡ç”ŸåŠ¨å›­(BMMME) / ç©(S)\nä¼˜åŒ–æ–¹æ¡ˆ ä¸ºäº†å¢åŠ å¤„ç† OOV çš„èƒ½åŠ›ï¼Œå¯¹äºæ²¡æœ‰å‡ºç°åœ¨è®­ç»ƒæ•°æ®é›†çš„å­—ç¬¦ï¼Œæ¯ä¸ªéšè—çŠ¶æ€éƒ½æœ‰ä¸€ä¸ªéå¸¸å°çš„ Emission Probability, è¿™æ ·å¯ä»¥å¢åŠ æ¨¡å‹çš„é²æ£’æ€§ã€‚\n\u0008å…³è”ç®—æ³• CRF çš„åŸºæœ¬æƒ³æ³•ä¸æ­¤ç®—æ³•ç±»ä¼¼ï¼Œä½†æ€§èƒ½æ›´åŠ å¼ºåŠ²ã€‚\nå‚è€ƒæ–‡çŒ® Part-of-Speech Tagging in Speech and Language Processing (Draft of August 12, 2018.) ","permalink":"https://blog.xiaoquankong.ai/zh/posts/implementing-a-hmm-based-chinese-tokenizer/","summary":"\u003cp\u003eåˆ©ç”¨ éšé©¬å°”ç§‘å¤«æ¨¡å‹ï¼ˆHMMï¼‰ çš„è§£ç èƒ½åŠ›ï¼Œèƒ½ä»ä¸€ä¸ªè§‚å¯Ÿåºåˆ—ï¼ˆå­—ç¬¦ä¸²åºåˆ—ï¼‰è§£ç æˆå¦ä¸€ä¸ªéšè—çŠ¶æ€åºåˆ—ï¼ˆåˆ†è¯ç¬¦å·åºåˆ—ï¼‰ã€‚\u003c/p\u003e","title":"æ„å»ºä¸­æ–‡åˆ†è¯å™¨ - éšé©¬å°”ç§‘å¤«æ¨¡å‹"},{"content":"ç»“åˆ æ­£å‘æœ€å¤§åŒ¹é…æ³• å’Œ åå‘æœ€å¤§åŒ¹é…æ³• çš„ä¼˜ç‚¹ï¼ŒæŒ‰ç…§ä¸€å®šçš„è§„åˆ™é€‰æ‹©å…¶ä¸­è¡¨ç°æœ€ä¼˜ç§€çš„ç»“æœä½œä¸º åŒå‘æœ€å¤§åŒ¹é…æ³• çš„ç»“æœã€‚\nè§£é‡Š ä» æ­£å‘æœ€å¤§åŒ¹é…æ³• å’Œ åå‘æœ€å¤§åŒ¹é…æ³• çš„ç»“æœä¸­é€‰æ‹©æœ€æ»¡è¶³ä¸­æ–‡åˆ†è¯åŸåˆ™çš„ä¸€ä¸ªåˆ†è¯ç»“æœã€‚\nä¸­æ–‡åˆ†è¯åŸåˆ™ åˆ†è¯ç²’åº¦ä»¥å¤§ä¸ºæœ€ä½³ï¼ˆæœ€å¤§åŒ–å¹³å‡è¯è¯­é•¿åº¦ï¼‰ åˆ†è¯çš„ç»“æœé¢—ç²’åº¦ï¼ˆå•ä¸ªè¯æ‰€åŒ…å«çš„å­—ç¬¦é•¿åº¦ï¼‰è¶Šå¤§è¶Šå¥½ã€‚\nåŒæ ·æ˜¯ åŒ—äº¬å¤§å­¦ å¯ä»¥åˆ†æˆ åŒ—äº¬ / å¤§å­¦ æˆ–è€… åŒ—äº¬å¤§å­¦ï¼Œåˆ™åè€…æ›´ä¼˜ï¼Œåè€…åŒ…å«çš„ä¿¡æ¯æ›´åŠ ç‰¹å®šå’Œæ˜ç¡®ã€‚\néè¯å…¸è¯è¶Šå°‘è¶Šä½³ï¼Œå•å­—å­—å…¸è¯æ•°è¶Šå°‘è¶Š\u0008ä½³ éè¯å…¸è¯çš„å‡ºç°è¯´æ˜å‡ºç°äº† OOV (Out Of Vocabulary) é—®é¢˜ï¼Œå­—å…¸è¶³å¤Ÿå¤§çš„æƒ…å†µä¸‹å‡ºç° OOVï¼Œ è¯´æ˜åˆ†è¯ç»“æœä¸ä½³ã€‚ç±»ä¼¼çš„ï¼Œåˆ†è¯ç»“æœå¤§é‡å‡ºç°å•ä¸ªå­—ï¼Œä¹Ÿæ˜¯æš—ç¤ºåˆ†è¯æ•ˆæœä¸ä½³ã€‚\n\u0008æ¯”å¦‚ æŠ€æœ¯å’ŒæœåŠ¡ å¯ä»¥è¢«åˆ†æˆ æŠ€æœ¯ / å’Œ / æœåŠ¡ æˆ–è€… æŠ€æœ¯ / å’Œæœ / åŠ¡ï¼Œåè€…ä¸­çš„ åŠ¡ å°±æ˜¯ä¸€ä¸ª OOVï¼Œå› ä¸ºä¸­æ–‡ä¸­ åŠ¡ ä¸èƒ½å•ç‹¬æˆè¯\næœ€å°åŒ–è¯è¯­é•¿åº¦çš„å˜åŒ–ç‡ åŒæ ·æ˜¯ ç ”ç©¶ç”Ÿå‘½èµ·æº å¯ä»¥\u0008è¢«åˆ†æˆ ç ”ç©¶ç”Ÿ / å‘½ / èµ·æº å’Œ ç ”ç©¶ / ç”Ÿå‘½ / èµ·æºï¼Œåè€… è¯è¯­é•¿åº¦çš„å˜åŒ–ç‡ æœ€å°ï¼Œå› æ­¤æ˜¯æ›´å¥½çš„åˆ†è¯ç»“æœã€‚\nå®ç° é€šè¿‡åˆ†åˆ«å®ç° æ­£å‘æœ€å¤§åŒ¹é…æ³• å’Œ åå‘æœ€å¤§åŒ¹é…æ³• æŒ‰ç…§ä¸Šè¿°åŸåˆ™å®ç°ä¸€ä¸ªåˆ¤åˆ«å™¨ï¼Œåˆ¤åˆ«æœ€ä¼˜ç»“æœï¼Œè¿”å›å³å¯ã€‚\nå‚è€ƒæ–‡çŒ® å…³äºMMSEGåˆ†è¯ç®—æ³• ä¸­æ–‡åˆ†è¯åŸºç¡€åŸåˆ™åŠæ­£å‘æœ€å¤§åŒ¹é…æ³•ã€é€†å‘æœ€å¤§åŒ¹é…æ³•ã€åŒå‘æœ€å¤§åŒ¹é…æ³•çš„åˆ†æ ","permalink":"https://blog.xiaoquankong.ai/zh/posts/creating-a-chinese-tokenizer-using-the-maximum-bidirectional-matching-method/","summary":"\u003cp\u003eç»“åˆ \u003ccode\u003eæ­£å‘æœ€å¤§åŒ¹é…æ³•\u003c/code\u003e å’Œ \u003ccode\u003eåå‘æœ€å¤§åŒ¹é…æ³•\u003c/code\u003e çš„ä¼˜ç‚¹ï¼ŒæŒ‰ç…§ä¸€å®šçš„è§„åˆ™é€‰æ‹©å…¶ä¸­è¡¨ç°æœ€ä¼˜ç§€çš„ç»“æœä½œä¸º \u003ccode\u003eåŒå‘æœ€å¤§åŒ¹é…æ³•\u003c/code\u003e çš„ç»“æœã€‚\u003c/p\u003e","title":"æ„å»ºä¸­æ–‡åˆ†è¯å™¨ - åŒå‘æœ€å¤§åŒ¹é…æ³•"},{"content":"TL;DR ä¸­æ–‡æ–‡æ¡ˆæ’ç‰ˆæŒ‡å—\nå‰è¨€ æ’ç‰ˆçš„é‡è¦æ€§ ä¸­æ–‡æ–‡æ¡ˆæ’ç‰ˆæ˜¯æ¯ä¸€ä¸ªç°ä»£äººæˆ–å¤šæˆ–å°‘éƒ½è¦è¿›è¡Œçš„èŒä¸šæ´»åŠ¨ã€‚ä½†æ˜¯æ–‡æ¡ˆæ’ç‰ˆä¸æ˜¯ä¸€ä¸ªå®¹æ˜“çš„å·¥ä½œï¼Œæœ‰å¾ˆå¤šäººä¸€ç›´éƒ½åœ¨ä½¿ç”¨é”™è¯¯çš„æ–¹å¼æ’ç‰ˆæ–‡æ¡ˆã€‚æ’ç‰ˆé”™è¯¯æˆ–è€…ä¸ç¾è§‚çš„æ–‡æ¡ˆå°†å½±å“æ–‡æ¡ˆçš„å®£ä¼ å’Œä¼ æ’­æ•ˆæœï¼Œå°¤å…¶æ˜¯ä½ çš„ç”³è¯·è¡¨ã€ç®€å†ã€ä¸ªäººä»‹ç»ç­‰ï¼Œå½±å“æ·±è¿œï¼\nç¬¦å·çº¦å®š ä¸ºäº†è®©ç©ºæ ¼æ›´å®¹æ˜“è¢«è¯†åˆ«å‡ºæ¥ï¼Œæœ¬æ–‡ä½™ä¸‹å†…å®¹ä¸­å°†ä½¿ç”¨â˜ (U+2610 BALLOT BOXï¼ˆæ–¹æ ¼ï¼‰) è¡¨ç¤ºç©ºæ ¼\nç‰ˆæƒç›¸å…³ æœ¬æ–‡ä¸­çš„å¤šæ•°å†…å®¹éƒ½æ˜¯åŸºäºå‚è€ƒæ–‡çŒ®çš„è¡ç”Ÿå’Œå†åˆ›é€ ï¼Œç‰¹æ­¤ç”³æ˜ï¼\nç©ºæ ¼çš„ä½¿ç”¨ ã€Œç‚ºä»€éº¼ä½ å€‘å°±æ˜¯ä¸èƒ½åŠ å€‹ç©ºæ ¼å‘¢ï¼Ÿã€\nby https://github.com/vinta/pangu.js\nä¸­è‹±æ–‡ä¹‹é–“éœ€è¦å¢åŠ ç©ºæ ¼ æ­£ç¡®çš„åšæ³• æ’ç‰ˆæ•ˆæœï¼š\nåœ¨ LeanCloud ä¸Šï¼Œæ•°æ®å­˜å‚¨æ˜¯å›´ç»• AVObject è¿›è¡Œçš„ã€‚\næ’ç‰ˆæ–¹æ¡ˆï¼š\nåœ¨â˜LeanCloudâ˜ä¸Šï¼Œæ•°æ®å­˜å‚¨æ˜¯å›´ç»•â˜AVObjectâ˜è¿›è¡Œçš„ã€‚\né”™è¯¯çš„åšæ³• åœ¨LeanCloudä¸Šï¼Œæ•°æ®å­˜å‚¨æ˜¯å›´ç»•AVObjectè¿›è¡Œçš„ã€‚\nåœ¨ LeanCloudä¸Šï¼Œæ•°æ®å­˜å‚¨æ˜¯å›´ç»•AVObject è¿›è¡Œçš„ã€‚\nä¾‹å¤–æƒ…å†µ ä¾‹å¦‚ã€Œè±†ç“£FMã€ä¹‹ç±»çš„äº§å“åç§°ç­‰ä¸“æœ‰åè¯ï¼ŒæŒ‰ç…§äº§å“å®˜æ–¹å®šä¹‰çš„æ ¼å¼ä¹¦å†™ã€‚\nä¸­æ–‡ä¸æ•°å­—ä¹‹é—´éœ€è¦å¢åŠ ç©ºæ ¼ æ­£ç¡®çš„åšæ³• ä»Šå¤©å‡ºå»ä¹°èœèŠ±äº† 5000 å…ƒã€‚\né”™è¯¯çš„åšæ³• ä»Šå¤©å‡ºå»ä¹°èœèŠ±äº†5000å…ƒã€‚\nä»Šå¤©å‡ºå»ä¹°èœèŠ±äº† 5000å…ƒã€‚\næ•°å­—å’Œå•ä½ä¹‹é—´éœ€è¦å¢åŠ ç©ºæ ¼ NOTEï¼š å¾ˆå…¸å‹çš„é”™è¯¯çš„ï¼:(\næ­£ç¡®çš„åšæ³• æˆ‘å®¶çš„å…‰çº¤å…¥å±‹å¸¦å®½æœ‰ 10 Gbpsï¼ŒSSD ä¸€å…±æœ‰ 20 TBã€‚\né”™è¯¯çš„åšæ³• æˆ‘å®¶çš„å…‰çº¤å…¥å±‹å¸¦å®½æœ‰ 10Gbpsï¼ŒSSD ä¸€å…±æœ‰ 20TBã€‚\nä¾‹å¤–æƒ…å†µ åº¦ï¼ç™¾åˆ†æ¯”èˆ‡æ•¸å­—ä¹‹é–“ä¸éœ€è¦å¢åŠ ç©ºæ ¼\næ¸©åº¦ æ­£ç¡®çš„åšæ³• ä»Šå¤©æ˜¯ 233Â° çš„é«˜æº«ã€‚\né”™è¯¯çš„åšæ³• ä»Šå¤©æ˜¯ 233 Â° çš„é«˜æº«ã€‚\nç™¾åˆ†æ¯” æ­£ç¡®çš„åšæ³• æ–° MacBook Pro æœ‰ 15% çš„ CPU æ€§èƒ½æå‡ã€‚\né”™è¯¯çš„åšæ³• æ–° MacBook Pro æœ‰ 15 % çš„ CPU æ€§èƒ½æå‡ã€‚\nå…¨å½¢ï¼ˆå…¨è§’ï¼‰æ¨™é»èˆ‡å…¶ä»–å­—ç¬¦ä¹‹é–“ä¸åŠ ç©ºæ ¼ æ­£ç¡®çš„åšæ³• å‰›å‰›è²·äº†ä¸€éƒ¨ iPhoneï¼Œå¥½é–‹å¿ƒï¼\né”™è¯¯çš„åšæ³• å‰›å‰›è²·äº†ä¸€éƒ¨ iPhone ï¼Œå¥½é–‹å¿ƒï¼\nå…¶ä»–éç©ºæ ¼ç›¸å…³çš„æ’ç‰ˆé—®é¢˜ å¸¸è§é”™è¯¯ç±» ä¸­æ–‡ç¯å¢ƒä½¿ç”¨åŠè§’ç¬¦å·æ˜¯é”™è¯¯çš„ï¼ æ­£ç¡®çš„åšæ³• æ’ç‰ˆæ•ˆæœï¼š\nå—¨ï¼ä½ çŸ¥é“å˜›ï¼Ÿä»Šå¤©å‰å°çš„å°å¦¹è·Ÿæˆ‘èªªã€Œå–µã€äº†å“ï¼\næ’ç‰ˆæ–¹æ¡ˆï¼š\nå—¨ï¼ä½ çŸ¥é“å˜›ï¼Ÿä»Šå¤©å‰å°çš„å°å¦¹è·Ÿæˆ‘èªªã€Œå–µã€äº†å“ï¼\nNOTEï¼š ä¸Šæ–‡æ–‡å­—é—´æ²¡æœ‰â˜ï¼Œä¹Ÿå°±æ˜¯æ²¡æœ‰ç©ºæ ¼ã€‚\né”™è¯¯çš„åšæ³• æ’ç‰ˆæ•ˆæœï¼š\nå—¨! ä½ çŸ¥é“å˜›? ä»Šå¤©å‰å°çš„å°å¦¹è·Ÿæˆ‘èªª \u0026ldquo;å–µ\u0026rdquo; äº†å“!\næ’ç‰ˆæ–¹æ¡ˆï¼š\nå—¨!â˜ä½ çŸ¥é“å˜›?â˜ä»Šå¤©å‰å°çš„å°å¦¹è·Ÿæˆ‘èªªâ˜\u0026quot;å–µ\u0026quot;â˜äº†å“!\nNOTEï¼š è¿™ç§é”™è¯¯è¿˜æŒºå¸¸è§çš„ï¼\nå°ˆæœ‰åè©ä½¿ç”¨æ­£ç¢ºçš„å¤§å°å¯« æ­£ç¡®çš„åšæ³• æˆ‘å€‘çš„å®¢æˆ¶æœ‰ GitHubã€Foursquareã€Microsoft Corporationã€Googleã€Facebook, Inc.ã€‚\né”™è¯¯çš„åšæ³• æˆ‘å€‘çš„å®¢æˆ¶æœ‰ githubã€foursquareã€microsoft corporationã€googleã€facebook, inc.ã€‚\nNOTEï¼š çœ‹å®Œä¹‹åï¼Œå¤šæ•°äººéƒ½æœ‰æƒ³ç«‹å³æŠŠé¦–å­—æ¯æ”¹æˆå¤§å†™çš„å†²åŠ¨ï¼ŒçœŸçš„ï¼\nä¸è¦ä½¿ç”¨ä¸åœ°é“çš„ç¸®å¯« æ­£ç¡®çš„åšæ³• æˆ‘å€‘éœ€è¦ä¸€ä½ç†Ÿæ‚‰ JavaScriptã€HTML5ï¼Œè‡³å°‘ç†è§£ä¸€ç§æ¡†æ¶ï¼ˆå¦‚ Backbone.jsã€AngularJSã€React ç­‰ï¼‰çš„å‰ç«¯é–‹ç™¼è€…ã€‚\né”™è¯¯çš„åšæ³• æˆ‘å€‘éœ€è¦ä¸€ä½ç†Ÿæ‚‰ Jsã€h5ï¼Œè‡³å°‘ç†è§£ä¸€ç§æ¡†æ¶ï¼ˆå¦‚ backboneã€angularã€RJS ç­‰ï¼‰çš„ FEDã€‚\nNOTEï¼š é”™è¯¯åˆ°ç®€ç›´è¾£çœ¼ç›ï¼åƒä¸‡ä¸è¦å‡ºç°åœ¨ä½ çš„ç®€å†é‡Œï¼ŒçœŸçš„æ‹œæ‰˜äº†ğŸ™ï¼\nç•¥æœ‰äº‰è®®ä½†æˆ‘ï¼ˆä½œè€…ä¸ªäººï¼‰è§‰å¾—æ­£ç¡®çš„å¸¸è§é”™è¯¯ç±» é“¾æ¥ä¹‹é—´å¢åŠ ç©ºæ ¼ æ­£ç¡®çš„åšæ³• è®¿é—®æˆ‘ä»¬ç½‘ç«™çš„æœ€æ–°åŠ¨æ€ï¼Œè¯· ç‚¹å‡»è¿™é‡Œ è¿›è¡Œè®¢é˜…ï¼\né”™è¯¯çš„åšæ³• è®¿é—®æˆ‘ä»¬ç½‘ç«™çš„æœ€æ–°åŠ¨æ€ï¼Œè¯·ç‚¹å‡»è¿™é‡Œè¿›è¡Œè®¢é˜…ï¼\nNOTEï¼š é“¾æ¥æ–‡å­—å’Œæ™®é€šæ–‡å­—æŒ¤åœ¨ä¸€èµ·çš„æ„Ÿè§‰ï¼Œè®©äººè§‰å¾—å¾ˆä¸šä½™ï¼\nç®€ä½“ä¸­æ–‡ä½¿ç”¨ç›´è§’å¼•å·ï¼ˆè¿™ä¸ªè¿˜çœŸæ˜¯æŒºäº‰è®®çš„ï¼‰ æ­£ç¡®çš„åšæ³• ã€Œè€å¸ˆï¼Œã€æœ‰æ¡ä¸ç´Šã€çš„ã€ç´Šã€æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿã€\nNOTEï¼š æ„Ÿè§‰æ­£ä½“å¾ˆå¸…ï¼Œå¾ˆæ­£å¼ï¼\né”™è¯¯çš„åšæ³• â€œè€å¸ˆï¼Œâ€˜æœ‰æ¡ä¸ç´Šâ€™çš„â€˜ç´Šâ€™æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿâ€\næ€ä¹ˆè¾“å…¥ç›´è§’å¼•å·ï¼ˆi.e.ã€Œã€ã€ã€ã€ã€ã€ï¼‰ è§çŸ¥ä¹ï¼šå¦‚ä½•è¾“å…¥ç›´è§’å¼•å·ï¼ˆã€Œã€å’Œã€ã€ ï¼‰ï¼Ÿ\nä¸å¸¸è§é”™è¯¯ç±» æ—¢ç„¶æ˜¯ä¸å¸¸è§çš„é”™è¯¯ï¼Œé‚£ä¹ˆæœ¬æ–‡å°±ä¸å†è®¨è®ºäº†ï¼Œè¯»è€…è¿˜æ˜¯å»çœ‹é™„åœ¨æ–‡æœ«çš„å‚è€ƒæ–‡çŒ®å§ï¼Œé‡Œé¢ä»€ä¹ˆéƒ½æœ‰ï¼\nã€Œç›¤å¤ä¹‹ç™½ã€æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ æ‰€æœ‰çš„ä¸­æ–‡å­—å’ŒåŠå½¢çš„è‹±æ–‡ã€æ•¸å­—ã€ç¬¦è™Ÿä¹‹é–“åº”è¯¥å­˜åœ¨çš„ç©ºç™½ï¼Œè¢«æ¼¢å­¸å®¶ç¨±ç‚ºã€Œç›¤å¤ä¹‹ç™½ã€ï¼Œå› ç‚ºå®ƒåŠˆé–‹äº†å…¨å½¢å­—å’ŒåŠå½¢å­—ä¹‹é–“çš„æ··æ²Œã€‚\nå¦æœ‰ç ”ç©¶é¡¯ç¤ºï¼Œæ‰“å­—çš„æ™‚å€™ä¸å–œæ­¡åœ¨ä¸­æ–‡å’Œè‹±æ–‡ä¹‹é–“åŠ ç©ºæ ¼çš„äººï¼Œæ„Ÿæƒ…è·¯éƒ½èµ°å¾—å¾ˆè¾›è‹¦ï¼Œæœ‰ä¸ƒæˆçš„æ¯”ä¾‹æœƒåœ¨ 34 æ­²çš„æ™‚å€™è·Ÿè‡ªå·±ä¸æ„›çš„äººçµå©šï¼Œè€Œå…¶é¤˜ä¸‰æˆçš„äººæœ€å¾Œåªèƒ½æŠŠéºç”¢ç•™çµ¦è‡ªå·±çš„è²“ã€‚ç•¢ç«Ÿæ„›æƒ…è·Ÿæ›¸å¯«éƒ½éœ€è¦é©æ™‚åœ°ç•™ç™½ã€‚\nèˆ‡å¤§å®¶å…±å‹‰ä¹‹ã€‚\nby https://github.com/vinta/pangu.js\nå·¥å…· ä»“åº“ è¯­è¨€ vinta/paranoid-auto-spacing JavaScript huei90/pangu.node Node.js huacnlee/auto-correct Ruby sparanoid/space-lover PHP (WordPress) nauxliu/auto-correct PHP ricoa/copywriting-correct PHP hotoo/pangu.vim Vim sparanoid/grunt-auto-spacing Node.js (Grunt) hjiang/scripts/add-space-between-latin-and-cjk Python è°åœ¨è¿™æ ·åšï¼Ÿ ç½‘ç«™ æ–‡æ¡ˆ UGC Apple ä¸­å›½ Yes N/A Apple é¦™æ¸¯ Yes N/A Apple å°æ¹¾ Yes N/A Microsoft ä¸­å›½ Yes N/A Microsoft é¦™æ¸¯ Yes N/A Microsoft å°æ¹¾ Yes N/A LeanCloud Yes N/A çŸ¥ä¹ Yes éƒ¨åˆ†ç”¨æˆ·è¾¾æˆ V2EX Yes Yes SegmentFault Yes éƒ¨åˆ†ç”¨æˆ·è¾¾æˆ Apple4us Yes N/A è±Œè±†èš Yes N/A Ruby China Yes æ ‡é¢˜è¾¾æˆ PHPHub Yes æ ‡é¢˜è¾¾æˆ å°‘æ•°æ´¾ Yes N/A blog.xiaoquankong.ai (æœ¬ç«™å•¦) Yes ä½œè€…è¿˜åœ¨åŠªåŠ›æ¨è¿›ä¸­ :) å‚è€ƒæ–‡çŒ® ä¸­æ–‡æ–‡æ¡ˆæ’ç‰ˆæŒ‡åŒ— ","permalink":"https://blog.xiaoquankong.ai/zh/posts/chinese-document-typesetting-specification-spacing-of-pangu/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e ä¸­æ–‡æ–‡æ¡ˆæ’ç‰ˆæŒ‡å—\u003c/p\u003e","title":"ã€Œç›¤å¤ä¹‹ç™½ã€"},{"content":"TL;DR ä¸€äº›å…³äº Chinese Spelling Check Task æ¯”è¾ƒé‡è¦çš„ä¼šè®®å’Œèµ„æ–™çš„æ•´ç†å’Œæ±‡æ€»ã€‚\né‡è¦çš„ç›¸å…³ä¼šè®® ACL ACLCLP ACLCLP æ˜¯ Association for Computational Linguistics and Chinese Language Processing çš„ç¼©å†™ã€‚\næ•°æ®é›† Chinese Grammatical Error Diagnosis NLPTEA 2016 Shared Task: http://ir.itc.ntnu.edu.tw/lre/nlptea16cged.htm NLPTEA 2015 Shared Task: http://ir.itc.ntnu.edu.tw/lre/nlptea15cged.htm NLPTEA 2014 Shared Task: http://ir.itc.ntnu.edu.tw/lre/nlptea14cfl.htm\nChinese Spelling Check SIGHAN 2015 Bake-off: http://ir.itc.ntnu.edu.tw/lre/sighan8csc.html CLP 2014 Bake-off: http://ir.itc.ntnu.edu.tw/lre/clp14csc.html SIGHAN 2013 Bake-off: http://ir.itc.ntnu.edu.tw/lre/sighan7csc.html\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/chinese-spelling-check-task-related-materials/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e ä¸€äº›å…³äº Chinese Spelling Check Task æ¯”è¾ƒé‡è¦çš„ä¼šè®®å’Œèµ„æ–™çš„æ•´ç†å’Œæ±‡æ€»ã€‚\u003c/p\u003e","title":"Chinese Spelling Check Task: èµ„æ–™æ±‡æ€»"},{"content":" TL;DR åœ¨å³å°†å‘å¸ƒï¼ˆæœ¬æ–‡ç« å†™äº 2018-01-06ï¼‰çš„ TenserFlow v1.5 ä¸­ï¼ŒTensorFlowå°†ä¼šå¼•å…¥ä¸€ä¸ªé‡è¦çš„ User-friendly ç‰¹æ€§ï¼šEager Execution. æœ¬æ–‡ç« å°†å±•ç¤º Eager Execution å¼•å…¥çš„ä¸€äº›æ–°çš„ç‰¹æ€§ã€‚\nå®‰è£… TensorFlow å¯¹åº”çš„ç‰ˆæœ¬ å› ä¸º TensorFlow æ­£å¼ç‰ˆï¼ˆå†™ä½œæ—¶é—´ 2018-01-06ï¼Œæ­¤æ—¶çš„æ­£å¼ç‰ˆæœ¬ä¸º1.4.1ï¼‰ä¸­è¿˜ä¸åŒ…å«æ­¤åŠŸèƒ½ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å®‰è£… TensorFlow nightly build ç‰ˆæœ¬ã€‚\npip install tf-nightly # or tf-nightly-gpu if you have GPU ç‰¹æ€§æ¢ç´¢ Eager execution åœ¨å¼€å¯è¿™ä¸ªæ¨¡å¼åï¼ŒTensorFlow å°†ä¼šç«‹å³æ‰§è¡Œæ“ä½œï¼Œè¿”å›ç»“æœç»™ Pythonï¼Œè€Œä¸éœ€è¦ä½¿ç”¨ Session.run(), ä¾‹å¦‚ï¼š\nimport tensorflow as tf import tensorflow.contrib.eager as tfe tfe.enable_eager_execution() x = [[2]] m = tf.matmul(x, x) print(m) ç‚¹å‡»è¿™é‡Œ launch binder ï¼Œåœ¨çº¿è¿è¡Œè¿™ä¸ªä¾‹å­\nä½ ä¼šå¾—åˆ°å¦‚ä¸‹æ˜¾ç¤ºï¼š\ntf.Tensor([[4]], shape=(1, 1), dtype=int32) Dynamic models åœ¨ä¸å…·å¤‡åŠ¨æ€æ¨¡å‹çš„èƒ½åŠ›å‰ï¼ŒTensorFlow ä¸­çš„æ¯ä¸€ä¸ª operator éƒ½éœ€è¦æ˜ç¡®å®šå£°æ˜å’Œå®šä¹‰ã€‚åœ¨å…·å¤‡çš„äº†åŠ¨æ€æ¨¡å‹èƒ½åŠ›ä¹‹åï¼ŒTensorFlow å…·å¤‡äº†ä»æ“ä½œä¸­æ¨å¯¼æ“ä½œæ•°ç±»å‹çš„èƒ½åŠ›ï¼Œè®©å¤æ‚çš„åŠ¨æ€æ¨¡å‹å®¹æ˜“å®ç°ï¼Œä¾‹å¦‚ï¼š\nimport tensorflow as tf import tensorflow.contrib.eager as tfe tfe.enable_eager_execution() a = tf.constant(12) counter = 0 while not tf.equal(a, 1): if tf.equal(a % 2, 0): a = a / 2 else: a = 3 * a + 1 print(a) ç‚¹å‡»è¿™é‡Œ launch binder ï¼Œåœ¨çº¿è¿è¡Œè¿™ä¸ªä¾‹å­\nå¦‚æœæ²¡æœ‰å¯ç”¨ Eager Execution ä¼šæ˜¾ç¤ºå¦‚ä¸‹é”™è¯¯ï¼š\nUsing a tf.Tensor as a Python bool is not allowed.\nåŸå› æ˜¯åœ¨ while not tf.equal(a, 1) å¤„ï¼Œå¦‚æœæ²¡æœ‰å¯åŠ¨ Eager Execution é‚£ä¹ˆè¿”å›çš„ç»“æœæ˜¯ tf.Tensor å¯¹è±¡ï¼Œå› ä¸ºè¿˜ä¸çŸ¥é“å…·ä½“çš„å€¼æ‰€ä»¥ä¸èƒ½è½¬æ¢æˆboolç±»å‹ã€‚\nGradients å¾—ç›Šäº Eager Execution ç«‹å³æ‰§è¡Œçš„ç‰¹æ€§ï¼ŒGradients ä¹Ÿå¯ä»¥ç«‹å³å¾—åˆ°ï¼Œè€Œä¸ç”¨ç­‰åˆ°è¿è¡Œæ—¶æ‰èƒ½çŸ¥é“ï¼Œä¾‹å­å¦‚ä¸‹ï¼š\nimport tensorflow as tf import tensorflow.contrib.eager as tfe tfe.enable_eager_execution() def square(x): return tf.multiply(x, x) grad = tfe.gradients_function(square) print(square(3.)) # è¾“å‡º [9.] print(grad(3.)) # è¾“å‡º [6.] ç‚¹å‡»è¿™é‡Œ launch binder ï¼Œåœ¨çº¿è¿è¡Œè¿™ä¸ªä¾‹å­\nè¾“å…¥çš„å…·ä½“æƒ…å†µå¦‚ä¸‹ï¼š\ntf.Tensor(9.0, shape=(), dtype=float32) [\u0026lt;tf.Tensor: id=11, shape=(), dtype=float32, numpy=6.0\u0026gt;] Building models å®˜æ–¹æ¨èåº”è¯¥ä½¿ç”¨ Python çš„ class æ¥ç»„ç»‡æ¨¡å‹ç»“æ„è€Œä¸æ˜¯ functionã€‚Eager Execution å¸¦æœ‰çš„ tfe.Network å°±æ˜¯è®¾è®¡ç”¨æ¥ä½œä¸ºæ¨¡å‹çš„çˆ¶ç±»çš„ï¼Œç»§æ‰¿è¿™ä¸ªç±»ä¹‹åå°±æ”¯æŒç½‘ç»œçš„å¥—åµŒï¼Œä¸‹é¢è¿™æ®µä»£ç æ˜¯å®˜æ–¹æ¨èçš„ç®€æ˜“ MNIST æ¨¡å‹çš„å‚è€ƒï¼š\nclass MNISTModel(tfe.Network): def __init__(self): super(MNISTModel, self).__init__() self.layer1 = self.track_layer(tf.layers.Dense(units=10)) self.layer2 = self.track_layer(tf.layers.Dense(units=10)) def call(self, input): \u0026#34;\u0026#34;\u0026#34;Actually runs the model.\u0026#34;\u0026#34;\u0026#34; result = self.layer1(input) result = self.layer2(result) return result å³ä½¿æ²¡æœ‰è®­ç»ƒï¼Œæˆ‘ä»¬ä¹Ÿèƒ½å¤Ÿç«‹å³è°ƒç”¨å®ƒå¹¶è§‚å¯Ÿè¾“å‡ºï¼š\n# Let\u0026#39;s make up a blank input image model = MNISTModel() batch = tf.zeros([1, 1, 784]) print(batch.shape) # (1, 1, 784) result = model(batch) print(result) # tf.Tensor([[[ 0. 0., ...., 0.]]], shape=(1, 1, 10), dtype=float32) è¿™é‡Œå¹¶ä¸éœ€è¦ä½¿ç”¨ placeholders æˆ–è€… sessionsã€‚å½“æˆ‘ä»¬ç¬¬ä¸€è¾“å…¥æ—¶ï¼Œæ¨¡å‹çš„å‚æ•°ä¼šè¢«è®¾å®šå¥½ã€‚\nä¸ºäº†è®­ç»ƒä»»ä½•æ¨¡å‹ï¼Œæˆ‘ä»¬éƒ½éœ€è¦ loss functionï¼Œcalculate gradients å’Œ optimizer å»ä¼˜åŒ–å‚æ•°ã€‚ loss function\ndef loss_function(model, x, y): y_ = model(x) return tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_) calculate gradients \u0026amp; optimizer\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001) for (x, y) in tfe.Iterator(dataset): grads = tfe.implicit_gradients(loss_function)(model, x, y) optimizer.apply_gradients(grads) ç‚¹å‡»è¿™é‡Œ launch binder ï¼Œåœ¨çº¿è¿è¡Œè¿™ä¸ªä¾‹å­\nå…¶ä»–ç‰¹æ€§ è¿˜æœ‰å…¶ä»–ç‰¹æ€§ï¼Œå¦‚ï¼š\nget the second derivative derivative under control flow Custom Gradients è¿™é‡Œå°±ä¸å†ä»‹ç»ï¼Œæ„Ÿå…´è¶£çš„å¯ä»¥å‚è€ƒå®˜æ–¹æ–‡æ¡£æˆ–è€…æœ¬æ–‡çš„å‚è€ƒæ–‡æ¡£ã€‚\nå‚è€ƒæ–‡æ¡£ Google Research Blog \u0026gt; Eager Execution: An imperative, define-by-run interface to TensorFlow ","permalink":"https://blog.xiaoquankong.ai/zh/posts/introduce-to-eager-execution-of-tensorflow/","summary":"\u003c!-- TODO: https://github.com/hexojs/hexo/issues/2150 caused can not use GitHub badge --\u003e\n\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e åœ¨å³å°†å‘å¸ƒï¼ˆæœ¬æ–‡ç« å†™äº 2018-01-06ï¼‰çš„ TenserFlow v1.5 ä¸­ï¼ŒTensorFlowå°†ä¼šå¼•å…¥ä¸€ä¸ªé‡è¦çš„ User-friendly ç‰¹æ€§ï¼šEager Execution. æœ¬æ–‡ç« å°†å±•ç¤º Eager Execution å¼•å…¥çš„ä¸€äº›æ–°çš„ç‰¹æ€§ã€‚\u003c/p\u003e","title":"TenserFlow æ–°ç‰¹æ€§ï¼šEager Execution"},{"content":"TL;DR å›¾å½¢æ¸¸æˆï¼ˆæ¯”å¦‚å¦å…‹å¤§æˆ˜ï¼‰å¦‚æœè¦å®ç°æ™ºèƒ½Agentï¼ˆAKA ç”µè„‘ç©å®¶ï¼‰çš„è¯ï¼Œç›®å‰æœ€ä½³çš„æ–¹æ¡ˆå°±æ˜¯Reinforcement Learning (ç®€ç§° RL ;ä¸­æ–‡ï¼šå¢å¼ºå­¦ä¹ )ã€‚ æœ¬æ–‡è®°å½•äº†æˆ‘å’ŒReinforcement Learningçš„ç¬¬ä¸€æ¬¡äº¤æ‰‹ï¼Œå°†å¸¦ä½ äº†è§£è¿™ä½åæ‰¬å››æµ·å´åˆç¥ç§˜è«æµ‹çš„å¯¹æ‰‹ã€‚:)\nèƒŒæ™¯ å…¬å¸ä¸¾åŠHackthonï¼ˆä¸­å›½ï¼šé»‘å®¢æ¾ \u0026lt;- æ¥è‡ªç»´åŸºç™¾ç§‘çš„ç¿»è¯‘ï¼‰ï¼Œå…¶ä¸­æœ‰ä¸€é“é¢˜æ˜¯å®ç°å¦å…‹å¤§æˆ˜çš„ç©å®¶ç¨‹åºã€‚åœ¨åˆ«äººæ™®éä½¿ç”¨äººå·¥ç­–ç•¥çš„æƒ…å†µä¸‹ï¼Œè€ƒè™‘åˆ°æˆ‘ä»¬å›¢é˜Ÿäººå°‘ï¼ˆç²¾ç¡®çš„è®²åªæœ‰æˆ‘ä¸€äººä¼šå†™ç¨‹åºï¼Œå…¶ä»–å›¢é˜Ÿèµ·ç ä¸‰ä¸ªç¨‹åºå‘˜ï¼‰ï¼Œæ‰€ä»¥åœ¨äººå·¥ç­–ç•¥è¿™æ¡è·¯ä¸Šè‚¯å®šæ˜¯éå¸¸çš„åƒäºï¼Œæ‰€ä»¥ä¸å¦‚å¦è¾Ÿè¹Šå¾„ï¼Œæ‹¼æä¸€æŠŠï¼ˆåæ­£ä¹ŸåŸºæœ¬å‡ºä¸äº†åˆèµ›äº†)ã€‚äºæ˜¯æˆ‘ä»¬é€‰æ‹©äº†è®©æœºå™¨å­¦ä¹ çš„æ–¹æ¡ˆã€‚äºæ˜¯ å°±æˆäº†ç›®æ ‡ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä¹Ÿåªæ˜¯å¬è¿‡RLçš„å¤§åï¼Œç°åœ¨è¦ä½¿ç”¨RLï¼Œå†…å¿ƒæ˜¯æ—¢å…´å¥‹åˆç´§å¼ ã€‚\nReinforcement Learning æ¦‚å¿µ ä¸ºäº†æ›´åŠ å®¹æ˜“ç†è§£ï¼Œæˆ‘ä»¬å°†å¼•å…¥å¦å…‹å¤§æˆ˜çš„ä¾‹å­æ¥è¾…åŠ©è®²è§£ã€‚æ€»çš„æ¥è¯´RLæ¨¡å‹å°†ç°å®ä¸–ç•Œçš„é—®é¢˜æŠ½è±¡æˆä¸¤ç±»å¯¹è±¡çš„äº¤äº’ï¼šEnviromentå’ŒAgentï¼Œå¯¹å¦å…‹å¤§æˆ˜è€Œè¨€ï¼Œæ¸¸æˆå°±æ˜¯Enviromentï¼Œè€Œæ¸¸æˆç©å®¶å°±æ˜¯Agentã€‚\nEnviromentæä¾›observationï¼šè¿™æ˜¯Agentå¯¹å¤–ç•Œç¯å¢ƒçš„è§‚å¯Ÿï¼Œå¦å…‹å¤§æˆ˜ä¸­ï¼Œæ¸¸æˆçš„å›¾å½¢ç•Œé¢å°±æ˜¯Agent(æ¸¸æˆç©å®¶)å¯¹Enviromentï¼ˆæ¸¸æˆï¼‰çš„observationã€‚Agentä½¿ç”¨è‡ªå·±çš„é€»è¾‘ï¼Œæ ¹æ®å¯¹observationçš„ç†è§£ï¼Œç»™å‡ºä¸€ä¸ªactionï¼šè¿™è¡¨ç¤ºå¯¹å¤–ç•Œç¯å¢ƒçš„ä¸€ä¸ªæ“ä½œæˆ–è€…åé¦ˆï¼Œå¦å…‹å¤§æˆ˜ä¸­æ¸¸æˆç©å®¶çš„æ“ä½œå°±æ˜¯actionã€‚actionåœ¨æ¯ä¸ªstepä¸­ä¼šè¢«å‘é€ç»™Enviroment,Environmentåˆ™ä¼šè¿”å›æ–°çš„observationå’Œrewardã€‚rewardè¡¨ç¤ºçš„æ˜¯å½“å‰æƒ…å†µä¸‹Environmentå¯¹acitonçš„åé¦ˆï¼šæ•°å€¼å¯èƒ½æ­£æ•°ä¹Ÿå¯èƒ½è´Ÿæ•°ä¹Ÿå¯èƒ½æ˜¯é›¶ï¼Œå¦å…‹å¤§æˆ˜ä¸­å¦å…‹è¢«å‡»æ¯ã€å‡»æ¯æ•Œæ–¹å¦å…‹ã€è·å–è£…å¤‡æˆ–è€…æ——å¸œç­‰ç›´æ¥å¾—åˆ†æˆ–è€…å¤±åˆ†éƒ½ç®—æ˜¯rewardã€‚ç„¶åAgentæ ¹æ®æ–°çš„observationç»™å‡ºæ–°çš„action,å¦‚æ­¤å¾ªç¯å¾€å¤ã€‚èªæ˜çš„ç®—æ³•èƒ½åœ¨observationã€actionå’Œrewardä¸­å‘ç°å…³ç³»ï¼Œä½¿å¾—æ¯ä¸€æ¬¡ç»™å‡ºçš„actionéƒ½èƒ½å¾—åˆ°æœ€å¤§æœŸæœ›çš„rewardã€‚\nç‰¹ç‚¹ ä¸Supervised Learningä¸åŒçš„æ˜¯ï¼ŒReinforcement Learningè¦è§£å†³çš„é—®é¢˜æ˜¯å­˜åœ¨reward delayç°è±¡çš„ï¼Œä¹Ÿå°±æ˜¯è¯´Reinforcement Learningä¼šè€ƒè™‘å…¨å±€æœ€ä¼˜ï¼Œè€Œä¸æ˜¯å½“å‰è¿™ä¸€æ­¥æ˜¯æœ€ä¼˜çš„ï¼Œé¿å…â€œèµ¢äº†æˆ˜å½¹ï¼Œè¾“äº†æˆ˜äº‰â€è¿™ç§ç°è±¡ã€‚å¦å…‹å¤§æˆ˜ä¸­çš„ä¾‹å­å°±æ˜¯é«˜çº§ç©å®¶å¯èƒ½ä¼šé€‰æ‹©ä¸€ç§ç­–ç•¥ï¼šå³ä½¿ä¸åœçš„è¢«æ”»å‡»ï¼Œä»–çš„å¦å…‹ä¸é€‰æ‹©èº²é¿ç‚®å¼¹è€Œæ˜¯é€‰æ‹©æ‰¿å—ç‚®ç«çš„åŒæ—¶æŒç»­ä¸æ–­çš„æ”»å‡»ä½ çš„åŸºåœ°çš„å¤–å¢™ã€‚åªçœ‹ä¸€æ­¥æ“ä½œè€Œè¨€ï¼Œè¿™æ ·çš„è¡ŒåŠ¨æ˜¯å¤±è´¥çš„ï¼Œå› ä¸ºå·±æ–¹çš„æŸä¸€è¾†å¦å…‹è¢«å‡»æ¯ï¼Œä½†ä»é•¿è¿œçš„è§’åº¦æ¥çœ‹ï¼Œä½ èƒ½åœ¨æœ€åä¸€è¾†å·±æ–¹å¦å…‹è¢«å‡»æ¯å‰æˆåŠŸçš„å‡»æ¯å¯¹æ–¹çš„åŸºåœ°ã€‚\nQ-learning ç®—æ³• æˆ‘ä»¬å°†ä»‹ç»Reinforcement Learningä¸­æ¯”è¾ƒå®¹æ˜“ç†è§£çš„ç®—æ³•ï¼šQ-learning\nQ-learning ç®€ä»‹ TODO\nå®éªŒç¯å¢ƒ æˆ‘ä»¬å°†å¼•å…¥ä¸€ä¸ªç®€å•çš„ç¯å¢ƒï¼šä¸€ä¸ªæˆ¿å­ã€‚è¿™ä¸ªæˆ¿å­ç”±5ä¸ªæˆ¿é—´æ„æˆï¼ˆç¼–å·ï¼š0 - 4ï¼‰ï¼Œè¿ä¸Šæˆ¿å­å¤–çš„ç©ºé—´ï¼ˆç¼–å·ï¼š5ï¼‰ï¼Œå…±å…­ä¸ªçŠ¶æ€ã€‚æˆ¿é—´ä¹‹é—´ä¸æˆ¿é—´å’Œæˆ·å¤–ç©ºé—´ä¹‹é—´å¯èƒ½å­˜åœ¨é—¨ï¼Œä¹Ÿå°±æ˜¯ç›¸äº’è”é€šã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\næˆ‘ä»¬æ ¹æ®æˆ¿é—´çš„è”é€šçŠ¶æ€ï¼Œå°†ä¸Šè¿°çš„ç‰©ç†æˆ¿é—´å›¾æŠ½è±¡ï¼Œå°†æ¯ä¸ªæˆ¿é—´æŠ½è±¡æˆä¸€ä¸ªèŠ‚ç‚¹(Node)æˆ–è€…çŠ¶æ€ï¼ˆstate),æˆ¿å­ä¹‹é—´å­˜åœ¨è”é€šå…³ç³»çš„åˆ™ç”¨ä¸€ä¸ªæœ‰å‘è¾¹è¡¨ç¤ºï¼ˆå› ä¸ºæˆ¿é—¨æ˜¯åŒå‘è”é€šï¼Œæ‰€ä»¥æ¯ä¸ªæˆ¿é—¨å¯¹åº”ä¸¤ä¸ªç›¸å‘çš„æœ‰å‘è¾¹ï¼‰ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\nåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°† agent ï¼ˆæŠ½è±¡æ¦‚å¿µï¼‰ ä»æˆ¿é—´é‡Œç§»åŠ¨åˆ°æˆ·å¤–ç©ºé—´ã€‚Q-learning çš„ç›®æ ‡æ˜¯åˆ°è¾¾ reward æœ€é«˜çš„çŠ¶æ€ï¼Œè€Œåœ¨æœ¬ä¾‹ä¸­ï¼ŒçŠ¶æ€ 5 å°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„ç›®æ ‡çŠ¶æ€ï¼ˆä¹Ÿç§°æœ€ç»ˆçŠ¶æ€ï¼‰ï¼ŒQ-learning åˆ°è¾¾ç›®æ ‡çŠ¶æ€åå°±ä¼šæ°¸ä¹…ç•™åœ¨ç›®æ ‡çŠ¶æ€ï¼Œå› æ­¤æˆ‘ä»¬ç»™çŠ¶æ€ 5 å¢åŠ ä¸€ä¸ªæŒ‡å‘è‡ªå·±çš„æœ‰å‘è¾¹ï¼ˆå¦‚ä¸Šå›¾ç¤ºï¼‰ã€‚è¿™ç§ç›®æ ‡æˆ–è€…çŠ¶æ€ç§°ä¹‹ä¸º absorbing goal æˆ–è€… absorbing stateã€‚\nä¸ºäº†è®©çŠ¶æ€ 5 æˆä¸ºç›®æ ‡çŠ¶æ€ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰æŒ‡å‘çŠ¶æ€ 5 çš„æœ‰å‘è¾¹å…¨éƒ¨èµ‹å€¼ reward=100 ï¼Œé™¤æ­¤ä¹‹å¤–çš„è¾¹å…¨éƒ¨èµ‹å€¼ reward=0 ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\nå‡è®¾æœ¬ä¾‹å­ä¸­çš„ agent æ˜¯ä¸€ä¸ªç¬¨ç¬¨çš„è™šæ‹Ÿæœºå™¨äººï¼Œå®ƒä¼šä»ä»¥å‰çš„ç»éªŒä¸­å­¦ä¹ çŸ¥è¯†ï¼Œå®ƒèƒ½å¤Ÿä»ä¸€ä¸ªæˆ¿é—´åˆ°å¦ä¸€ä¸ªæˆ¿é—´ï¼Œä½†å®ƒä¸çŸ¥é“æˆ¿é—´çš„æƒ…å†µä¹Ÿä¸çŸ¥é“ä»æˆ¿é—´åˆ°å¤–é¢ç©ºé—´çš„è·¯å¾„ã€‚\nå‡è®¾æœ¬ä¾‹å­çš„ç›®æ ‡æ˜¯å»ºç«‹ä¸€ä¸ªæ¨¡å‹å¸®åŠ© agent ä»æˆ¿å­ä¸­çš„ ä»»æ„ä¸€ä¸ªæˆ¿é—´ å‡ºå‘åˆ°è¾¾æˆ·å¤–ç©ºé—´ã€‚ç°åœ¨æˆ‘ä»¬å‡è®¾ agent åœ¨æˆ¿é—´ 2 ï¼Œæˆ‘ä»¬æƒ³è¦è®©å®ƒå­¦ä¹ å¦‚ä½•åˆ°è¾¾æˆ·å¤–ç©ºé—´ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\nä¸ºäº†å’Œ Reinforcement Learning ä¿æŒä¸€æ”¯ï¼Œæˆ‘ä»¬ç‰¹åˆ«å°†æ¯ä¸ªæˆ¿é—´ Node ç§°ä¹‹çŠ¶æ€ï¼ˆstateï¼‰æˆ–è€…å«åš observation ï¼Œè€Œå°† agent çš„æ¯ä¸€æ¬¡ç§»åŠ¨ç§°ä¹‹ä¸º actionã€‚observation åœ¨è¿™é‡Œæœ‰ç‚¹éš¾ä»¥ç†è§£ï¼Œæ‰€ä»¥è¿™é‡Œä½¿ç”¨ çŠ¶æ€ï¼ˆstateï¼‰è¿™ä¸ª Q-learning æœ¯è¯­ã€‚åœ¨æœ¬ä¾‹å­ä¸­ï¼Œaction ä½¿ç”¨æœ‰å‘è¾¹æ¥è¡¨ç¤ºã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\nä»çŠ¶æ€ 2 agent å¯ä»¥åˆ°è¾¾çŠ¶æ€ 3ï¼Œè¿™æ˜¯å› ä¸ºçŠ¶æ€ 2 å­˜åœ¨åˆ°çŠ¶æ€ 3 çš„æœ‰å‘è¾¹ï¼Œä¹Ÿå°±æ˜¯å­˜åœ¨è”é€šçš„é—¨ã€‚çŠ¶æ€ 2 ä¸èƒ½ç›´æ¥åˆ°è¾¾çŠ¶æ€ 1ï¼Œè¿™æ˜¯å› ä¸ºçŠ¶æ€ 2 ä¸å­˜åœ¨åˆ°è¾¾çŠ¶æ€ 1 çš„æœ‰å‘è¾¹ï¼Œä¹Ÿå°±æ˜¯è¿™ä¸¤ä¸ªæˆ¿é—´ä¹‹é—´ä¸å­˜åœ¨é—¨ã€‚çŠ¶æ€ 3 å¯ä»¥åˆ°è¾¾çŠ¶æ€ 1 ã€çŠ¶æ€ 4 å’Œå›åˆ°çŠ¶æ€ 2ã€‚agent åœ¨çŠ¶æ€ 1 å’ŒçŠ¶æ€ 0 çš„å¯èƒ½åˆ°è¾¾çŠ¶æ€ï¼Œè¯»è€…å¯ä»¥è‡ªè¡Œè§‚å¯Ÿï¼Œä¸å†èµ˜è¿°ã€‚æˆ‘ä»¬å°†ä¸Šè¿°æ‰€æœ‰å¯èƒ½çŠ¶æ€ã€ action å’Œ reward ç¼–åˆ¶æˆä¸€å¼ è¡¨ï¼šå¾—åˆ° matrix Rã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\nNOTE è¡¨ä¸­çš„ -1 è¡¨ç¤ºæ— æ•ˆå€¼ï¼Œä¹Ÿå°±æ˜¯è¿™ä¸ª action ä¸å­˜åœ¨ï¼Œæ¯”å¦‚ä¸å­˜åœ¨ä»çŠ¶æ€ 0 åˆ°çŠ¶æ€ 1 çš„ action æˆ–è€…è¯´é—¨ã€‚\næˆ‘ä»¬å°†å¢åŠ ä¸€ä¸ªç›¸ä¼¼çš„çŸ©é˜µ matrix Q ï¼Œç”¨äºè¡¨ç¤º agent ä»ä¸­å­¦ä¹ çš„çŸ¥è¯†ã€‚matrix Q çš„æ¯ä¸€ä¸ªè¡Œä»£è¡¨ä¸€ä¸ªå‰ä¸€ä¸ªçŠ¶æ€ï¼Œæ¯ä¸€åˆ—è¡¨ç¤ºä¸‹ä¸€ä¸ªçŠ¶æ€ã€‚åˆšå¼€å§‹æ—¶ï¼Œagent å¹¶æ²¡æœ‰å­¦ä¹ åˆ°ä»»ä½•çŸ¥è¯†ï¼Œæ‰€ä»¥ matrix Q ä¸­çš„å€¼åˆå§‹åŒ–ä¸º 0. åœ¨æœ¬ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å·²ç»çŸ¥é“æ‰€æœ‰çš„çŠ¶æ€æ•°ä¸º 6ï¼Œ åœ¨ç°å®ä¾‹å­ä¸­ï¼Œè¿™ä¸ªæ•°å¯èƒ½æ˜¯æœªçŸ¥çš„ï¼Œæ‰€ä»¥åˆå§‹åŒ–çš„æ—¶å€™å¯èƒ½åªæœ‰ä¸€è¡Œä¸€åˆ—ï¼Œå½“å‘ç°æ–°çš„çŠ¶æ€æ—¶ï¼ŒMatrix Q å¯ä»¥å¢åŠ æ–°çš„è¡Œå’Œåˆ—ã€‚\nQ-learning çš„çŠ¶æ€è½¬ç§»è§„åˆ™å¦‚ä¸‹ï¼š\n$$ Q(state, action) = R(state, action) + \\gamma * Max[Q(next state, all actions)] $$\næŒ‰ç…§è¿™ä¸ªå…¬å¼ï¼Œèµ‹å€¼Qä¸­ä¸€ä¸ªå…ƒç´ çš„å€¼ç­‰äº Matrix R ä¸­çš„ç›¸åº”çš„å€¼å’Œ $\\gamma$ (å­¦ä¹ å‚æ•°) ä¹˜ä»¥ ä¸‹ä¸€ä¸ªçŠ¶æ€ä¸­æ‰€æœ‰çš„actionçš„æœ€å¤§çš„ Q rewardã€‚\næˆ‘ä»¬çš„ agent ä¸éœ€è¦è€å¸ˆå°±èƒ½ä»ç»éªŒä¸­å­¦ä¹ ï¼Œå› æ­¤è¿™ä¸ªæ˜¯ éç›‘ç£å­¦ä¹ ã€‚æ¯ä¸€æ¬¡ agent ä»ä¸€ä¸ªçŠ¶æ€è½¬åˆ°å¦ä¸€ä¸ªçŠ¶æ€ï¼Œæœ€ç»ˆè¾¾åˆ°ç›®æ ‡çŠ¶æ€ã€‚è¿™æ ·çš„ä¸€æ¬¡æ¢ç´¢è¿‡ç¨‹æˆ‘ä»¬ç§°ä¹‹ä¸º episodeã€‚æ¯ä¸€ä¸ª episode åŒ…å«äº† agent ä»åˆå§‹çŠ¶æ€åˆ°ç›®æ ‡çŠ¶æ€çš„æ‰€æœ‰çš„ actionã€‚æ¯å½“ agent åˆ°è¾¾ç›®æ ‡çŠ¶æ€æ—¶ï¼Œæˆ‘ä»¬å°±å¼€å§‹ä¸‹ä¸€ä¸ª episodeã€‚\nQ-Learning ç®—æ³•å¤§ä½“è¿è¡Œå¦‚ä¸‹ï¼š\nSet the gamma parameter, and environment rewards in matrix R. Initialize matrix Q to zero. For each episode { Select a random initial state. Do While the goal state hasn\u0026#39;t been reached. { Select one among all possible actions for the current state. Using this possible action, consider going to the next state. Get maximum Q value for this next state based on all possible actions. Compute: Q(state, action) = R(state, action) + Gamma * Max[Q(next state, all actions)] Set the next state as the current state. } } ","permalink":"https://blog.xiaoquankong.ai/zh/posts/introduce-to-reinforcement-leanring/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e å›¾å½¢æ¸¸æˆï¼ˆæ¯”å¦‚å¦å…‹å¤§æˆ˜ï¼‰å¦‚æœè¦å®ç°æ™ºèƒ½Agentï¼ˆAKA ç”µè„‘ç©å®¶ï¼‰çš„è¯ï¼Œç›®å‰æœ€ä½³çš„æ–¹æ¡ˆå°±æ˜¯Reinforcement Learning (ç®€ç§° RL ;ä¸­æ–‡ï¼šå¢å¼ºå­¦ä¹ )ã€‚ æœ¬æ–‡è®°å½•äº†æˆ‘å’ŒReinforcement Learningçš„ç¬¬ä¸€æ¬¡äº¤æ‰‹ï¼Œå°†å¸¦ä½ äº†è§£è¿™ä½åæ‰¬å››æµ·å´åˆç¥ç§˜è«æµ‹çš„å¯¹æ‰‹ã€‚:)\u003c/p\u003e","title":"Reinforcement Learning: åˆæ¬¡äº¤æ‰‹ï¼Œå¤šå¤šæŒ‡æ•™"},{"content":"TL;DR æœ¬æ–‡å°†ä»‹ç»Python bisectæ¨¡å—åœ¨æŸäº›åœºæ™¯ä¸‹çš„å¦™ç”¨ï¼Œå¯ä»¥é«˜æ•ˆå’Œä¼˜é›…çš„æ”¹å–„åŸæœ‰ä½¿ç”¨if-elseæ‰èƒ½è§£å†³é—®é¢˜ã€‚\néš¾é¢˜ï¼šæŸ¥è¯¢æ•´æ•°æ‰€å±çš„åŒºé—´ åº”ç”¨å¼€å‘è¿‡ç¨‹ä¸­ï¼Œç»å¸¸å‡ºç°ä¸€ç§æƒ…æ™¯ï¼Œéœ€è¦ä½ æŸ¥è¯¢ä¸€ä¸ªæ•´æ•°è½åœ¨å“ªä¸€ä¸ªèŒƒå›´å†…ï¼Œæ¯”å¦‚æ ¹æ®æ¶ˆè´¹é‡‘é¢ç¡®å®šä¼˜æƒ é‡‘é¢æˆ–è€…æ‰“æŠ˜åŠ›åº¦ç­‰ã€‚å…·ä½“çš„ä¾‹å­æœ‰ï¼šæ¶ˆè´¹æ»¡100å…ƒä¼˜æƒ 10å…ƒï¼Œæ¶ˆè´¹æ»¡200å…ƒä¼˜æƒ 25å…ƒï¼Œç­‰ç­‰ã€‚\nå¸¸è§„è§£å†³æ–¹æ¡ˆåŠå…¶ç¼ºç‚¹ é€šå¸¸æƒ…å†µä¸‹ï¼Œéƒ½æ˜¯ä½¿ç”¨switchï¼if-elifæ¥è§£å†³çš„ï¼ŒèŒƒå›´æ¯”è¾ƒå°‘çš„æƒ…å†µï¼Œä»£ç è¿˜å±äºæ¯”è¾ƒç®€æ´çš„ï¼Œå½“èŒƒå›´çš„æ•°é‡å¢åŠ ï¼Œä»£ç å°±å˜çš„ç›¸å½“çš„ä¸ç®€æ´äº†ï¼Œæ­£å¦‚ä¸‹é¢çš„ä»£ç ï¼š\ndiscount = None if value \u0026lt; 100: discount = 0 elif value \u0026lt; 200: discount = 10 elif values \u0026lt; 300: discount = 25 elif values \u0026lt; 400: discount = 42 elif values \u0026lt; 500: discount = 53 elif values \u0026lt; 600: discount = 64 elif values \u0026lt; 700: discount = 75 elif values \u0026lt; 800: discount = 86 elif values \u0026lt; 900: discount = 97 elif values \u0026lt; 1000: discount = 108 else: discount = 120 åŸºäºbisectçš„æ–¹æ¡ˆ bisectä»‹ç» bisectæ˜¯pythonçš„æ ‡å‡†æ¨¡å—ï¼Œæ˜¯ä¸€ä¸ªå…³äºæ•°ç»„äºŒåˆ†æŸ¥æ‰¾æ³•çš„åº“ï¼Œé‡Œé¢æä¾›äº†åœ¨è¿™é‡Œéå¸¸æœ‰ç”¨çš„ä¸‰ä¸ªå‡½æ•°bisect_left, bisect_right, bisect. è¿™ä¸‰ä¸ªå‚æ•°éƒ½æ¥å—ä¸€ä¸ªarrayå’Œä¸€ä¸ªæ•°å­—ï¼Œè¿”å›å°†æ•°å­—æ’å…¥è¿™ä¸ªarrayåè¿™ä¸ªæ•°å­—çš„ä½ç½®ï¼ˆindexï¼‰ï¼Œä½†å¹¶ä¸çœŸæ­£æ‰§è¡Œæ’å…¥æ“ä½œã€‚æ¯”å¦‚ï¼š\nIn[0]: import bisect In[1]: bisect.bisect([1, 3, 5], 2) Out[1]: 1 è¡¨ç¤ºå¦‚æœå°†2æ’å…¥1 3 5ä¸­é—´ï¼Œé‚£ä¹ˆæ’è¿›å»ä¹‹åçš„indexåˆ™ä¸ºè¿”å›å€¼ï¼ˆæœ¬ä¾‹ï¼Œè¿”å›å€¼ä¸º1ï¼‰ï¼Œå¦‚æœå‡ºç°ç›¸åŒçš„å€¼ï¼Œbisect()å‡½æ•°é€‰æ‹©å°†å€¼æ’åœ¨åé¢ä¹Ÿå°±æ˜¯åŸæœ‰å€¼çš„å³ä¾§ï¼š\nIn[0]: import bisect In[1]: bisect.bisect([1, 3, 5], 3) Out[1]: 2 bisect_left()å‡½æ•°é€‰æ‹©å°†å€¼æ’åœ¨å‰é¢ä¹Ÿå°±æ˜¯åŸæœ‰å€¼çš„å·¦ä¾§ï¼š\nIn[0]: import bisect In[1]: bisect.bisect_left([1, 3, 5], 3) Out[1]: 1 å¦å¤–bisect_right()å‡½æ•°æ˜¯bisect()å‡½æ•°çš„åˆ«åï¼Œæˆ–è€…åä¹‹ã€‚\nåˆ©ç”¨bisectæŸ¥æ‰¾æ•´æ•°èŒƒå›´ bisectå‡½æ•°æ˜¯äºŒåˆ†æŸ¥æ‰¾ï¼Œæ—¢å¯ä»¥ç”¨æ¥æ’å…¥ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥ç”¨æ¥æ£€ç´¢ä¿¡æ¯ï¼Œæ¯”å¦‚æŸ¥æ‰¾å€¼æ‰€å±çš„åŒºæ®µï¼åŒºé—´ã€‚\nå‰é¢æˆ‘ä»¬æåˆ°çš„é‚£ä¸ªå‡½æ•°å°±å¯ä»¥åˆ©ç”¨bisectåšæ”¹å†™:\nmapping = { 0: 0, 1:\t10, 2: 25, 3: 42, 4: 53, 5: 64, 6: 75, 7: 86, 8: 97, 9: 108, 10: 120, } i = bisect(range(100, 1001, 100), value) discount = mapping[i] è¿™ç§æ–¹æ¡ˆåœ¨ä¸šåŠ¡æ–¹æ¡ˆå¤šå˜ï¼ŒæŸ¥è¯¢èŒƒå›´ç‰¹åˆ«å¤šçš„æƒ…å†µä¸‹å…·å¤‡æå¤§çš„å¯ç»´æŠ¤æ€§å’Œæ€§èƒ½ä¼˜åŠ¿ã€‚\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/introduce-to-python-bisect-module/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e æœ¬æ–‡å°†ä»‹ç»Python bisectæ¨¡å—åœ¨æŸäº›åœºæ™¯ä¸‹çš„å¦™ç”¨ï¼Œå¯ä»¥é«˜æ•ˆå’Œä¼˜é›…çš„æ”¹å–„åŸæœ‰ä½¿ç”¨if-elseæ‰èƒ½è§£å†³é—®é¢˜ã€‚\u003c/p\u003e","title":"Python bisectæ¨¡å—çš„å¦™ç”¨"},{"content":"TL:DR æœ¬æ–‡å±äºå…¥é—¨çº§è¯¾ç¨‹101ï¼Œç”¨å›¾æ–‡å¹¶èŒ‚çš„æ–¹å¼è¯¦ç»†çš„ä»‹ç»äº†LSTMçš„å·¥ä½œåŸç†ã€‚\nç¥ç»ç½‘ç»œ æœ¬æ–‡å‡è®¾ä½ å·²ç»äº†è§£æœ€åŸºæœ¬çš„ç¥ç»ç½‘ç»œçš„çŸ¥è¯†ï¼Œä¸ºäº†æ›´å¥½çš„ç†è§£æœ¬æ–‡å†…å®¹ï¼Œæœ¬æ–‡å…ˆç®€å•å›é¡¾ä¸€ä¸‹ç¥ç»ç½‘ç»œçš„ä¸€äº›é‡è¦çš„æœ¯è¯­å’Œç¬¦å·ï¼Œè¿™äº›ç¬¦å·å°†åœ¨åç»­çš„å†…å®¹ä¸­æŒç»­ä½¿ç”¨ã€‚\nçŸ©é˜µè¡¨ç¤ºä¸‹çš„ç¥ç»ç½‘ç»œ å‡è®¾ï¼š\n$x$æ˜¯input layerçš„å€¼ $W$æ˜¯hidden layerçš„æƒé‡ $h$æ˜¯hidden layerçš„è¾“å‡ºå€¼ $V$æ˜¯hidden layeråˆ°output layerçš„æƒé‡ $y$æ˜¯output layerçš„å€¼ $\\phi$æ˜¯æ¿€æ´»å‡½æ•°ï¼Œå¸¸è§æ¿€æ´»å‡½æ•°ä¸ç‰¹æ€§è¯·è§ç¥ç»ç½‘ç»œé‡Œçš„æ¿€æ´»å‡½æ•°, è¿™é‡Œä½¿ç”¨$\\sigma$è¡¨ç¤ºsigmoidå‡½æ•° $[x,y]$è¡¨ç¤ºä¸¤ä¸ªåˆ—å‘é‡ï¼Œåœ¨åˆ—çš„ç»´åº¦ä¸Šconcatenate åˆ™æœ‰ï¼š\n$$ h = \\phi (Wx) $$\n$$ y = Vh $$\nä¸‹é¢æ˜¯å¤§æ„å›¾ï¼š\nTODO: æ›¿æ¢æœ¬å›¾\nRNN åº”ç”¨åœºæ™¯ ç°å®ç”Ÿæ´»ä¸­å¾ˆå¤šäº‹æƒ…éƒ½æ˜¯åºåˆ—çš„ï¼Œåé¢çš„äº‹æƒ…å’Œå‰é¢æ˜¯å­˜åœ¨ä¸Šä¸‹æ–‡å…³ç³»çš„ï¼Œå•ä»ä¸€ä¸ªç‰‡æ®µæ˜¯æ— æ³•åšå‡ºåˆ¤æ–­çš„ã€‚æ¯”å¦‚ï¼šä½ å‘ä¸Šæ‰”ä¸€ä¸ªè‹¹æœï¼Œåœ¨ä»»æ„æ—¶åˆ»ï¼Œä½ åªèƒ½å¾—åˆ°ä¸€ä¸ªè‹¹æœçš„ç¬æ—¶ç…§ç‰‡ï¼Œå•ä»ç…§ç‰‡ä½ æ ¹æœ¬æ²¡æ³•æ­£ç¡®æ¨æµ‹è¿™ä¸ªè‹¹æœçš„è¿åŠ¨çŠ¶æ€çš„ï¼ŒæˆåŠŸçš„æ¨æµ‹è‹¹æœçš„è¿åŠ¨çŠ¶æ€ï¼Œéœ€è¦æ¨¡å‹å…·å¤‡è®°å¿†èƒ½åŠ›èƒ½å¤Ÿè®°ä½ä¹‹å‰è‹¹æœçš„ä½ç½®ä¿¡æ¯ã€‚ä¼ ç»Ÿçš„ç¥ç»ç½‘ç»œåªèƒ½åˆ¤æ–­ä¸€ä¸ªç¬é—´çŠ¶æ€çš„æƒ…å†µï¼Œä¸å…·å¤‡è¿™ç§è®°å¿†çš„èƒ½åŠ›ï¼Œå› æ­¤åœ¨å¾ˆå¤šå¤æ‚çš„åœºæ™¯ä¸­æ— æ³•é€‚ç”¨ã€‚ä¸ºæ­¤äººä»¬æå‡ºäº†RNNï¼ˆRecurrent Neural Network)é€šè¿‡å°†ä¸Šä¸€ä¸ªåœºæ™¯çš„ä¿¡æ¯å¼•å…¥ä¸‹ä¸€ä¸ªåœºæ™¯çš„æ–¹å¼æ¥è®°ä½é‡è¦ä¿¡æ¯ã€‚\nRNNåŸç† æ—¢ç„¶ä¸Šä¸€ä¸ªåœºæ™¯çš„hidden layerçš„å€¼ä¸­åŒ…å«äº†åœºæ™¯ä¿¡æ¯ï¼Œé‚£ä¹ˆç†æ‰€å½“ç„¶çš„æˆ‘ä»¬è®¤ä¸ºhidden layerä¸­åŒ…å«äº†æœ‰ç”¨çš„ä¸Šä¸‹æ–‡çŸ¥è¯†ã€‚æ‰€ä»¥RNNå°±æ˜¯åœ¨å½“å‰çš„é¢„æµ‹ä¸­å¼•å…¥ä¸Šä¸€ä¸ªåœºæ™¯çš„hidden layerå€¼ï¼š\n$$ h_t = \\phi (W x_t + U h_{t-1}) $$\n$$ y_t = V h_t $$\nå…¶ä¸­ï¼š\n$h_t$æ˜¯$t$æ—¶åˆ»çš„hidden layerçš„å€¼ $h_{t-1}$æ˜¯$t-1$æ—¶åˆ»ï¼ˆäº¦å³ä¸Šä¸€ä¸ªæ—¶åˆ»ï¼‰çš„hidden layerçš„å€¼ ç¼ºé™· å°½ç®¡RNNæˆåŠŸè®°å¿†äº†éƒ¨åˆ†ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä½†å­˜åœ¨ä¸€ä¸ªå¾ˆå¤§çš„ç¼ºé™·ï¼Œé‚£å°±æ˜¯å®ƒå¾ˆéš¾è®°ä½é•¿æœŸçš„è®°å¿†ã€‚è¿˜æ˜¯ä¸Šé¢æŠ›è‹¹æœçš„ä¾‹å­ï¼ŒRNNèƒ½å¤Ÿè®°ä½çŸ­æœŸçš„ä¸Šä¸‹æ–‡ï¼Œæ‰€ä»¥åœ¨åæœŸå®ƒèƒ½å¤Ÿè¯†åˆ«å‡ºè‹¹æœåœ¨åŠ é€Ÿä¸‹è½ï¼Œä½†æ˜¯ç”±äºæ²¡æœ‰è®°ä½æ¯”è¾ƒä¹…è¿œçš„è‹¹æœå…ˆæ˜¯ä¸Šå‡çš„è¿™ä¸ªä¿¡æ¯ï¼Œå› æ­¤RNNåªèƒ½è¯†åˆ«å‡ºè¿™ä¸ªè‹¹æœæ˜¯ä¸‹é™çš„ã€‚\nLSTM ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œäººä»¬æå‡ºäº†LSTMï¼ˆLong Short-Term Memoryï¼‰ç½‘ç»œï¼ŒLSTMæœ€å¤§çš„ç‰¹ç‚¹å°±æ˜¯èƒ½å¤Ÿè®°ä½é•¿æœŸè®°å¿†ã€‚æ˜¯ç›®å‰å·¥ä¸šç•Œå’Œå­¦æœ¯ç•Œæœ€é‡è¦çš„RNNå®ç°ã€‚\nå·¥ä½œåŸç† LSTMæœ‰ä¸¤ä¸ªé‡è¦çš„stateæˆ–è€…memoryï¼š\né•¿æœŸè®°å¿† (long-term memory: $lsm$, é€šå¸¸è¢«ç§°ä¸ºcell state, æ ‡è¯†ä¸º$C$) å·¥ä½œè®°å¿† (working memory: $wm$, é€šå¸¸è¢«ç§°ä¸ºhidden state, æ ‡è¯†ä¸º$h$)ã€‚ ä¸€ä¸ªå­¦ä¹ è¿­ä»£æœ‰ä¸€ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š\né€‰æ‹©æ€§é—å¿˜éƒ¨åˆ†é•¿æœŸè®°å¿†ï¼šå°†è®°å¿†ä¸­ä¸éœ€è¦çš„è®°å¿†ç§»é™¤ å°†ç°æœ‰çš„ä¸€äº›ä¿¡æ¯åŠ å…¥åˆ°é•¿æœŸè®°å¿†ä¸­ è®¡ç®—å€™é€‰é•¿æœŸè®°å¿† é€‰æ‹©å‡½æ•° ä»long-term memoryä¸­æå–working memory è®¡ç®—å€™é€‰çš„working memory é€‰æ‹©å‡½æ•° é€‰æ‹©æ€§é—å¿˜éƒ¨åˆ†é•¿æœŸè®°å¿† è¿™ä¸ªéƒ¨åˆ†ä¹Ÿç§°ä¹‹ä¸ºforget gate layer\né—å¿˜å‡½æ•°/é—å¿˜é—¨(forget gate) æˆ‘ä»¬å…ˆå†³å®šå“ªäº›é•¿æœŸè®°å¿†éœ€è¦è¢«é—å¿˜ï¼ˆæˆ–è€…ä¿ç•™ï¼‰ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå•ç‹¬çš„æµ…å±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ ã€‚åœ¨$t$æ—¶åˆ»ï¼š\n$$ remember_t = \\sigma (W_r x_t + U_r wm_{t-1}) $$\nè¿™é‡Œçš„$remember_t$æ˜¯ä¸€ä¸ªbooleanåºåˆ—ï¼Œé•¿åº¦å’Œ$lsm_{t-1}$ç›¸åŒï¼Œé€šå¸¸è¢«ç§°ä¸ºforget gateã€‚å€¼1è¡¨ç¤ºä¿ç•™$lsm_{t-1}$å¯¹åº”ä½ç½®çš„æ•°å€¼ï¼Œ0åˆ™è¡¨ç¤ºæŠ›å¼ƒæˆ–è€…åˆ é™¤ã€‚\nä¸Šè¿°å…¬å¼è¿˜å¯ä»¥è¡¨ç¤ºæˆï¼š\n$$ f_t = \\sigma (W_f \\cdot [ h_{t-1} , x_t ] + b_f) $$\nä¿å­˜ä¸‹æ¥çš„é•¿æœŸè®°å¿† æœ‰äº†é—å¿˜å‡½æ•°åï¼Œæˆ‘ä»¬å°±èƒ½ç¡®å®šä¿å­˜ä¸‹æ¥çš„é•¿æœŸè®°å¿†æ˜¯ä»€ä¹ˆäº†ã€‚åœ¨$t$æ—¶åˆ»ï¼š\n$$ olsm_t = forget_t \\odot lsm_{t-1} $$\nå¢åŠ æ–°çš„é•¿æœŸè®°å¿† é™¤äº†æœ‰äº›æŸäº›è€çš„è®°å¿†éœ€è¦ç»§ç»­ä¿ç•™ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå½“å‰çš„ä¸€äº›é‡è¦ä¿¡æ¯æ·»åŠ åˆ°é•¿æœŸè®°å¿†ä¸­ã€‚\nè®¡ç®—å€™é€‰çš„é•¿æœŸè®°å¿† é¦–å…ˆç®—å‡ºæ¥å…¨ä½“å€™é€‰è®°å¿†ã€‚åœ¨$t$æ—¶åˆ»ï¼š\n$$ lsm\u0026rsquo;_t = \\phi (W_l x_t + U_l wm_{t-1}) $$\nè¿™é‡Œçš„$lsm\u0026rsquo;_t$ä»£è¡¨å¯èƒ½åŠ å…¥é•¿æœŸè®°å¿†çš„è®°å¿†åºåˆ—ï¼Œé•¿åº¦å’Œ$lsm_{t-1}$ç›¸åŒã€‚è¿™é‡Œçš„$\\phi$å‡½æ•°å¸¸å¸¸é€‰æ‹©$tanh$å‡½æ•°ã€‚\nä¸Šè¿°å…¬å¼è¿˜å¯ä»¥è¡¨ç¤ºæˆï¼š $$ \\tilde{C}_t = \\phi (W_C \\cdot [ h_{t-1} , x_t ] + b_C) $$\né€‰æ‹©å‡½æ•° æœ‰äº†å€™é€‰è®°å¿†åï¼Œéœ€è¦ä¸€ä¸ªé€‰æ‹©å‡½æ•°è´Ÿè´£å®é™…é€‰æ‹©å“ªäº›è®°å¿†å¯ä»¥åŠ å…¥é•¿æœŸè®°å¿†ã€‚åœ¨$t$æ—¶åˆ»ï¼š\n$$ save_t = \\phi (W_s x_t + U_s wm_{t-1}) $$\nä¸Šè¿°å…¬å¼è¿˜å¯ä»¥è¡¨ç¤ºæˆï¼š $$ i_t = \\sigma (W_i \\cdot [h_{t-1},x_t] + b_i) $$\næ–°çš„é•¿æœŸè®°å¿† æœ‰äº†å€™é€‰çš„é•¿æœŸè®°å¿†å’Œé€‰æ‹©å‡½æ•°åï¼Œæˆ‘ä»¬å°±å¯ä»¥ç¡®å®šå“ªäº›è®°å¿†æ˜¯è¦æ·»åŠ åˆ°é•¿æœŸè®°å¿†çš„ã€‚åœ¨$t$æ—¶åˆ»ï¼š\n$$ nlsm_t = save_t \\odot lsm\u0026rsquo;_t $$\næ›´æ–°é•¿æœŸè®°å¿† æ—¢ç„¶æœ‰äº†é—å¿˜å’Œæ›´æ–°æœºåˆ¶ï¼Œé‚£ä¹ˆæœ€ç»ˆçš„é•¿æœŸè®°å¿†ä¹Ÿå°±å¯ä»¥ç¡®å®šäº†ã€‚åœ¨$t$æ—¶åˆ»ï¼š\n$$ lsm_t = olsm_t + nlsm_t $$\nä¸Šè¿°å…¬å¼è¿˜å¯ä»¥è¡¨ç¤ºæˆï¼š $$ C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t $$\nå…¶ä¸­$\\odot$è¡¨ç¤ºelement-wise product, å¦‚æœä½¿ç”¨*æ›¿ä»£ï¼Œåˆ™èƒ½å¾—åˆ°ï¼š $$ C_t = f_t * C_{t-1} + i_t * \\tilde{C}_t $$\nåº”ç”¨é•¿æœŸè®°å¿† é•¿æœŸè®°å¿†éœ€è¦åº”ç”¨åœ¨å½“å‰çš„å·¥ä½œè®°å¿†ä¸­æ‰æœ‰ä½œç”¨ã€‚\né€‰æ‹©å‡½æ•° ä»ä¸Šä¸€ä¸ªå·¥ä½œè®°å¿†å’Œå½“å‰è¾“å…¥ä¸­ç¡®å®šé€‰æ‹©å‡½æ•°ã€‚åœ¨$t$æ—¶åˆ»ï¼š\n$$ focus_t = \\sigma (W_f x_t + U_f wm_{t-1}) $$\nä¸Šè¿°å…¬å¼è¿˜å¯ä»¥è¡¨ç¤ºæˆï¼š $$ o_t = \\sigma (W_o \\cdot [h_{t-1},x_t] + b_o) $$\nå€™é€‰çš„å·¥ä½œè®°å¿† å·¥ä½œè®°å¿†æ˜¯ä»é•¿æœŸè®°å¿†è½¬æ¢æ¥çš„ã€‚åœ¨$t$æ—¶åˆ»ï¼š\n$$ wm\u0026rsquo;_t = \\phi (lsm_{t-1}) $$\nå…¶ä¸­è¿™é‡Œçš„$\\phi$å¸¸å¸¸é€‰æ‹©$tanh$\nä¸Šè¿°å…¬å¼è¿˜å¯ä»¥è¡¨ç¤ºæˆï¼š\n$$ \\tilde{h}_t = \\phi (C_t) $$\næ›´æ–°å·¥ä½œè®°å¿† æ—¢ç„¶æœ‰äº†å€™é€‰å·¥ä½œè®°å¿†å’Œé€‰æ‹©å‡½æ•°ï¼Œé‚£ä¹ˆæœ€ç»ˆçš„å·¥ä½œè®°å¿†ä¹Ÿå°±ç¡®å®šäº†ã€‚åœ¨$t$æ—¶åˆ»ï¼š\n$$ wm_t = focus_t \\odot wm\u0026rsquo;_t $$\nä¸Šè¿°å…¬å¼è¿˜å¯ä»¥è¡¨ç¤ºæˆï¼š\n$$ h_t = o_t * \\tilde{h}_t $$\nå˜ç§ LSTMè¯ç”Ÿåï¼Œä¸æ–­æœ‰äººæ”¹è¿›æ¨¡å‹ï¼Œè‡³ä»ŠLSTMå·²ç»æœ‰å¾ˆå¤šå˜ç§äº†(è¯·å‚è€ƒ[å‚è€ƒæ–‡çŒ®]éƒ¨åˆ†)ã€‚æœ¬èŠ‚å°†ä»‹ç»å…¶ä¸­æœ€é‡è¦çš„ä¸¤ä¸ªå˜ç§ï¼šPeephole LSTMå’ŒGated Recurrent Unit\nPeephole LSTM æ™®é€šçš„LSTMçš„æ‰€æœ‰çš„é—¨çš„å†³ç­–å…¨éƒ¨éƒ½æ˜¯ç”±è¾“å…¥$x$å’Œ$wm_{t-1}$å†³å®šï¼ŒPeephole LSTMæ”¹è¿›äº†é—¨çš„å®ç°ï¼Œè®©$lsm_{t-1}$ä¹Ÿå‚ä¸é—¨çš„å†³ç­–ã€‚\nCoupled Input and Forget Gate (CIFG) æ—¢ç„¶forget gateå’Œinput gateéƒ½æ˜¯æ§åˆ¶æ›´æ–°long-term memoryï¼ˆ$C$ï¼‰çš„ï¼Œé‚£ä¹ˆä»–ä»¬å¯ä»¥åˆå¹¶æˆä¸ºä¸€ä¸ªupdate gate:forget gateå¿˜è®°çš„ä¿¡æ¯å…¨éƒ¨ç”±input gateæä¾›ã€‚\nGated Recurrent Unit (GRU) GRUä¸ä»…ä½¿ç”¨äº†update gateæ›¿ä»£äº†forget gateå’Œinput gate,è€Œä¸”å°†long-term memory ($C$)å’Œworking memoryï¼ˆ$h$ï¼‰åˆå¹¶äº†ï¼Œå¹¶åšäº†ä¸€äº›ç»†å¾®çš„è°ƒæ•´ã€‚ç”±äºç®€åŒ–äº†åŸæœ‰LSTMçš„ç»“æ„ï¼Œé€Ÿåº¦æ›´å¿«ï¼Œç›®å‰æµè¡Œåº¦ä¸æ–­å¢åŠ ã€‚\nå‚è€ƒæ–‡çŒ® Understanding LSTM Networks Exploring LSTMs http://slazebni.cs.illinois.edu/spring17/lec03_rnn.pdf ","permalink":"https://blog.xiaoquankong.ai/zh/posts/quickly-understand-lstm/","summary":"\u003cp\u003e\u003cstrong\u003eTL:DR\u003c/strong\u003e æœ¬æ–‡å±äºå…¥é—¨çº§è¯¾ç¨‹101ï¼Œç”¨å›¾æ–‡å¹¶èŒ‚çš„æ–¹å¼è¯¦ç»†çš„ä»‹ç»äº†LSTMçš„å·¥ä½œåŸç†ã€‚\u003c/p\u003e","title":"ç†è§£LSTMçš„å·¥ä½œåŸç†"},{"content":"TL;DR æœ¬æ–‡ç« æ”¶é›†äº†ä¸€äº›æœºå™¨å­¦ä¹ ç›¸å…³çš„ç†è®ºæ–¹é¢çš„å…¥é—¨çº§çš„èµ„æ–™ï¼Œé€‚åˆåˆå­¦è€…ä½œä¸ºå…¥é—¨è¯¾ç¨‹101ã€‚\næ•°å­¦åŸºç¡€ çº¿æ€§ä»£æ•° Vector, Matrix, and Tensor Derivatives CS321n ä»‹ç»çŸ©é˜µå’Œå‘é‡å¯¼æ•°çš„ç®—æ³• Properties of the Trace and Matrix Derivatives Matrix Differentiation ( and some other stuff ) æ’ç‰ˆéå¸¸å¥½çœ‹ ç¥ç»ç½‘ç»œ Backpropagation Calculus on Computational Graphs: Backpropagation æ¨èå…¥é—¨ ä»è®¡ç®—å›¾çš„è§’åº¦ä»‹ç»BPç®—æ³• LSTM åšæ–‡ Exploring LSTMs å…¥é—¨æ¨è éå¸¸è¯¦ç»†çš„ç”¨æ˜“äºç†è§£çš„æ–¹å¼ä»‹ç»äº†LSTMä¸­å„ç§é—¨ï¼Œåé¢æ›´å¤§ç¯‡å¹…æ¢ç´¢äº†ä¸€ä¸‹LSTMåœ¨å„ç§ç®€å•é—®é¢˜ä¸Šçš„å†…éƒ¨å‚æ•°æƒ…å†µï¼Œä½†åé¢çš„éƒ¨åˆ†ï¼Œæˆ‘æš‚æ—¶æ²¡çœ‹æ‡‚:( Understanding LSTM Networks Stanford CS224n æ¨èé˜…è¯» éå¸¸ç»†è‡´çš„ä»‹ç»äº†LSTMä¸­çš„å„ç§é—¨ï¼Œå»ºè®®å…ˆé˜…è¯»ä¸Šä¸€ç¯‡æ–‡ç« å†çœ‹è¿™ä¸ªæ–‡ç« ï¼Œåœ¨ç†è§£ä¸ºä»€ä¹ˆéœ€è¦å„ç§é—¨çš„åŸºç¡€ä¸Šå†å­¦ä¹ å„ç§é—¨æ˜¯æ€ä¹ˆå®ç°çš„ä¼šæ›´åŠ æ¸…æ™°æ¥é¾™å»è„‰ã€‚ MOOC TODO\nå¤§å­¦è¯¾ç¨‹ Stanford CS224n: Natural Language Processing with Deep Learning æ²¡å•¥å¥½ä»‹ç»çš„ï¼Œæ¥è‡ªStanford NLP groupçš„ï¼Œè´¨é‡ä»€ä¹ˆçš„æ²¡å¾—è¯´ã€‚ ","permalink":"https://blog.xiaoquankong.ai/zh/posts/machine-learning-related-materials/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e æœ¬æ–‡ç« æ”¶é›†äº†ä¸€äº›æœºå™¨å­¦ä¹ ç›¸å…³çš„ç†è®ºæ–¹é¢çš„å…¥é—¨çº§çš„èµ„æ–™ï¼Œé€‚åˆåˆå­¦è€…ä½œä¸ºå…¥é—¨è¯¾ç¨‹101ã€‚\u003c/p\u003e","title":"æœºå™¨å­¦ä¹ ç›¸å…³çš„ç†è®ºèµ„æ–™æ±‡æ€»"},{"content":"TL;DR æœ¬æ–‡å°†ä»‹ç»ç¥ç»ç½‘ç»œä¸­å¸¸ç”¨çš„å‡ ç§æ¿€æ´»å‡½æ•°çš„ç‰¹æ€§å’Œä½¿ç”¨åœºåˆã€‚\nç¥ç»ç½‘ç»œ(Neural Network)ä¸­çš„æ¿€æ´»å‡½æ•°(Activation Function)é€‰æ‹©æ˜¯è‡³å…³é‡è¦çš„ï¼Œå®ƒç›´æ¥å½±å“ç€æ¨¡å‹çš„performanceã€‚\nå„ç§æ¿€æ´»å‡½æ•°ä»‹ç» ä¸‹é¢å°†å¯¹æ¯”è¾ƒå¸¸è§çš„å‡ ç§æ¿€æ´»å‡½æ•°åšç®€å•çš„ä»‹ç»ï¼š\nSigmoid Sigmoidæ˜¯æœ€æ—©è¢«ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ä¹‹ä¸€ï¼Œç°åœ¨ä¾æ—§ç»å¸¸å‡ºç°åœ¨æ•™ç§‘ä¹¦å’Œæ•™å­¦ä¸­ï¼Œæ˜¯æœ€ç»å…¸çš„æ¿€æ´»å‡½æ•°ä¹‹ä¸€ã€‚Sigmoidå‡½æ•°æœ‰æ—¶ä½¿ç”¨ç¬¦å·$\\sigma$æ¥è¡¨ç¤ºã€‚\næ•°å­¦è¡¨ç¤º $$ a=\\frac{1}{1+e^{-z}} $$\nå›¾åƒ Note: ä¸ºäº†å›¾åƒæ›´åŠ ç´§å‡‘ï¼Œè¿™å¹…å›¾å®é™…å¯¹åº”çš„å‡½æ•°æ˜¯$a=\\frac{1}{1+e^{-5z}}$\nå¯¼æ•° $$ f\u0026rsquo;(z)=\\frac{\\mathrm d \\sigma}{\\mathrm d z}=\\frac{1}{1+e^{-z}}(1-\\frac{1}{1+e^{-z}})=f(z)(1-f(z))=\\sigma(1-\\sigma) $$\nç‰¹æ€§ å¯ä»¥çœ‹åˆ°sigmoidå‡½æ•°çš„ä¸€ä¸ªæœ€å¤§çš„ç‰¹ç‚¹å°±æ˜¯ï¼šå€¼åŸŸä¸¥æ ¼é™åˆ¶åœ¨(0, 1)å¼€åŒºé—´ã€‚è¿™ç§ç‰¹æ€§ä½¿å¾—sigmoidå¯ä»¥å°†å®æ•°èŒƒå›´çš„å€¼è¡¨ç¤ºæˆæ¦‚ç‡çš„å½¢å¼ï¼Œè¿™æ˜¯sigmoidæœ€å¤§çš„ç‰¹ç‚¹ã€‚\ntanh tanhå‡½æ•°çš„å…¨ç§°æ˜¯\u0026quot;hyperbolic tangent\u0026quot;,å±äº\u0026quot;Hyperbolic function\u0026quot;(åŒæ›²çº¿å‡½æ•°)ï¼Œå…³äºè¿™ä¸ªå‡½æ•°çš„æ›´å¤šè¯¦ç»†çš„èµ„æ–™å¯ä»¥è®¿é—®Hyperbolic functionåœ¨Wikipediaçš„ç›¸å…³é¡µé¢\næ•°å­¦è¡¨ç¤º $$ a=\\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}} $$\nå›¾åƒ å¯¼æ•° $$ f\u0026rsquo;(z)=\\frac{\\mathrm d \\tanh}{\\mathrm d z}=1-(\\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}})^2=1-f(z)^2=1-\\tanh^2 $$\nç‰¹æ€§ tanhå‡½æ•°å’Œsigmoidå‡½æ•°éå¸¸ç›¸ä¼¼ï¼Œéƒ½æ˜¯ä¸€ä¸ªä¼˜é›…çš„Så‹æ›²çº¿ï¼Œäº‹å®ä¸Š$tanh=sigmoid(z)*2+1$ã€‚å”¯ä¸€ä¸åŒçš„åœ°æ–¹æ˜¯tanhçš„å€¼åŸŸä¸¥æ ¼é™åˆ¶åœ¨(-1, 1)å¼€åŒºé—´ã€‚\nReLU ReLUçš„å…¨ç§°æ˜¯\u0026quot;Rectified Linear Unit\u0026quot;ï¼ˆä¸­æ–‡ååº”è¯¥ç¿»è¯‘æˆâ€œçº¿æ€§æ•´æµå‡½æ•°â€æˆ–â€œä¿®æ­£çº¿æ€§å•å…ƒâ€ï¼Œä½†ä¸­æ–‡åå‡ ä¹æ— äººä½¿ç”¨ï¼‰ã€‚æ˜¯ç›®å‰ç¥ç»ç½‘ç»œä¸­æœ€ä¸»æµçš„æ¿€æ´»å‡½æ•°ã€‚\næ•°å­¦è¡¨ç¤º $$ a=max(0, z) $$\nå›¾åƒ å¯¼æ•° $$ f\u0026rsquo;(z) = \\begin{cases} 0 \u0026amp; \\quad \\text{if } z \u0026lt; 0\\\\ 1 \u0026amp; \\quad \\text{if } z \u0026gt; 0 \\end{cases} $$\nç‰¹æ€§ ReLUå¯ä»¥è¢«çœ‹ä½œæ˜¯sigmoidå‡½æ•°åœ¨$(-\\infty, 0)$å®šä¹‰åŸŸä¸Šçš„è¿‘ä¼¼å‡½æ•°ã€‚å¦‚ä¸‹å›¾ï¼š ä¸Šå›¾ä¸­ï¼Œè“è‰²çš„çº¿è¡¨ç¤ºsigmoidå‡½æ•°ï¼Œç»¿è‰²çš„çº¿è¡¨ç¤ºReLUå‡½æ•°ã€‚ Noteï¼šä¸ºäº†è®©å›¾æ›´åŠ å®¹æ˜“ç†è§£ï¼Œå®é™…ä½¿ç”¨çš„sigmoidå‡½æ•°æ˜¯$a=\\frac{1}{1+e^{-5z}}$ï¼ŒReLUå‡½æ•°æ˜¯$a=max(0, z+0.5)$\nåŒæ—¶å› ä¸ºå› ä¸ºæ•°å­¦ä¸Šç‰¹åˆ«ç®€å•ï¼Œæ‰€ä»¥è®¡ç®—é€Ÿåº¦éå¸¸å¿«ã€‚å·²ç»åœ¨å¾ˆå¤šé¢†åŸŸæ›¿ä»£sigmoidå’Œtanhã€‚\nLeaky ReLU æ˜¯å¯¹ReLUçš„å¾®å°æ”¹åŠ¨ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ä¼šæœ‰æ¯”è¾ƒå¥½çš„æ•ˆæœã€‚\næ•°å­¦è¡¨ç¤º $$ a=max(\\alpha z, z) $$ å…¶ä¸­$\\alpha \u0026lt; 1$\nå›¾åƒ Note: ä¸Šå›¾ä¸­ä½¿ç”¨çš„å‡½æ•°ä¸ºï¼š$ a=max(0.05z, z) $\nå¯¼æ•° $$ f\u0026rsquo;(z) = \\begin{cases} \\alpha \u0026amp; \\quad \\text{if } z \u0026lt; 0\\\\ 1 \u0026amp; \\quad \\text{if } z \u0026gt; 0 \\end{cases} $$\nç‰¹æ€§ Leaky ReLUæ˜¯ReLUçš„æ”¹åŠ¨ç‰ˆï¼Œåœ¨æŸäº›ç‰¹å®šçš„æƒ…å†µä¸‹ä¼šæœ‰æ¯”è¾ƒå¥½çš„ç»“æœã€‚\nåˆ—è¡¨å¯¹æ¯” ä¸‹é¢ç”¨åˆ—è¡¨çš„å½¢å¼ï¼Œå¯¹å¸¸è§çš„å‡ ç§æ¿€æ´»å‡½æ•°çš„ç‰¹æ€§å’Œä½¿ç”¨åœºæ™¯åšä¸€ä¸ªæ€»ç»“ï¼š\nå‡½æ•°å å‡½æ•°å…¬å¼ ä½¿ç”¨åœºæ™¯^[æ¥è‡ªï¼šNeural Networks and Deep Learning by Andrew Ng on Coursera] sigmoid $a=\\frac{1}{1+e^{-z}}$ é€‚åˆäºŒåˆ†ç±»é—®é¢˜çš„output layer tanh $a=\\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$ ç»å¤§å¤šæ•°æƒ…å†µä¸‹ä¼˜äºsigmoid ReLU $a=max(0, z)$ ä¼˜å…ˆä½¿ç”¨è¿™ç§æ–¹æ³•ï¼ˆæ¨èï¼‰ Leaky ReLU $a=max(\\alpha z, z)$ æŸäº›æƒ…å†µä¸‹æ•ˆæœè¾ƒå¥½ Note: åœ¨å®é™…åœºæ™¯ä¸­ï¼Œå¯ä»¥å°è¯•ä¸åŒçš„å‡½æ•°ï¼Œå¯»æ‰¾æœ€ä¼˜æ–¹æ¡ˆã€‚\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/activiation-functions-in-neural-networks/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e æœ¬æ–‡å°†ä»‹ç»ç¥ç»ç½‘ç»œä¸­å¸¸ç”¨çš„å‡ ç§æ¿€æ´»å‡½æ•°çš„ç‰¹æ€§å’Œä½¿ç”¨åœºåˆã€‚\u003c/p\u003e","title":"ç¥ç»ç½‘ç»œé‡Œçš„æ¿€æ´»å‡½æ•°"},{"content":"TL;DR requirements.txtä¸­ä¸è¦ä½¿ç”¨éASCIIç¼–ç çš„å­—ç¬¦ï¼Œå¦åˆ™ä¼šé€ æˆå­—ç¬¦é›†é”™è¯¯ï¼Œæ— æ³•è§£æå†…å®¹\nå®éªŒè®¾è®¡ ä¸¤ä»½requirements.txtæ–‡ä»¶ï¼ŒåŒ…å«ç›¸åŒçš„ä¾èµ–ï¼Œä½†ä¸åŒçš„åœ°æ–¹æ˜¯ï¼šä¸€ä»½æ˜¯ASCIIç¼–ç ï¼ˆæˆ–è€…è¯´åªåŒ…å«è‹±æ–‡å­—ç¬¦ï¼‰ï¼›å¦ä¸€ä»½åŒ…å«éASCIIå­—ç¬¦ï¼ˆæ¯”å¦‚ä¸­æ–‡æ³¨é‡Šä¹‹ç±»çš„ï¼‰ åˆ†åˆ«å®‰è£…ä¸¤ä»½requirements.txtæ–‡ä»¶ï¼Œè§‚å¯Ÿç°è±¡ å®éªŒææ–™ ASCIIç¼–ç çš„requirements.txt å‘½åä¸ºï¼šall_ascii_requirements.txt\nå…·ä½“å†…å®¹å¦‚ä¸‹ï¼š\ndummy éASCIIç¼–ç çš„requirements.txt å‘½åä¸ºï¼šnon_ascii_requirements.txt\nå…·ä½“å†…å®¹å¦‚ä¸‹ï¼š\n# è¿™ä¸ªæ˜¯ä¸­æ–‡æ³¨é‡Š dummy å®éªŒè¿‡ç¨‹ å®‰è£…ASCIIç¼–ç çš„requirements.txt æ‰§è¡Œå‘½ä»¤ pip install -r all_ascii_requirements.txt\nå‘½ä»¤å·¥ä½œæ­£å¸¸ï¼Œè¾“å…¥å†…å®¹å¦‚ä¸‹ï¼š\nCollecting dummy (from -r all_ascii_requirements.txt (line 1)) Downloading dummy-0.1.0.zip Requirement already up-to-date: jinja2\u0026gt;=2.0.0 in /usr/local/lib/python2.7/dist-packages (from dummy-\u0026gt;-r all_ascii_requirements.txt (line 1)) Collecting numpy\u0026gt;=1.0.0 (from dummy-\u0026gt;-r all_ascii_requirements.txt (line 1)) Downloading numpy-1.13.1-cp27-cp27mu-manylinux1_x86_64.whl (16.6MB) 100% |################################| 16.6MB 66kB/s Requirement already up-to-date: mock\u0026gt;=1.0.0 in /usr/local/lib/python2.7/dist-packages (from dummy-\u0026gt;-r all_ascii_requirements.txt (line 1)) Requirement already up-to-date: MarkupSafe\u0026gt;=0.23 in /usr/local/lib/python2.7/dist-packages (from jinja2\u0026gt;=2.0.0-\u0026gt;dummy-\u0026gt;-r all_ascii_requirements.txt (line 1)) Requirement already up-to-date: six\u0026gt;=1.9 in /usr/local/lib/python2.7/dist-packages (from mock\u0026gt;=1.0.0-\u0026gt;dummy-\u0026gt;-r all_ascii_requirements.txt (line 1)) Requirement already up-to-date: funcsigs\u0026gt;=1; python_version \u0026lt; \u0026#34;3.3\u0026#34; in /usr/local/lib/python2.7/dist-packages (from mock\u0026gt;=1.0.0-\u0026gt;dummy-\u0026gt;-r all_ascii_requirements.txt (line 1)) Requirement already up-to-date: pbr\u0026gt;=0.11 in /usr/local/lib/python2.7/dist-packages (from mock\u0026gt;=1.0.0-\u0026gt;dummy-\u0026gt;-r all_ascii_requirements.txt (line 1)) Building wheels for collected packages: dummy Running setup.py bdist_wheel for dummy ... done Stored in directory: /root/.cache/pip/wheels/fb/72/de/c12e171be0c7bff52d4bcebf680bd3b012203c68b8372b02a5 Successfully built dummy Installing collected packages: numpy, dummy Found existing installation: numpy 1.11.0 Uninstalling numpy-1.11.0: Successfully uninstalled numpy-1.11.0 Successfully installed dummy-0.1.0 numpy-1.13.1 å®‰è£…éASCIIç¼–ç çš„requirements.txt æ‰§è¡Œå‘½ä»¤ pip install -r non_ascii_requirements.txt\nå‘½ä»¤å·¥ä½œå‡ºç°å¼‚å¸¸ï¼Œè¾“å‡ºå†…å®¹å¦‚ä¸‹ï¼š\nException: Traceback (most recent call last): File \u0026#34;/usr/local/lib/python2.7/dist-packages/pip/basecommand.py\u0026#34;, line 215, in main status = self.run(options, args) File \u0026#34;/usr/local/lib/python2.7/dist-packages/pip/commands/install.py\u0026#34;, line 312, in run wheel_cache File \u0026#34;/usr/local/lib/python2.7/dist-packages/pip/basecommand.py\u0026#34;, line 295, in populate_requirement_set wheel_cache=wheel_cache): File \u0026#34;/usr/local/lib/python2.7/dist-packages/pip/req/req_file.py\u0026#34;, line 84, in parse_requirements filename, comes_from=comes_from, session=session File \u0026#34;/usr/local/lib/python2.7/dist-packages/pip/download.py\u0026#34;, line 422, in get_file_content content = auto_decode(f.read()) File \u0026#34;/usr/local/lib/python2.7/dist-packages/pip/utils/encoding.py\u0026#34;, line 31, in auto_decode return data.decode(locale.getpreferredencoding(False)) UnicodeDecodeError: \u0026#39;ascii\u0026#39; codec can\u0026#39;t decode byte 0xe8 in position 2: ordinal not in range(128) å®éªŒç»“è®º pipåœ¨è§£ærequirements.txtï¼Œåªèƒ½å¤„ç†ASCIIç¼–ç çš„æ–‡ä»¶ï¼Œå¦åˆ™ä¼šå‡ºç°Unicodeé”™è¯¯ã€‚åœ¨ç¼–å†™requirements.txtæ—¶ï¼Œåˆ‡è®°ä½¿ç”¨ASCIIç¼–ç ï¼Œä¸è¦å¤¹æ‚ä¸­æ–‡ç­‰éASCIIå­—ç¬¦\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/encoding-issue-in-python-requirements/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e requirements.txtä¸­ä¸è¦ä½¿ç”¨éASCIIç¼–ç çš„å­—ç¬¦ï¼Œå¦åˆ™ä¼šé€ æˆå­—ç¬¦é›†é”™è¯¯ï¼Œæ— æ³•è§£æå†…å®¹\u003c/p\u003e","title":"pythonä¸­requirements.txtçš„ç¼–ç é—®é¢˜"},{"content":"TL;DR æœ¬æ–‡ä½¿ç”¨å¼€æºæ¡†æ¶chatterbotä»é›¶å¼€å§‹æ„å»ºä½ è‡ªå·±çš„èŠå¤©æœºå™¨äººï¼ˆè¿˜å¸¦æœ‰WEBç•Œé¢å¥¥ï½ï¼‰ã€‚\nèŠå¤©æœºå™¨äººå¤§ä½“ä¸Šåˆ†ä¸ºä¸‰ç§ï¼šé—²èŠæœºå™¨äººã€é—®ç­”æœºå™¨äººå’Œä»»åŠ¡å‹æœºå™¨äººã€‚é—²èŠæœºå™¨äººï¼Œé¡¾åæ€ä¹‰å°±æ˜¯å’Œä½ é—²èŠæ’ç§‘æ‰“è¯¨çš„æœºå™¨äººï¼Œç›®å‰æ¯”è¾ƒå…¸å‹çš„ä»£è¡¨æ˜¯å¾®è½¯å°å†°ï¼Œå°é»„é¸¡ç­‰ã€‚é—®ç­”æœºå™¨äººæœ‰ä¸€ä¸ªæ ‡å‡†ç­”æ¡ˆåº“ï¼Œå½“ç”¨æˆ·æ¥å’¨è¯¢æ—¶æœºå™¨äººè´Ÿè´£ç†è§£ç”¨æˆ·çš„è¯­æ„ï¼Œç»™å‡ºç¬¦åˆè¯­æ„çš„æ ‡å‡†ç­”æ¡ˆï¼Œç›®å‰æ¯”è¾ƒå…¸å‹çš„åº”ç”¨æ˜¯å„ç±»å’¨è¯¢æœºå™¨äººï¼Œå®¢æœæœºå™¨äººç­‰ã€‚æœ€åä¸€ç±»ï¼šä»»åŠ¡å‹æœºå™¨äººï¼Œé€šè¿‡å’Œå®¢æˆ·çš„æ²Ÿé€šå¸®åŠ©ç”¨æˆ·å®Œæˆç‰¹å®šä»»åŠ¡æ¯”å¦‚å®šæœºç¥¨ã€å®šé—¹é’Ÿç­‰ï¼Œç›®å‰æ¯”è¾ƒå…¸å‹çš„åº”ç”¨æ˜¯å„ç§ç§äººåŠ©ç†ï¼Œè‹¹æœçš„siriç³»ç»Ÿä¹Ÿå…·å¤‡æ­¤ç±»åŠŸèƒ½ã€‚\næˆ‘ä»¬è¿™é‡Œä»‹ç»ä¸€ä¸ªç®€å•æ˜“ç”¨çš„é—²èŠæœºå™¨äººæ¡†æ¶chatterbot website: http://chatterbot.readthedocs.io/\nå…ˆä¸Šä¸€ä¸ªæˆå“å›¾ï¼Œè¿™å°†æ˜¯æˆ‘ä»¬æœ€åå®Œæˆæ—¶çš„æ•ˆæœï¼š\nå®‰è£… pip install chatterbot å¿«é€Ÿå…¥é—¨ï¼ˆtoyçº§åˆ«çš„æ–¹æ¡ˆï¼‰ ä¸‹é¢çš„ä»£ç å®ç°äº†ä¸€ä¸ªtoyèŠå¤©æœºå™¨äºº\n# å¯¼å…¥æ‰€éœ€çš„ä¾èµ– from chatterbot import ChatBot from chatterbot.trainers import ListTrainer chatbot = ChatBot(\u0026#34;SillyRobot\u0026#34;) # è¿™é‡Œåˆ›å»ºäº†æœºå™¨äººå®ä¾‹ï¼Œå¹¶è®¾å®šäº†æœºå™¨äººçš„åå­—ï¼šSillyRobot # å®šä¹‰è®­ç»ƒæ•°æ®é›† conversation = [ \u0026#34;Hello\u0026#34;, \u0026#34;Hi there!\u0026#34;, \u0026#34;How are you doing?\u0026#34;, \u0026#34;I\u0026#39;m doing great.\u0026#34;, \u0026#34;That is good to hear\u0026#34;, \u0026#34;Thank you.\u0026#34;, \u0026#34;You\u0026#39;re welcome.\u0026#34; ] # è®­ç»ƒ chatbot.set_trainer(ListTrainer) chatbot.train(conversation) # å“åº”ç”¨æˆ·è¯·æ±‚ response = chatbot.get_response(\u0026#34;Good morning!\u0026#34;) print(response) ä¸Šè¿°ä»£ç ä¼šè®­ç»ƒä½ ç»™å®šçš„è®­ç»ƒé›†ï¼Œå¹¶æŠŠè®­ç»ƒç»“æœä¿å­˜èµ·æ¥ï¼Œæ²¡æœ‰æŒ‡å®šçš„æƒ…å†µä¸‹ï¼Œä¼šä½¿ç”¨å­˜å‚¨æ¨¡å—chatterbot.storage.SQLStorageAdapterå®Œæˆæ¨¡å‹çš„å­˜å‚¨ã€‚åœ¨å®Œæˆè®­ç»ƒåå°±å¯ä»¥å°†è®­ç»ƒä»£ç ç§»é™¤ï¼Œè¿™æ ·æœºå™¨äººå°±ä¸ä¼šæ¯æ¬¡éƒ½è¦ä»å¤´è®­ç»ƒäº†ã€‚\næ¯”è¾ƒæ­£å¼çš„æ–¹æ¡ˆ ä¸Šé¢çš„æ–¹æ¡ˆä½¿ç”¨çš„è¯­æ–™åº“æ˜¯ç¡¬ç¼–ç åœ¨æ–‡æ¡£ä¸­çš„ï¼Œè¿™åœ¨æ­£å¼é¡¹ç›®ä¸­æ˜¯ä¸åˆé€‚çš„ã€‚ä¸‹é¢ä»‹ç»ä¸€ä¸ªæ¯”è¾ƒæ­£å¼çš„ä½¿ç”¨chatterçš„æ–¹æ¡ˆã€‚\nimport os from chatterbot import ChatBot from chatterbot.trainers import ChatterBotCorpusTrainer current_dir = os.path.dirname(os.path.realpath(__file__)) chat_bot = ChatBot(\u0026#34;SillyRobot\u0026#34;) # è¿™é‡Œåˆ›å»ºäº†æœºå™¨äººå®ä¾‹ï¼Œå¹¶è®¾å®šäº†æœºå™¨äººçš„åå­—ï¼šSillyRobot chat_bot.set_trainer(ChatterBotCorpusTrainer) # ä½¿ç”¨ä¸­æ–‡è¯­æ–™åº“è®­ç»ƒå®ƒ # chat_bot.train(\u0026#34;chatterbot.corpus.chinese\u0026#34;) # è¯­æ–™åº“ # å¼€å§‹å¯¹è¯ response = chat_bot.get_response(\u0026#34;æˆ‘å¥½ä¹ˆ\u0026#34;) print(response) å®˜æ–¹è‡ªå¸¦çš„ä¸­æ–‡èŠå¤©æ•°æ®é›†è¡¨ç°æ¯”è¾ƒå·®ï¼Œä½ éœ€è¦è‡ªå·±å®ç°ä¸€ä¸ªtrainerï¼Œå…·ä½“æ€ä¹ˆå®ç°è§å®˜æ–¹æ–‡æ¡£ Creating a new training class.\nWebé›†æˆ chatterè‡ªå¸¦äº†Djangoé›†æˆï¼Œæ‰€ä»¥å¾ˆå®¹æ˜“æ¶è®¾ä¸€ä¸ªç½‘ç«™ï¼Œæä¾›HTTPæ¥å£ã€ç®¡ç†åå°ä»¥åŠåœ¨çº¿èŠå¤©é¡µé¢ç­‰åŠŸèƒ½ã€‚å…·ä½“ä»£ç å¯ä»¥æ‹·è´å®˜æ–¹çš„ç¤ºä¾‹ä»£ç https://github.com/gunthercox/ChatterBot/tree/master/examples/django_app, è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä½ éœ€è¦æ›´æ”¹chatterbotçš„é…ç½®åœ¨settings.pyé‡Œé¢çš„CHATTERBOTå˜é‡å¤„ï¼Œå…·ä½“æ€ä¹ˆä¿®æ”¹ï¼Œè¯·å‚è€ƒæ–‡æ¡£1å’Œæ–‡æ¡£2,ä½†ä½ ä»ç„¶éœ€è¦ä»¥ä¸‹æ­¥éª¤ï¼š\nå®‰è£…Django pip install django åŒæ­¥æ•°æ®åº“ python manage.py migrate åˆ›å»ºè¶…çº§ç”¨æˆ· python manage.py createsuperuser è®­ç»ƒchatterbot python manage.py train è¿è¡Œserver python manage.py runserver webæœåŠ¡å™¨é»˜è®¤ç›‘å¬5000ç«¯å£ï¼Œè®¿é—®http://127.0.0.0.1:5000å°±èƒ½è®¿é—®é¡µé¢äº†ï¼Œé¡µé¢æ•ˆæœå¦‚ä¸‹å›¾ï¼š\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/building-your-own-chitbot-using-chatterbot/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e æœ¬æ–‡ä½¿ç”¨å¼€æºæ¡†æ¶chatterbotä»é›¶å¼€å§‹æ„å»ºä½ è‡ªå·±çš„èŠå¤©æœºå™¨äººï¼ˆè¿˜å¸¦æœ‰WEBç•Œé¢å¥¥ï½ï¼‰ã€‚\u003c/p\u003e","title":"ä½¿ç”¨chatterbotæ„å»ºè‡ªå·±çš„ä¸­æ–‡chat(é—²èŠ)æœºå™¨äºº"},{"content":"TL;DR å¼ƒå‘wordpressï¼Œèµ°å‘hexo\nä¸€ç›´ä»¥æ¥ï¼Œæˆ‘éƒ½æ˜¯ä½¿ç”¨wordpressæ¥å†™åšå®¢ï¼Œä»Octopressæ—¶ä»£å°±æƒ³å°è¯•é™æ€åšå®¢ç³»ç»Ÿçš„ï¼Œä½†ç”±äºæƒ°æ€§ä½¿ç„¶ï¼Œä¸€ç›´ä¹Ÿå°±ç”¨ç€wordpressã€‚ æœ€è¿‘ä¸¤ä¸ªäº‹æƒ…è®©æˆ‘ç»ˆäºä¸‹å®šå†³å¿ƒè¦åˆ‡æ¢åšå®¢ç³»ç»Ÿäº†ï¼šä¸€æ˜¯wordpressçš„markdownæ”¯æŒå®åœ¨å¤ªçƒ‚ï¼Œç”¨äº†ä¸å°‘ç›¸å…³æ’ä»¶ä½†æ˜¯è¿˜æ˜¯ä¸å¥½ç”¨ï¼›äºŒæ˜¯wordpressé‡Œé¢æ²¡æœ‰ä¸€ä¸ªè®©æˆ‘ç§°å¿ƒå¦‚æ„çš„ä¸»é¢˜,hexoçš„Nextä¸»é¢˜ç¡®å®å¾ˆé€‚åˆç å†œï¼Œæˆ‘åœ¨wordpressä¸–ç•Œé‡Œæ‰¾ä¸åˆ°ç±»ä¼¼çš„ä¸»é¢˜ã€‚æ‰€ä»¥ï¼Œè¿˜æ˜¯é€‰æ‹©è¿½éšæ½®æµï¼Œå¾ˆå¤šæŠ€æœ¯äººéƒ½é€‰æ‹©äº†hexoï¼Œæˆ‘æƒ³åº”è¯¥æ˜¯æœ‰ä¿éšœçš„,åˆå¼€å§‹æŠ˜è…¾ä¹‹è·¯ã€‚\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/bye-wordpress-and-hello-hexo/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e å¼ƒå‘wordpressï¼Œèµ°å‘hexo\u003c/p\u003e","title":"å†è§wordpress,ä½ å¥½hexo"},{"content":"TL;DR mapå‡½æ•°åŠå…¶ç±»ä¼¼å‡½æ•°åœ¨python2å’Œpython3ä¸‹è¡¨ç°å·®å¼‚å¾ˆå¤§ï¼Œpy2ä¸‹è¿”å›listï¼Œè€Œpy3ä¸‹è¿”å›è¿­ä»£å™¨ã€‚è§£å†³åŠæ³•æ˜¯ä½¿ç”¨listå‡½æ•°æ˜¾å¼æ±‚å€¼ã€‚\nä¸‹é¢æ˜¯å…³äºmapå‡½æ•°çš„ä»£ç ç¤ºä¾‹ï¼Œé€è¿‡åœ¨python2å’Œpython3ä¸åŒè¡Œä¸ºï¼Œä¸ºä½ å±•ç°ä¸åŒï¼š\nå¯¼å…¥ç›¸å…³æ¨¡å—\nimport time å®šä¹‰æˆ‘ä»¬çš„taskå‡½æ•°ï¼Œé€šè¿‡æ‰“å°è¾“å‡ºè®©æˆ‘ä»¬äº†è§£å®é™…å·¥ä½œæƒ…å†µ\ndef task(x): print(\u0026#34;round: {}, I am start to sleep\u0026#34;.format(x)) time.sleep(1) print(\u0026#34;round: {}, I am finished sleep\u0026#34;.format(x)) return pow(x, 2) å°†å¯è¿­ä»£å¯¹è±¡mapåˆ°taskå‡½æ•°\nmap(task, range(4)) python2ä¸­çš„mapå‡½æ•° åœ¨python2ä¸­æ‰§è¡Œä»¥ä¸Šä»£ç ï¼Œå¯ä»¥å¾—åˆ°å¦‚ä¸‹è¾“å‡ºï¼š\nround: 0, I am start to sleep round: 0, I am finished sleep round: 1, I am start to sleep round: 1, I am finished sleep round: 2, I am start to sleep round: 2, I am finished sleep round: 3, I am start to sleep round: 3, I am finished sleep [0, 1, 4, 9] python3ä¸­çš„mapå‡½æ•° åœ¨python3ä¸­æ‰§è¡Œä»¥ä¸Šä»£ç ï¼Œå¯ä»¥å¾—åˆ°å¦‚ä¸‹è¾“å‡ºï¼š\n\u0026lt;map at 0x7f9df0559b00\u0026gt; å¾ˆä¸å¹¸ï¼Œä½ çš„taskä»£ç å¹¶æ²¡æœ‰æ‰§è¡Œï¼Œæ— è®ºæ˜¯æ‰“å°è¾“å‡ºè¿˜æ˜¯è¿”å›å€¼ï¼Œéƒ½æ²¡æœ‰æ‰§è¡Œã€‚ é‚£æ˜¯å› ä¸ºpython2ä¸­çš„mapæ˜¯Apply function to every item of iterable and return a list of the results.è€Œpython3ä¸­çš„mapæ˜¯Return an iterator that applies function to every item of iterable, yielding the results.\nè¿™ä¸ªä¾‹å­ä¸­ï¼Œä½¿ç”¨äº†äº¤äº’å¼ç¼–ç¨‹ï¼Œç”¨æˆ·å¯ä»¥ç›´è§‚çš„çœ‹åˆ°è¿”å›ç»“æœï¼Œä½†æ˜¯åœ¨éäº¤äº’å¼ä½¿ç”¨åœºæ™¯ï¼ˆæ¯”å¦‚ä½œä¸ºæ¨¡å—è¿è¡Œï¼‰æ—¶ï¼Œå¦‚æœæ²¡æœ‰æ”¶é›†è¿”å›å€¼ä¹Ÿæ²¡æœ‰ç±»ä¼¼æ‰“å°è¾“å‡ºçš„æƒ…å†µä¸‹ï¼Œä¸€åˆ‡çœ‹ä¼¼æ­£å¸¸ï¼Œä½†å®é™…æ²¡æœ‰è¿è¡Œçš„æƒ…å†µï¼Œå°†é€ æˆéš¾ä»¥è°ƒè¯•çš„bugã€‚\nè§£å†³ä¸åŒ å¦‚ä½•æ‰èƒ½è®©python3çš„mapå‡½æ•°çš„è¡Œä¸ºå’Œpython2çš„ä¸€æ ·å‘¢ï¼Ÿ\nç­”æ¡ˆæ˜¯ä½¿ç”¨listå‡½æ•°ï¼Œå°†ä¸Šè¿°ä»£ç ç¨ä½œæ”¹åŠ¨ï¼š\nlist(map(task, range(4))) é‚£ä¹ˆä½ å°†å¾—åˆ°è¾“å‡ºï¼š\nround: 0, I am start to sleep round: 0, I am finished sleep round: 1, I am start to sleep round: 1, I am finished sleep round: 2, I am start to sleep round: 2, I am finished sleep round: 3, I am start to sleep round: 3, I am finished sleep [0, 1, 4, 9] è¿™å°†å’Œpython2ä¸€æ¨¡ä¸€æ ·ã€‚\næ›´å¤§èŒƒå›´çš„ä¸åŒ å¾ˆä¸å¹¸çš„æ˜¯python2å’Œpython3çš„å·®å¼‚ä¸ä»…ä»…åœ¨ä¸€ä¸ªmapå‡½æ•°ä¸Šï¼Œå¾ˆå¤šå‡½æ•°ä¹Ÿå­˜åœ¨ç±»ä¼¼çš„å·®å¼‚ï¼Œå¦‚multiprocessingæ¨¡å—çš„Poolç±»çš„imap_unorderedå’Œmapæ–¹æ³•ï¼Œå®é™…ä¸Špython2å’Œpython3å·®å¼‚è¿˜æ˜¯æ¯”è¾ƒå¤§çš„ï¼Œæ‰€ä»¥å¦‚æœé‡åˆ°å…¼å®¹æ€§é—®é¢˜ï¼Œç¬¬ä¸€ä»¶äº‹æƒ…å°±æ˜¯ç«‹å³æŸ¥é˜…å®˜æ–¹æ–‡æ¡£ã€‚\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/the-difference-of-map-function-in-python-2-and-python-3/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e mapå‡½æ•°åŠå…¶ç±»ä¼¼å‡½æ•°åœ¨python2å’Œpython3ä¸‹è¡¨ç°å·®å¼‚å¾ˆå¤§ï¼Œpy2ä¸‹è¿”å›listï¼Œè€Œpy3ä¸‹è¿”å›è¿­ä»£å™¨ã€‚è§£å†³åŠæ³•æ˜¯ä½¿ç”¨listå‡½æ•°æ˜¾å¼æ±‚å€¼ã€‚\u003c/p\u003e","title":"mapå‡½æ•°ä¸ç›¸ä¼¼å‡½æ•°åœ¨python2å’Œpython3ä¸­çš„ä¸åŒ"},{"content":"TL;DR æŒ‡å®šmetadata_pathæ—¶ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„ä¼šé€ æˆtensorboardæ‰¾ä¸åˆ°æ–‡ä»¶ã€‚è§£å†³åŠæ³•ï¼šä½¿ç”¨ç»å¯¹è·¯å¾„\nTensorBoardçš„embeddingè½½å…¥æ—¶å¡ç€ä¸åŠ¨ TensorBoardçš„EmbeddingåŠŸèƒ½ï¼Œç»™å›¾ç‰‡å’Œæ–‡å­—çš„ä¸‰ç»´ç›´è§‚å±•ç¤ºæä¾›äº†å¯èƒ½ï¼Œè¿™äº›ä¸œè¥¿é€šå¸¸æƒ…å†µä¸‹éœ€è¦ä¸€ä¸ªäººç±»å¯è¯»çš„metaä¿¡æ¯ï¼šè¿™ä¸ªä¿¡æ¯åœ¨TensorBoardä¸­å«åšmetadataã€‚\nä½ å¯ä»¥ä»https://www.tensorflow.org/versions/r1.3/programmers_guide/embeddingè·å–æ›´å¤šå®˜æ–¹æ–‡æ¡£\nåŸå› åˆ†æ å¦‚ä¸‹æ˜¯å®˜æ–¹ä»£ç ç¤ºä¾‹\nfrom tensorflow.contrib.tensorboard.plugins import projector # Create randomly initialized embedding weights which will be trained. vocabulary_size = 10000 embedding_size = 200 embedding_var = tf.get_variable('word_embedding', [vocabulary_size, embedding_size]) # Format: tensorflow/tensorboard/plugins/projector/projector_config.proto config = projector.ProjectorConfig() # You can add multiple embeddings. Here we add only one. embedding = config.embeddings.add() embedding.tensor_name = embedding_var.name # Link this tensor to its metadata file (e.g. labels). embedding.metadata_path = os.path.join(LOG_DIR, 'metadata.tsv') # Use the same LOG_DIR where you stored your checkpoint. summary_writer = tf.summary.FileWriter(LOG_DIR) # The next line writes a projector_config.pbtxt in the LOG_DIR. TensorBoard will # read this file during startup. projector.visualize_embeddings(summary_writer, config) ä¸Šé¢çš„ä»£ç ä¸­ï¼Œä¸»è¦æ˜¯é€šè¿‡projectorå¯¹è±¡å°†tensorå˜é‡embedding_varå’Œmetadata_pathå…³è”äº†èµ·æ¥ï¼Œéšåè¿™ä¸ªå…³è”ä¿¡æ¯è¢«summary_writerå†™å…¥äº†é…ç½®æ–‡ä»¶ã€‚\nå¾ˆå¤šäººçš„ä»£ç å®ç°ï¼Œåœ¨è¿è¡Œæ—¶æ²¡æœ‰ä»»ä½•é—®é¢˜ï¼Œä½†æ˜¯åœ¨ä½¿ç”¨tensorboardä¸­è¿›è¡Œembeddingå¯è§†åŒ–çš„æ—¶å€™ï¼Œå´ä¸€ç›´å¡åœ¨åŠ è½½metadataçš„è¿‡ç¨‹ä¸­ã€‚å…·ä½“åŸå› æ˜¯åœ¨æŒ‡å®šembedding.metadata_pathæ—¶ï¼Œä½¿ç”¨äº†ç›¸å¯¹è·¯å¾„æ¥æŒ‡å®šæ–‡ä»¶ä½ç½®ï¼Œä½†æ˜¯è¿™ä¸ªæ–‡ä»¶ä½ç½®æ˜¯ç›¸å¯¹logç›®å½•çš„ï¼Œtensorboardåœ¨å¯åŠ¨çš„æ—¶å€™ç»å¤§å¤šæ•°æƒ…å†µä¸‹ä¸æ˜¯åœ¨logæ‰€åœ¨çš„ç›®å½•ä¸­å¯åŠ¨çš„ï¼Œè¿™æ—¶ä»tensorboardçš„è§’åº¦æ¥æ‰¾è¿™ä¸ªç›¸å¯¹æ–‡ä»¶ï¼Œå°±æ— æ³•æ‰¾åˆ°ï¼Œå› æ­¤å‡ºç°äº†è½½å…¥å¡ä½çš„æƒ…å†µã€‚\nPS stackoverflow ä¹Ÿæœ‰äººæ³¨æ„åˆ°äº†è¿™ä¸ªissueï¼Œå¹¶ç»™å‡ºäº†ç›¸åŒçš„ç­”æ¡ˆ\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/solution-for-tensorboard-embedding-blocked-when-loading-metadata/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e æŒ‡å®š\u003ccode\u003emetadata_path\u003c/code\u003eæ—¶ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„ä¼šé€ æˆtensorboardæ‰¾ä¸åˆ°æ–‡ä»¶ã€‚è§£å†³åŠæ³•ï¼šä½¿ç”¨ç»å¯¹è·¯å¾„\u003c/p\u003e","title":"TensorBoardçš„embeddingå¡åœ¨Loading metadataçš„è§£å†³æ–¹æ¡ˆ"},{"content":"TL;DR Descriptoræ˜¯Pythonå®ç°streagyæ¨¡å¼çš„ä¸€ç§å˜å½¢ï¼Œå®ƒå°†å±æ€§çš„è®¿é—®ï¼ä¿®æ”¹ï¼åˆ é™¤å§”æ‰˜ç»™äº†Descriptorã€‚\nDescriptor ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š\nclass Descriptor(object): class_var = \u0026#34;cls\u0026#34; def __init__(self, *args, **kwargs): # Here the `super` is differ from python2: super(Descriptor, self) super().__init__(*args, **kwargs) def __get__(self, instance, owner): print(\u0026#34;==\u0026#34;) print(instance, owner) return None def __set__(self, instance, value): print(instance, value) def __delete__(self, instance): print(instance) class Host(object): desc = Descriptor() norm = 1 host = Host() host.desc host.norm == \u0026lt;__main__.Host object at 0x7ff7dbff5d68\u0026gt; \u0026lt;class \u0026#39;__main__.Host\u0026#39;\u0026gt; 1 host.desc = 2 host.norm = 2 \u0026lt;__main__.Host object at 0x7ff7dbff5d68\u0026gt; 2 desc = Descriptor() desc.__get__(None, None) == None None ","permalink":"https://blog.xiaoquankong.ai/zh/posts/introduce-to-python-descriptor/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e Descriptoræ˜¯Pythonå®ç°streagyæ¨¡å¼çš„ä¸€ç§å˜å½¢ï¼Œå®ƒå°†å±æ€§çš„è®¿é—®ï¼ä¿®æ”¹ï¼åˆ é™¤å§”æ‰˜ç»™äº†Descriptorã€‚\u003c/p\u003e","title":"Pythonæè¿°å™¨"},{"content":"TL;DR Pythonçš„é»˜è®¤å‚æ•°å®ç°æœºåˆ¶å¾ˆå®¹æ˜“å¯¼è‡´éš¾ä»¥è°ƒè¯•çš„bugã€‚æ­£ç¡®çš„ä½¿ç”¨æ–¹æ³•æ˜¯é¿å…ä½¿ç”¨å¯å˜ç±»å‹ä½œä¸ºé»˜è®¤å‚æ•°ã€‚\né»˜è®¤å¯å˜å‚æ•°å¸¦æ¥çš„é—®é¢˜ å‡½æ•°çš„é»˜è®¤å‚æ•°å¦‚æœæ˜¯å¯å˜ç±»å‹çš„å˜é‡ï¼Œå¯èƒ½ä¼šå¸¦æ¥éš¾ä»¥debugçš„bugã€‚defå®šä¹‰çš„å‡½æ•°ï¼Œåœ¨è§£é‡Šå™¨å®šä¹‰ä¸ºå‡½æ•°æ—¶ï¼Œä¼šè®¡ç®—é»˜è®¤å‚æ•°çš„å€¼ï¼Œå¹¶å°†å€¼å­˜å‚¨åœ¨ func_defaults å±æ€§ä¸­ï¼Œå¹¶ä¸”è¯¥é»˜è®¤å€¼åªä¼šåˆå§‹åŒ–ä¸€æ¬¡\ndef append_to_list(item, list_=[]): list_.append(item) print(list_) print(\u0026#34;.func_defaults:\u0026#34;, append_to_list.func_defaults) append_to_list(0) print(\u0026#34;.func_defaults:\u0026#34;, append_to_list.func_defaults) append_to_list(1) print(\u0026#34;.func_defaults:\u0026#34;, append_to_list.func_defaults) è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º:\n(\u0026#39;.func_defaults:\u0026#39;, ([],)) [0] (\u0026#39;.func_defaults:\u0026#39;, ([0],)) [0, 1] (\u0026#39;.func_defaults:\u0026#39;, ([0, 1],)) è§£å†³æ–¹æ¡ˆ def append_to_list(item, list_=None): if list_ is None: list_ = [] list_.append(item) print(list_) print(\u0026#34;.func_defaults:\u0026#34;, append_to_list.func_defaults) append_to_list(0) print(\u0026#34;.func_defaults:\u0026#34;, append_to_list.func_defaults) append_to_list(1) print(\u0026#34;.func_defaults:\u0026#34;, append_to_list.func_defaults) è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º:\n(\u0026#39;.func_defaults:\u0026#39;, (None,)) [0] (\u0026#39;.func_defaults:\u0026#39;, (None,)) [1] (\u0026#39;.func_defaults:\u0026#39;, (None,)) å‚è€ƒ ç¼–å†™é«˜è´¨é‡Pythonä»£ç çš„91ä¸ªå»ºè®® ç¬¬32ä¸ªå»ºè®® ","permalink":"https://blog.xiaoquankong.ai/zh/posts/default-arguments-in-python-function/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e Pythonçš„é»˜è®¤å‚æ•°å®ç°æœºåˆ¶å¾ˆå®¹æ˜“å¯¼è‡´éš¾ä»¥è°ƒè¯•çš„bugã€‚æ­£ç¡®çš„ä½¿ç”¨æ–¹æ³•æ˜¯é¿å…ä½¿ç”¨å¯å˜ç±»å‹ä½œä¸ºé»˜è®¤å‚æ•°ã€‚\u003c/p\u003e","title":"Pythonå‡½æ•°é»˜è®¤å‚æ•°çš„é—®é¢˜"},{"content":"TL;DR ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€šè¿‡æ§åˆ¶ä»£ç å—çº§åˆ«çš„ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥å®ç°çš„å¾ˆå¤šè¯¸å¦‚è‡ªåŠ¨å…³é—­æ–‡ä»¶ã€æ•è·å¼‚å¸¸ç­‰åŠŸèƒ½\nä»€ä¹ˆæ˜¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨ ä¸Šä¸‹æ–‡ç®¡ç†å™¨ context manager èƒ½å¤Ÿæ§åˆ¶ç¨‹åºæ‰§è¡Œçš„ä¸Šä¸‹æ–‡,æ¯”å¦‚æ§åˆ¶æ–‡ä»¶çš„å…³é—­,æŠ‘åˆ¶å¼‚å¸¸,æ•è·å¼‚å¸¸,ä¿®æ”¹ä¸Šä¸‹æ–‡å˜é‡ç­‰\nè°ƒç”¨è¿‡ç¨‹ ç®€å•ä¾‹å­ class Context(object): def __enter__(self): print(\u0026quot;__enter__ invoked\u0026quot;) def __exit__(self, exc_type, exc_val, exc_tb): print(\u0026quot;__exit__ invoked\u0026quot;) with Context(): print(\u0026quot;with block\u0026quot;) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`__enter__ invoked with block __exit__ invoked `\u0026lt;/pre\u0026gt; ### ä¸­çº§å¤æ‚çš„ä¾‹å­ \u0026lt;pre\u0026gt;`class ContextInstance(object): def __init__(self, msg): self.msg = msg def say(self): print(self.msg) def when_exit(self): print(\u0026quot;instance exited!\u0026quot;) class Context(object): def __init__(self, msg): self.msg = msg self.instance = None super(Context, self).__init__() def __enter__(self): print(\u0026quot;__enter__ invoked\u0026quot;) self.instance = ContextInstance(self.msg) return self.instance def __exit__(self, exc_type, exc_val, exc_tb): print(\u0026quot;__exit__ invoked\u0026quot;) self.instance.when_exit() with Context(\u0026quot;Message\u0026quot;) as ctx: ctx.say() print(\u0026quot;within block\u0026quot;) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`__enter__ invoked Message within block __exit__ invoked instance exited! `\u0026lt;/pre\u0026gt; ### å¤æ‚ä¾‹å­ \u0026lt;pre\u0026gt;`class ContextManager(object): def __init__(self, msg): self.msg = msg self.instance = None super(ContextManager, self).__init__() def __enter__(self): print(\u0026quot;__enter__ invoked\u0026quot;) self.instance = ContextInstance(self.msg) return self.instance def __exit__(self, exc_type, exc_val, exc_tb): print(\u0026quot;__exit__ invoked\u0026quot;) self.instance.when_exit() class ContextInstance(object): def __init__(self, msg): self.msg = msg super(ContextInstance, self).__init__() def say(self): print(self.msg) def when_exit(self): print(\u0026quot;instance existed!\u0026quot;) with ContextManager(\u0026quot;Message\u0026quot;) as ctx: ctx.say() print(\u0026quot;with block\u0026quot;) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`__enter__ invoked Message with block __exit__ invoked instance existed! `\u0026lt;/pre\u0026gt; ## ä½¿ç”¨åœºæ™¯ ### æ§åˆ¶æ–‡ä»¶å…³é—­ \u0026lt;pre\u0026gt;`with open(\u0026quot;/tmp/context_manager.txt\u0026quot;, 'wt') as f: f.write(\u0026quot;contexts go here\u0026quot;) `\u0026lt;/pre\u0026gt; ### æŠ‘åˆ¶å¼‚å¸¸ \u0026lt;pre\u0026gt;`class Context(object): def __enter__(self): return self def __exit__(self, exc_type, exc_val, exc_tb): # supress all the exception return True with Context(): print(\u0026quot;start\u0026quot;) raise ValueError(\u0026quot;E!\u0026quot;) print(\u0026quot;end\u0026quot;) print(\u0026quot;next\u0026quot;) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`start next `\u0026lt;/pre\u0026gt; ### æ•è·å¼‚å¸¸ \u0026lt;pre\u0026gt;`# TODOï¼š see unittest catch exceptioon `\u0026lt;/pre\u0026gt; ### ä¿®æ”¹ä¸Šä¸‹æ–‡ \u0026lt;pre\u0026gt;`env_context = [] class Context(object): def __enter__(self): env_context.append(1) def __exit__(self, exc_type, exc_val, exc_tb): env_context.pop() print(\u0026quot;before with\u0026quot;, len(env_context)) with Context(): print(\u0026quot;in with\u0026quot;, len(env_context)) print(\u0026quot;after with\u0026quot;, len(env_context)) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`('before with', 0) ('in with', 1) ('after with', 0) `\u0026lt;/pre\u0026gt; ## contextlib åº“ contextlibæ˜¯Pythonå®˜æ–¹åŒ…ï¼Œä½¿ç”¨contenxtlibå¯ä»¥å¾ˆæ–¹ä¾¿çš„æ„å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨ ### contextlib.contextmanager #### ç®€å•ç”¨æ³• \u0026lt;pre\u0026gt;`import contextlib @contextlib.contextmanager def context(): print(\u0026quot;before yeild\u0026quot;) yield [] print(\u0026quot;after yeild\u0026quot;) with context() as value: print(\u0026quot;before value\u0026quot;) print(value) print(\u0026quot;after value\u0026quot;) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`before yeild before value [] after value after yeild `\u0026lt;/pre\u0026gt; #### æ•è·å¼‚å¸¸ \u0026lt;pre\u0026gt;`import contextlib @contextlib.contextmanager def context(): print(\u0026quot;before yeild\u0026quot;) try: yield except ValueError as e: print(e) print(\u0026quot;after yeild\u0026quot;) with context(): raise ValueError(\u0026quot;NO\u0026quot;) print(\u0026quot;after exception\u0026quot;) print(\u0026quot;after with\u0026quot;) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`before yeild NO after yeild after with `\u0026lt;/pre\u0026gt; ### åµŒå¥—çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ (Nesting contexts) \u0026lt;pre\u0026gt;`import contextlib @contextlib.contextmanager def context(name): print(\u0026quot;entring %s\u0026quot; % name) yield name print(\u0026quot;exiting %s\u0026quot; % name) with contextlib.nested(context('a'), context('b'), context('c')) as (a, b, c): print(\u0026quot;inside with statement: %s\u0026quot; % ((a, b, c), )) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`entring a entring b entring c inside with statement: ('a', 'b', 'c') exiting c exiting b exiting a /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: With-statements now directly support multiple context managers if __name__ == '__main__': `\u0026lt;/pre\u0026gt; è§‚å¯Ÿè¾“å‡ºï¼Œä½ ä¼šå‘ç°ï¼ŒåµŒå¥—çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨å·¥ä½œèµ·æ¥åƒæ˜¯å…ˆå…¥åå‡ºçš„æ ˆä¸€æ ·ï¼šæœ€å…ˆè¿›å…¥çš„ç®¡ç†å™¨æœ€åé€€å‡ºï¼Œæœ€åè¿›å…¥çš„ç®¡ç†å™¨æœ€å…ˆé€€å‡ºã€‚ åŒæ—¶ä½ åº”è¯¥è§‚å¯Ÿåˆ°ä¸€ä¸ªWarningï¼šDeprecationWarning: With-statements now directly support multiple context managersã€‚contextlib.nestedå‡½æ•°å°†äºåç»­Pythonç‰ˆæœ¬è¢«å¼ƒç”¨ï¼ŒPython 2.7å¼•å…¥äº†åµŒå¥—ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ–°è¯­æ³•ã€‚ #### Python 2.7 ç‰ˆæœ¬çš„æ–°è¯­æ³• (py2.7 now support nested) \u0026lt;pre\u0026gt;`import contextlib @contextlib.contextmanager def context(name): print(\u0026quot;entring %s\u0026quot; % name) yield name print(\u0026quot;exiting %s\u0026quot; % name) with context('a') as a, context('b') as b, context('c') as c: print(\u0026quot;inside with statement: %s\u0026quot; % ((a, b, c), )) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`entring a entring b entring c inside with statement: ('a', 'b', 'c') exiting c exiting b exiting a `\u0026lt;/pre\u0026gt; ### è‡ªåŠ¨å…³é—­çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ (closing context) `contextlib.closing`ç­‰ä»·ä¸å¦‚ä¸‹ä»£ç : \u0026lt;pre\u0026gt;`import contextlib @contextlib.contextmanager def closing(thing): try: yield thing finally: thing.close() `\u0026lt;/pre\u0026gt; ### ç®€å•ä¾‹å­ \u0026lt;pre\u0026gt;`import contextlib class Door(): def close(self): print(\u0026quot;Door closing\u0026quot;) def do_something(self): print(\u0026quot;doing something\u0026quot;) try: with contextlib.closing(Door()) as door: door.do_something() raise ValueError(\u0026quot;Exception raising\u0026quot;) except ValueError as e: print(e) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`doing something Door closing Exception raising `\u0026lt;/pre\u0026gt; ### æ›¿ä»£çš„ä¾‹å­ \u0026lt;pre\u0026gt;`import contextlib @contextlib.contextmanager def closing(thing): try: yield thing finally: thing.close() class Door(): def close(self): print(\u0026quot;Door closing\u0026quot;) def do_something(self): print(\u0026quot;doing something\u0026quot;) try: with closing(Door()) as door: door.do_something() raise ValueError(\u0026quot;Exception raising\u0026quot;) except ValueError as e: print(e) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`doing something Door closing Exception raising `\u0026lt;/pre\u0026gt; ### å®é™…çš„ä¾‹å­ \u0026lt;pre\u0026gt;`from contextlib import closing import urllib fair_license_url = 'http://www.samurajdata.se/opensource/mirror/licenses/fair.txt' with closing(urllib.urlopen(fair_license_url)) as page: for line in page: print(line) `\u0026lt;/pre\u0026gt; è¿è¡Œä»¥ä¸Šä»£ç ï¼Œåˆ™ä¼šæœ‰å¦‚ä¸‹è¾“å‡º: \u0026lt;pre\u0026gt;`Fair License \u0026amp;lt;Copyright Information\u0026amp;gt; Usage of the works is permitted provided that this instrument is retained with the works, so that any entity that uses the works is notified of this instrument. DISCLAIMER: THE WORKS ARE WITHOUT WARRANTY. [2004, Fair License: rhid.com/fair] å‚è€ƒ Pythonå®˜æ–¹contexlibåº“æ–‡æ¡£ ","permalink":"https://blog.xiaoquankong.ai/zh/posts/introduce-to-context-manager-in-python/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€šè¿‡æ§åˆ¶ä»£ç å—çº§åˆ«çš„ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥å®ç°çš„å¾ˆå¤šè¯¸å¦‚è‡ªåŠ¨å…³é—­æ–‡ä»¶ã€æ•è·å¼‚å¸¸ç­‰åŠŸèƒ½\u003c/p\u003e","title":"Python context manager ä¸Šä¸‹æ–‡ç®¡ç†å™¨"},{"content":"TL;DR Git Flowæ˜¯ä¸€ç§å¾—åˆ°å¹¿æ³›è®¤å¯çš„æ¨¡å‹ï¼Œé€šè¿‡ç¡®å®šåˆ†æ”¯çš„å®é™…ç”¨é€”ï¼ˆmaster/develop/featureç­‰ï¼‰ï¼Œè¾¾åˆ°å›¢é˜Ÿå…±åŒè®¤çŸ¥è®¤å¯å…¨éƒ¨å¼€å‘è¿‡ç¨‹æ•ˆæœã€‚\nä¸ºä»€ä¹ˆéœ€è¦Gitå¼€å‘è§„èŒƒï¼ˆæ¨¡å‹ï¼‰ éšç€Gitçš„æ™®åŠï¼Œå‡ ä¹æ‰€æœ‰çš„å¼€å‘å›¢é˜Ÿéƒ½åœ¨ä½¿ç”¨Gitè¿›è¡Œç‰ˆæœ¬ç®¡ç†å’Œå›¢é˜Ÿåä½œã€‚ä½†æ˜¯Gitæœ¬èº«æä¾›çš„åŠŸèƒ½å¾ˆå¤šï¼Œçµæ´»æ€§å¤ªå¤§ï¼Œæ¯ä¸ªäººéƒ½å¯ä»¥æœ‰è‡ªå·±çš„ä½¿ç”¨æ–¹å¼å’Œä»£ç ç®¡ç†é£æ ¼ã€‚\næ··ä¹±çš„å¼€å‘æµç¨‹ å¦‚æœæ•´ä¸ªå›¢é˜Ÿæ²¡æœ‰ä¸€ä¸ªå…±åŒçš„Gitä½¿ç”¨å…±è¯†ï¼Œé‚£ä¹ˆåˆä½œèµ·æ¥éœ€è¦æ²Ÿé€šå’Œä½œå‡ºå¦¥åï¼Œæ²Ÿé€šä¸ç•…çš„æƒ…å†µä¸‹è¿˜å¯èƒ½å¯¼è‡´çš„é—®é¢˜ã€‚\nè½»åˆ™ï¼Œåˆ†æ”¯åå­—åƒå¥‡ç™¾æ€ªï¼šæœ‰çš„ç”¨æ—¥æœŸï¼Œæœ‰çš„ç”¨åŠŸèƒ½åç§°ï¼Œæœ‰çš„ç”¨Bugç¼–å·ï¼Œæœ‰çš„ç”¨å¼€å‘è€…è‡ªå·±çš„åå­—ï¼Œç”šè‡³æ˜¯æ··åˆä½“ï¼›æœ¬åœ°åˆ†æ”¯å’Œè¿œç¨‹åˆ†æ”¯å‡ åä¸ªï¼Œè°ä¹Ÿä¸çŸ¥é“å…·ä½“çš„åˆ†æ”¯æ˜¯åšä»€ä¹ˆçš„ã€‚\nä¸¥é‡çš„æƒ…å†µåˆ™æ¯”å¦‚ï¼š\nAå‘masteræäº¤äº†æœªç»æµ‹è¯•çš„ä¸‹ä¸€ä¸ªè¿­ä»£æˆ–è€…ç‰ˆæœ¬æ‰ä¼šä¸Šçº¿çš„ä»£ç ï¼Œå¹¶pushåˆ°äº†æœåŠ¡å™¨ï¼Œè¿™ä¸ªæ—¶å€™çº¿ä¸Šä»£ç å‡ºç°é—®é¢˜éœ€è¦ç´§æ€¥ä¿®å¤ï¼ŒBè´Ÿè´£æ­¤äº‹ï¼Œä»–æ²¡æœ‰å’ŒAæ²Ÿé€šï¼Œè®¤ä¸ºmasterä¸Šçš„ä»£ç å°±æ˜¯çº¿ä¸Šä»£ç ï¼Œç›´æ¥pullä¸‹æ¥ï¼Œä¿®å¤äº†bugæ‰€åœ¨çš„ä»£ç ç‰‡æ®µï¼Œå¹¶å°†ä»£ç å‘å¸ƒåˆ°äº†çº¿ä¸Šï¼Œè¿™ä¸ªæ—¶å€™Aæäº¤çš„æœªç»æµ‹è¯•çš„ä»£ç å‡ºç°åœ¨äº†çº¿ä¸Šï¼ŒåŒæ—¶ç”±äºæœªç»è¿‡æµ‹è¯•æ‰€ä»¥å‡ºç°äº†å¾ˆä¸¥é‡çš„Bugå¯¼è‡´ç³»ç»Ÿä¸å¯ç”¨ã€‚\nè¿™ç§æƒ…å†µåœ¨å›¢é˜Ÿäººå‘˜æ°´å¹³å‚å·®ä¸é½æˆ–è€…æ¥è‡ªä¸åŒçš„å°ç»„ï¼Œç¼ºä¹è‰¯å¥½æ²Ÿé€šå’Œåˆä½œç»éªŒçš„æƒ…å†µä¸‹ï¼Œå¾ˆæœ‰å¯èƒ½ä¼šå‡ºç°ã€‚\nå¸¸è§çš„Gitè§„èŒƒ é’ˆå¯¹è¿™ç§æƒ…å†µï¼Œè¿™ä¸ªå›¢é˜Ÿéœ€è¦ä¸€ä¸ªå…¨å‘˜éƒ½è®¤å¯å¹¶çŸ¥æ™“çš„Gitä»£ç ç®¡ç†è§„èŒƒï¼Œè¿™ç§è§„èŒƒæœ€å¥½æ˜¯ç»è¿‡é•¿æ—¶é—´å·¥ç¨‹å®è·µè€ƒéªŒçš„ï¼Œé€šç”¨çš„ï¼Œå®¹æ˜“å­¦ä¹ å’Œçµæ´»çš„ã€‚ç›®å‰å·¥ç¨‹é¢†åŸŸé‡Œæœ‰ä¸¤ä¸ªå¼€å‘è§„èŒƒæˆ–è€…è¯´å¼€å‘æ¨¡å‹ç¬¦åˆè¿™äº›ç‰¹å¾ï¼šä¸€ä¸ªæ˜¯å¼€æºé¡¹ç›®æ¯”è¾ƒé€šç”¨çš„åŒæ—¶ä¹Ÿæ˜¯Githubå®˜æ–¹æ¨èçš„Pull Requestçš„æ–¹å¼ï¼Œå¦ä¸€ä¸ªæ˜¯ä»Šå¤©æˆ‘ä»¬å°†è¦é‡ç‚¹è¯´æ˜çš„Git Flowæ¨¡å‹ã€‚\nGit Flowç®€ä»‹ Git Flowæ¨¡å‹æºè‡ªVincent Driessenåœ¨2010å¹´å‘å¸ƒçš„ä¸€ç¯‡æ–‡ç« : A successful Git branching model, è¿™è¾¹æ–‡ç« å¾—åˆ°äº†å¾ˆå¤šäººçš„è®¤åŒï¼ˆæ¯”å¦‚é˜®ä¸€å³°çš„Gitåˆ†æ”¯ç®¡ç†ç­–ç•¥ï¼‰å¹¶ä¸”åœ¨å·¥ä¸šç•Œå¾—åˆ°äº†å¹¿æ³›çš„åº”ç”¨ã€‚\nä¸¤ä¸ªæ°¸ä¹…åˆ†æ”¯ Git Flow æ¨¡å‹ä¸­æœ‰ä¸¤ä¸ªæ°¸ä¹…å­˜åœ¨çš„åˆ†æ”¯ï¼šmaster å’Œ develop\nmasteråˆ†æ”¯ masteråˆ†æ”¯ä¸Šçš„ä»£ç æ°¸è¿œä»£è¡¨ç€å½“å‰ç”Ÿäº§ç¯å¢ƒçš„ä»£ç çŠ¶å†µï¼Œå¹¶ä¸”masteråˆ†æ”¯åªæ¥å—ä»£ç åˆå¹¶ï¼Œä¸æ¥å—commitæäº¤\ndevelopåˆ†æ”¯ developåˆ†æ”¯çš„ä»£ç ä»£è¡¨è¿™ä¸‹ä¸€ä¸ªè¿­ä»£å°†è¦å‘å¸ƒçš„ä»£ç æƒ…å†µï¼Œæ²¡æœ‰ç¡®å®šä¸‹æ¥å°†è¦åœ¨ä¸‹ä¸€ä¸ªè¿­ä»£å‘å¸ƒçš„ä»£ç ä¸èƒ½åˆå¹¶åœ¨è¿™ä¸ªåˆ†æ”¯ã€‚devlopåˆ†æ”¯çš„ä»£ç å’Œmasteråˆ†æ”¯åŒæ­¥æˆ–è€…é¢†å…ˆmasteråˆ†æ”¯ï¼Œç»å¯¹ä¸ä¼šå‡ºç°è½åmasteråˆ†æ”¯çš„æƒ…å†µã€‚\nè‹¥å¹²è¾…åŠ©åˆ†æ”¯ featureåˆ†æ”¯ ä¸šåŠ¡çš„éœ€æ±‚ç­‰éƒ½å¯ä»¥çœ‹ä½œæ˜¯äº§å“çš„ç‰¹æ€§ï¼Œfeatureåˆ†æ”¯å°±æ˜¯æ­£åœ¨å¼€å‘çš„å¤šä¸ªç‰¹æ€§æ„æˆçš„é›†åˆï¼Œfeatureåˆ†æ”¯å¯ä»¥åŒæ—¶æ‹¥æœ‰å¤šä¸ªï¼Œå…·å¤‡ç»Ÿä¸€çš„å‘½åè§„èŒƒï¼ˆå…·ä½“å‘½åè§„èŒƒåœ¨ä¸‹æ–‡ä¸­è¯¦è¿°ï¼‰ã€‚featureåˆ†æ”¯èµ·æºäºdevelopåˆ†æ”¯ï¼Œæœ€ç»ˆä¹Ÿå°†åˆå¹¶è‡³developåˆ†æ”¯ï¼Œä½†ä¹Ÿæœ‰ä¾‹å¤–ï¼šè¯•éªŒæ€§çš„ç‰¹æ€§å¦‚æœæœ€ç»ˆè¯æ˜æ˜¯å¤±è´¥çš„ï¼Œå°†è¢«åˆ é™¤è€Œä¸åˆå¹¶å…¥developã€‚æ¯ä¸€ä¸ªfeatureä»£è¡¨ç€ä¸€ä¸ªç‰¹æ€§ï¼Œè¿™äº›ç‰¹æ€§åªåœ¨å¼€å‘å®Œæ¯•å‡†å¤‡ä¸‹ä¸ªè¿­ä»£å‘å¸ƒæ—¶åˆå¹¶å…¥developåˆ†æ”¯ï¼Œä¸åœ¨ä¸‹ä¸€ä¸ªè¿­ä»£å‘å¸ƒçš„ç‰¹æ€§ä¸èƒ½åˆå¹¶åˆ°developåˆ†æ”¯ã€‚\nhotfixåˆ†æ”¯ çº¿ä¸Šä»£ç å‡ºç°ä¸¥é‡Bugéœ€è¦ç´§æ€¥ä¿®å¤æ—¶ä½¿ç”¨è¯¥åˆ†æ”¯ã€‚hotfixåˆ†æ”¯èµ·æºäºmasteråˆ†æ”¯ï¼ˆä¹Ÿå°±æ˜¯çº¿ä¸Šä»£ç ï¼‰ï¼Œå¼€å‘å®Œæˆååˆå¹¶è‡³masteråˆ†æ”¯åŒæ—¶åˆå¹¶åˆ°developåˆ†æ”¯ä»¥ç¡®ä¿ä¸‹ä¸€ä¸ªç‰ˆæœ¬çš„ä»£ç ä¹ŸåŒ…å«è¿™ä¸ªhotfixè¡¥ä¸ã€‚\nreleaseåˆ†æ”¯ å½“developåˆ†æ”¯ä»£ç æµ‹è¯•å®Œæ¯•ï¼Œå‡†å¤‡å‘å¸ƒæ—¶ï¼Œå°†ä»developåˆ†æ”¯å‘èµ·releaseåˆ†æ”¯ï¼Œè¿›å…¥releaseé˜¶æ®µçš„ä»£ç å°†ä¸å…è®¸æ–°ç‰¹æ€§çš„æ·»åŠ ï¼ˆä¹Ÿå°±æ˜¯ä¸å…è®¸featureåˆ†æ”¯åˆå¹¶å…¥developåˆ†æ”¯æˆ–è€…releaseåˆ†æ”¯ï¼‰ï¼Œåˆç§°ç‰¹æ€§å†»ç»“ï¼ˆfeature freezeï¼‰ã€‚releaseåˆ†æ”¯å°†è¿›è¡Œæœ€ç»ˆæœ€ä¸¥æ ¼çš„æµ‹è¯•ã€‚releaseåˆ†æ”¯æ¥å—ä¸ºäº†ä¿®å¤bugè€Œäº§ç”Ÿçš„æäº¤ã€‚releaseåˆ†æ”¯æŒç»­å˜åŠ¨ï¼Œç›´è‡³å¼€å‘å·¥ä½œéªŒæ”¶é€šè¿‡ï¼Œè¿™æ—¶releaseåˆ†æ”¯å°†ä¼šæ‰“ä¸Šç‰ˆæœ¬æ ‡ç­¾ï¼ˆtagï¼‰åˆå¹¶è‡³masteråˆ†æ”¯åŒæ—¶åˆå¹¶è‡³devlopåˆ†æ”¯ä»¥ç¡®ä¿developåˆ†æ”¯æ˜¯masteråˆ†æ”¯çš„ç›´æ¥åç»§ã€‚\nbugfixåˆ†æ”¯ bugfixåˆ†æ”¯å’Œhotfixåˆ†æ”¯ç›®çš„ç±»ä¼¼ï¼Œä½†bugç´§æ€¥ç¨‹åº¦ä¸éœ€è¦ç«‹å³ä¿®å¤ï¼Œè€Œæ˜¯ç•™åˆ°ä¸‹ä¸€ä¸ªç‰ˆæœ¬å‘å¸ƒæ—¶ä¿®æ­£ã€‚å’Œhotfixä¸åŒçš„æ˜¯bugfixèµ·æºäºdevelopåˆ†æ”¯ä¹Ÿæœ€ç»ˆåˆå¹¶äºdevelopåˆ†æ”¯ï¼Œè¿™ä¸€ç‚¹å’Œfeatureåˆ†æ”¯éå¸¸ç›¸ä¼¼ã€‚\nsupportåˆ†æ”¯ å¦‚æœé¡¹ç›®æœ‰è€ç‰ˆæœ¬çš„ä»£ç å› ä¸ºå„ç§åŸå› éœ€è¦ç»´æŠ¤æ—¶ï¼Œä¼šéœ€è¦supportåˆ†æ”¯æ¥ç®¡ç†è¿™äº›è¿‡æ—¶ä½†æ˜¯ä¾æ—§éœ€è¦ç»´æŠ¤çš„ä»£ç ã€‚\nspecialåˆ†æ”¯ å¯¹åº”äºè½¯ä»¶çš„å„ç§ç‰¹åˆ«ç‰ˆæœ¬ï¼šèŠ‚æ—¥ç‰¹åˆ«ç‰ˆï¼ˆåœ£è¯ç­‰ï¼‰ï¼Œå‘¨å¹´ç‰¹åˆ«ç‰ˆç­‰\nGit Flow AVH ä»‹ç» é™¤äº†è¿™äº›æ ‡å‡†è§„èŒƒï¼Œä½œè€…è¿˜æä¾›äº†Gitçš„æ’ä»¶å¸®åŠ©å¼€å‘è€…æ›´å¿«å’Œæ›´å¥½çš„å¤„ç†å…·ä½“çš„ç»†èŠ‚ï¼Œæˆ‘ä»¬ç°åœ¨ä»‹ç»çš„æ˜¯æ¯”è¾ƒæµè¡Œçš„Git Flow AVHç‰ˆæœ¬ã€‚\nå®‰è£… è¿™é‡Œä½¿ç”¨Linuxä¸‹å®‰è£…ä¸ºä¾‹å­ï¼Œæ›´åŠ è¯¦ç»†å’Œæ›´å¤šå¹³å°çš„å®‰è£…æŒ‡å—è¯·æŸ¥é˜…å®˜æ–¹ç»´åŸºgit-flow AVH Edition\nå®‰è£…å¼€å‘ç‰ˆæœ¬:\nwget --no-check-certificate -q https://raw.githubusercontent.com/petervanderdoes/gitflow-avh/develop/contrib/gitflow-installer.sh \u0026amp;amp;\u0026amp;amp; sudo bash gitflow-installer.sh install develop; rm gitflow-installer.sh `\u0026lt;/pre\u0026gt; å®‰è£…ç¨³å®šç‰ˆæœ¬: \u0026lt;pre\u0026gt;`wget --no-check-certificate -q https://raw.githubusercontent.com/petervanderdoes/gitflow-avh/develop/contrib/gitflow-installer.sh \u0026amp;amp;\u0026amp;amp; sudo bash gitflow-installer.sh install stable; rm gitflow-installer.sh åˆå§‹åŒ– Git flow é€šè¿‡è®©ä½ å›ç­”ä¸€äº›åˆ†æ”¯å‘½åè§„åˆ™ç­‰ä¿¡æ¯æ¥åˆå§‹åŒ–ã€‚ å¤§ä½“é—®é¢˜å¦‚ä¸‹ï¼š\né»˜è®¤çš„ç”Ÿäº§å‘å¸ƒåˆ†æ”¯ï¼ˆproduction releasesï¼‰çš„åå­—æ˜¯ä»€ä¹ˆã€é»˜è®¤æ˜¯masterã€‘ é»˜è®¤çš„developï¼ˆ\u0026ldquo;next release\u0026rdquo; developmentï¼‰åˆ†æ”¯çš„åå­—æ˜¯ä»€ä¹ˆã€é»˜è®¤æ˜¯developã€‘ é»˜è®¤çš„featureåˆ†æ”¯çš„å‰ç¼€æ˜¯ä»€ä¹ˆã€é»˜è®¤æ˜¯feature/ã€‘ é»˜è®¤çš„bugfixåˆ†æ”¯çš„å‰ç¼€æ˜¯ä»€ä¹ˆã€é»˜è®¤æ˜¯bugfix/ã€‘ é»˜è®¤çš„releaseåˆ†æ”¯çš„å‰ç¼€æ˜¯ä»€ä¹ˆã€é»˜è®¤æ˜¯release/ã€‘ é»˜è®¤çš„hotfixåˆ†æ”¯çš„å‰ç¼€æ˜¯ä»€ä¹ˆã€é»˜è®¤æ˜¯hotfix/ã€‘ é»˜è®¤æ˜¯supportåˆ†æ”¯çš„å‰ç¼€æ˜¯ä»€ä¹ˆã€é»˜è®¤æ˜¯support/ã€‘ é»˜è®¤çš„ç‰ˆæœ¬å·çš„å‰ç¼€æ˜¯ä»€ä¹ˆã€é»˜è®¤æ˜¯æ˜¯ç©ºã€‘ Git flowçš„hookså’Œfiltersçš„è·¯å¾„ [é»˜è®¤æ˜¯gité¡¹ç›®ä¸­çš„.git/hooksç›®å½•] é€šè¿‡è¿™äº›é—®é¢˜ï¼ŒGit flowè·å–äº†ç›¸å…³çš„é…ç½®è®¾å®šï¼Œåˆå§‹åŒ–å®Œæˆ\né€šç”¨æ¨¡å¼ Git flowçš„å‘½ä»¤å­˜åœ¨ä¸€ä¸ªé€šç”¨çš„æ¨¡å¼ï¼Œäº¦å³ git flow MODE ACTION NAME [BASE], ä¸‹é¢å°†ä¸€ä¸€ä»‹ç»ï¼š\nMODE MODEäº¦å³æ¨¡å¼ï¼Œè¡¨ç¤ºä½ æƒ³è¦ä½¿ç”¨çš„git flowçš„åŠŸèƒ½ï¼ŒåŠŸèƒ½è´Ÿè´£æ˜ å°„å‘½ä»¤åˆ°åˆ†æ”¯å’Œç›¸åº”çš„åŠ¨ä½œï¼Œå¸¸è§æ¨¡å¼æœ‰\nfeature bugfix hotfix release ACTION ACTIONäº¦å³åŠ¨ä½œï¼Œè¡¨ç¤ºä½ æƒ³è¦åœ¨è¿™ä¸ªæ¨¡å¼ä¸‹æ‰§è¡Œçš„åŠ¨ä½œï¼Œå¸¸è§çš„åŠ¨ä½œæ¨¡å¼æœ‰\nstart finish NAME NAMEäº¦å³åå­—ï¼Œè¡¨ç¤ºä½ è¦å®Œæˆçš„å¯¹è±¡çš„åå­—ï¼Œè¿™ä¸ªéƒ¨åˆ†å®Œå…¨ç”±ä½ è‡ªå·±å®šä¹‰ï¼Œæœ‰ä¸‹é¢å‡ ä¸ªå»ºè®®\nfeature / bugfix æ¨¡å¼ä¸‹ä½¿ç”¨è‹±æ–‡æè¿°å‘½åï¼Œå› ä¸ºè¿™ä¸ªå¯ä»¥æ–¹ä¾¿çš„äº†è§£è¿™äº›åˆ†æ”¯çš„ç”¨é€” hotfix / release æ¨¡å¼ä½¿ç”¨ç‰ˆæœ¬å·å‘½å [BASE] æŒ‰ç…§ä¼ ç»Ÿæƒ¯ä¾‹ï¼Œ[]å†…åŒ…è£¹çš„éƒ¨åˆ†æ˜¯å¯é€‰çš„ï¼Œè¿™ä¹Ÿä¸ä¾‹å¤–ï¼Œbaseä»…åœ¨startåŠ¨ä½œæ‰æœ‰ï¼ŒfinishåŠ¨ä½œå¹¶æ— æ­¤å‚æ•°ï¼Œbaseè¡¨ç¤ºçš„æ˜¯ä½ æƒ³è¦æ“ä½œçš„å¯¹è±¡ä¸æ˜¯ä»¥é»˜è®¤çš„åˆ†æ”¯ä½œä¸ºèµ·ç‚¹ï¼Œè€Œæ˜¯ä»¥baseå‚æ•°æŒ‡å®šçš„commit idä½œä¸ºèµ·ç‚¹\nä½¿ç”¨èŒƒä¾‹ å¼€å§‹æ–°çš„feature å‡è®¾ä½ æƒ³è¦å¼€å§‹ä¸€ä¸ªæ–°çš„featureï¼Œè¿™ä¸ªfeatureå¯¹åº”äº§å“éœ€æ±‚çš„â€œå¢åŠ å›å¤åŠŸèƒ½â€œï¼Œä½ å¯ä»¥ä½¿ç”¨å‘½ä»¤å¦‚ï¼šgit flow feature start add_replay_function, è¯¥å‘½ä»¤å°†ä¼šæ‰§è¡Œå¦‚ä¸‹åŠ¨ä½œï¼š\nåŸºäºdevelopåˆ†æ”¯ï¼ˆæˆ–è€…ä½ åœ¨åˆå§‹åŒ–æ—¶æŒ‡å®šçš„developå¯¹åº”çš„åˆ†æ”¯ï¼‰åˆ›å»º \u0026lsquo;feature/add_replay_function\u0026rsquo;åˆ†æ”¯ï¼ˆå¦‚æœä½ åœ¨åˆå§‹åŒ–æ—¶æ”¹å˜äº†é»˜è®¤çš„feature/çš„åˆ†æ”¯å‰ç¼€ï¼Œè¿™é‡Œä¹Ÿä¼šå‘ç”Ÿç›¸åº”çš„å˜åŠ¨ï¼‰ åˆ‡æ¢åˆ°åˆšåˆšæ–°å»ºçš„åˆ†æ”¯ åœ¨å‘½ä»¤ä¸­featureæ˜¯MODEï¼Œstartæ˜¯ACTIONï¼Œadd_replay_functionæ˜¯NAME\nå®Œæˆæ–°çš„feature å½“ä½ å®Œæˆä¸€ä¸ªfeatureçš„å¼€å‘æ—¶ï¼Œä½ å¯ä»¥ä½¿ç”¨å‘½ä»¤ï¼šgit flow feature finish add_replay_functionï¼Œè¯¥å‘½ä»¤å°†ä¼šæ‰§è¡Œå¦‚ä¸‹æ“ä½œï¼š\nå°†åˆ†æ”¯\u0026rsquo;feature/add_replay_function\u0026rsquo;ï¼ˆåå­—å¯èƒ½æœ‰æ‰€ä¸åŒï¼Œè§\u0026quot;å¼€å§‹æ–°çš„feature\u0026quot;éƒ¨åˆ†ï¼Œä¸‹åŒï¼‰åˆå¹¶åˆ°developåˆ†æ”¯ å°†æœ¬åœ°çš„\u0026rsquo;feature/add_replay_function\u0026rsquo;åˆ†æ”¯åˆ é™¤ åˆ‡æ¢åˆ°developåˆ†æ”¯ åœ¨å‘½ä»¤ä¸­featureæ˜¯MODEï¼Œfinishæ˜¯ACTIONï¼Œadd_replay_functionæ˜¯NAME\nå¼€å§‹release å½“ä¸€åˆ‡å‡†å¤‡å°±ç»ªï¼Œå‡†å¤‡å¼€å§‹å‘å¸ƒæ–°ç‰ˆ1.0çš„æ—¶å€™ï¼Œä½ å¯ä»¥ä½¿ç”¨å‘½ä»¤å¦‚ï¼šgit flow release start 1.0, è¯¥å‘½ä»¤å°†ä¼šæ‰§è¡Œå¦‚ä¸‹åŠ¨ä½œï¼š\nåŸºäº develop åˆ†æ”¯åˆ›å»º release/1.0 åˆ†æ”¯ åˆ‡æ¢è‡³ release/1.0 åˆ†æ”¯ åœ¨å‘½ä»¤ä¸­releaseæ˜¯MODEï¼Œstartæ˜¯ACTIONï¼Œ1.0æ˜¯NAMEï¼Œæ³¨æ„è¿™é‡Œçš„åå­—å®é™…æ—¶ç‰ˆæœ¬å·ï¼Œè¿™é‡Œæ¨èä½¿ç”¨ç‰ˆæœ¬å·\nå®Œæˆrelease å½“å‘å¸ƒå®Œæˆä¹‹åï¼Œä½¿ç”¨å‘½ä»¤ï¼šgit flow release finish 1.0, è¯¥å‘½ä»¤å°†ä¼šæ‰§è¡Œå¦‚ä¸‹åŠ¨ä½œï¼š\nåˆå¹¶ release/1.0 åˆ° master masteråˆ†æ”¯è¢«æ‰“ä¸Štag åˆå¹¶ release/1.0 åˆ° develop åˆ é™¤æœ¬åœ°çš„ release/1.0 åˆ†æ”¯ åˆ‡æ¢è‡³ develop åˆ†æ”¯ ä¸­é—´å¯èƒ½ä¼šè¦æ±‚ä½ å¡«å†™çš„ä¿¡æ¯ï¼š\nè¦æ±‚ä½ å¡«å†™ release/1.0 åˆå¹¶åˆ° master çš„ merge messageï¼Œæœ‰é»˜è®¤å€¼ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨é»˜è®¤å€¼ è¦æ±‚ä½ å¡«å†™ tag ä¿¡æ¯ï¼Œè¿™æ¬¡æäº¤å°†ä¼šè¢«æ‰“ä¸Štagï¼Œæ²¡æœ‰é»˜è®¤å€¼ï¼Œå»ºè®®å¡«å†™æœ¬æ¬¡å‘å¸ƒçš„å†…å®¹ï¼Œæ”¹å˜ç­‰ä¿¡æ¯ å¯èƒ½ä¼šè®©ä½ å¡«å†™ release/1.0 åˆå¹¶åˆ° develop çš„ merge messageï¼Œæœ‰é»˜è®¤å€¼ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨é»˜è®¤å€¼ é€šè¿‡ä»¥ä¸Šçš„ä¾‹å­ï¼Œä½ åº”è¯¥å·²ç»ç†è§£git flowçš„å·¥ä½œæ¨¡å¼ï¼Œå‰©ä¸‹çš„å‘½ä»¤ä½ éƒ½å¯ä»¥ä¸¾ä¸€åä¸‰ï¼Œçµæ´»åº”ç”¨ï¼Œæ›´å¤šä¿¡æ¯è¯·æŸ¥çœ‹å®˜æ–¹æ–‡æ¡£ã€‚\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/introduce-to-git-flow/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e Git Flowæ˜¯ä¸€ç§å¾—åˆ°å¹¿æ³›è®¤å¯çš„æ¨¡å‹ï¼Œé€šè¿‡ç¡®å®šåˆ†æ”¯çš„å®é™…ç”¨é€”ï¼ˆmaster/develop/featureç­‰ï¼‰ï¼Œè¾¾åˆ°å›¢é˜Ÿå…±åŒè®¤çŸ¥è®¤å¯å…¨éƒ¨å¼€å‘è¿‡ç¨‹æ•ˆæœã€‚\u003c/p\u003e","title":"Git Flowå¼€å‘æ¨¡å‹"},{"content":"TL;DR æœ¬æ–‡ä»ä»£ç çº§åˆ«è¯¦ç»†ä»‹ç»äº† Whisper çš„å®ç°å’Œä¸€äº›å…¶ä¸­ç”¨åˆ°çš„ç¼–ç¨‹æŠ€å·§\nä»€ä¹ˆæ˜¯Whisper å¾ˆå¤šäººç†Ÿæ‚‰è‘—åçš„æŒ‡æ ‡ç›‘æ§ç³»ç»Ÿï¼šGraphite\nè¿™é‡Œæœ‰ä¸€äº›æ¥è‡ªGraphiteå®˜æ–¹çš„ä»‹ç»ï¼Œç¿»è¯‘æˆä¸­æ–‡åå¤§è‡´æ˜¯ï¼š\nGraphiteæ˜¯ä¸€ä¸ªè¿è¡Œåœ¨å»‰ä»·ç¡¬ä»¶ä¸Šçš„ä¼ä¸šçº§çš„ç›‘æ§å·¥å…·\nGraphiteåšä¸¤ä»¶äº‹ï¼š\nå­˜å‚¨æ•°å€¼åŒ–çš„æ—¶é—´åºåˆ—æ•°æ® æŒ‰éœ€æ¸²æŸ“æ•°æ®å›¾å½¢ Whisperæ˜¯Graphiteæ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ã€‚è´Ÿè´£â€œå­˜å‚¨æ•°å€¼åŒ–çš„æ—¶é—´åºåˆ—æ•°æ®â€çš„ä¸¤ä¸ªéƒ¨åˆ†ï¼šä¸€ä¸ªæ˜¯è´Ÿè´£æ¥æ”¶ç½‘ç»œæ•°æ®çš„Carbonç»„ä»¶ï¼Œå¦ä¸€ä¸ªå°±æ˜¯è´Ÿè´£å­˜å‚¨åˆ°ç£ç›˜çš„Whisperç»„ä»¶ã€‚\næ­£å¼çš„è¯´ï¼ŒWhisperæ˜¯ä¸ºGraphiteé¡¹ç›®å®šåˆ¶çš„æ—¶é—´åºåˆ—æ•°æ®åº“ï¼ˆæˆ–è€…è½¯ä»¶åº“ï¼‰ï¼Œå…¶æœ¬èº«ä¹Ÿæ˜¯å¯ä»¥å•ç‹¬ä½œä¸ºæˆ–è€…é›†æˆä¸ºé€šç”¨çš„æ—¶é—´æ•°æ®åº“ã€‚\né‡è¦:\nä»¥ä¸‹ä»£ç ï¼ç»“æ„åˆ†æåŸºäºwhisper==0.9.10ï¼Œä¸åŒçš„ç‰ˆæœ¬å¯èƒ½ä¼šå­˜åœ¨å˜åŠ¨ã€‚\næ•°æ®åº“ç»“æ„æ€»æ½ ç»¼è¿° ä¸€ä¸ªWhisperæ•°æ®åº“ï¼Œç”±å•ä¸ªæ–‡ä»¶æ„æˆã€‚è¿™ä¸ªæ–‡ä»¶å¯ä»¥åˆ†æˆä¸‰ä¸ªéƒ¨åˆ†ï¼šHeaderï¼ŒArchivesï¼Œdataã€‚ æ¯ä¸ªéƒ¨åˆ†éƒ½æ˜¯Cå…¼å®¹çš„æ•°æ®ç»“æ„æ„æˆï¼Œåœ¨å®ç°ä¸Šwhisperä½¿ç”¨structåº“æ¥å®ç°packå’Œunpackã€‚ æ¯ä¸€ä¸ªarchiveéƒ½å¯¹åº”ç€ä¸€ä¸ªprecisionä¸åŒçš„å­˜å‚¨åŒºåŸŸã€‚\nHeader Headerç”±å››ä¸ªå­—æ®µæ„æˆï¼šaggregationType, maxRetention, xff, archiveCount\naggregationType æ•°æ®ç±»å‹ï¼šLong int (aka \u0026lsquo;L\u0026rsquo; in struct format), ç”¨æ¥æ§åˆ¶é«˜ç²¾åº¦å‘ä½ç²¾åº¦èšåˆæ—¶é‡‡ç”¨çš„ç­–ç•¥ï¼ˆç®—æ³•ï¼‰ å…·ä½“ç­–ç•¥å¦‚ä¸‹ï¼š\naggregationTypeToMethod = dict({ 1: \u0026#39;average\u0026#39;, 2: \u0026#39;sum\u0026#39;, 3: \u0026#39;last\u0026#39;, 4: \u0026#39;max\u0026#39;, 5: \u0026#39;min\u0026#39;, 6: \u0026#39;avg_zero\u0026#39; }) maxRetention æ•°æ®ç±»å‹ï¼šLong int, è¯¥æ•°æ®åº“èƒ½å¤Ÿå­˜å‚¨çš„æœ€å¤§æ—¶é—´é•¿åº¦ï¼ˆå•ä½ç§’ï¼‰\nxff å…¨ç§°: xFilesFactor, æ•°æ®ç±»å‹ï¼šFloat (aka \u0026lsquo;f\u0026rsquo; in struct format), å½“higher precisionå‘lower precisionèšåˆæ—¶ï¼Œå¦‚æœæœ‰æ•ˆæ•°æ®ä½äºè¿™ä¸ªthresholdï¼Œé‚£ä¹ˆèšåˆåçš„ç»“æœå°†è®¾ç½®æˆNoneã€‚\narchiveCount æ•°æ®ç±»å‹ï¼šLong int, æè¿°archiveçš„æ•°é‡\nArchives ç»¼è¿° whisperåœ¨åˆ›å»ºæ•°æ®åº“æ–‡ä»¶æ—¶ï¼Œå…³äºArchivesåšäº†å¦‚ä¸‹æ£€æŸ¥ï¼š\nè‡³å°‘æœ‰ä¸ªarchive Archivesçš„ç²¾åº¦åœ¨é¡ºåºä¸Šå¿…é¡»ä¸¥æ ¼é€’å‡ï¼Œä¸èƒ½ç²¾åº¦ç›¸åŒ Arhcivesçš„ç²¾åº¦ä¸Šå¿…é¡»æ˜¯æ•´æ•°å…³ç³»ï¼Œé«˜ç²¾åº¦å¿…é¡»æ˜¯ä½ç²¾åº¦çš„æ•´æ•°å€ Archivesçš„retentionå¿…é¡»ä¸¥æ ¼é€’å¢ï¼Œä¸èƒ½ç›¸åŒ é«˜ç²¾åº¦çš„archiveå¿…é¡»æœ‰è¶³å¤Ÿçš„ç‚¹ä¿è¯è‡³å°‘å®Œæˆä¸€æ¬¡Consolidation ä¸¾ä¾‹ï¼š\nHigher: 1s/20 Lower: 60s/1 æ»¡è¶³å‰å››ç‚¹ï¼Œä½†ä¸æ»¡è¶³æœ€åä¸€ä¸ªæ¡ä»¶\nå…·ä½“æ£€æŸ¥ä»£ç å¦‚ä¸‹ï¼š\nif not archiveList: raise InvalidConfiguration(\u0026#34;You must specify at least one archive configuration!\u0026#34;) archiveList.sort(key=lambda a: a[0]) # Sort by precision (secondsPerPoint) for i, archive in enumerate(archiveList): if i == len(archiveList) - 1: break nextArchive = archiveList[i + 1] if not archive[0] \u0026lt; nextArchive[0]: raise InvalidConfiguration(\u0026#34;A Whisper database may not be configured having \u0026#34; \u0026#34;two archives with the same precision (archive%d: %s, archive%d: %s)\u0026#34; % (i, archive, i + 1, nextArchive)) if nextArchive[0] % archive[0] != 0: raise InvalidConfiguration(\u0026#34;Higher precision archives\u0026#39; precision \u0026#34; \u0026#34;must evenly divide all lower precision archives\u0026#39; precision \u0026#34; \u0026#34;(archive%d: %s, archive%d: %s)\u0026#34; % (i, archive[0], i + 1, nextArchive[0])) retention = archive[0] * archive[1] nextRetention = nextArchive[0] * nextArchive[1] if not nextRetention \u0026gt; retention: raise InvalidConfiguration(\u0026#34;Lower precision archives must cover \u0026#34; \u0026#34;larger time intervals than higher precision archives \u0026#34; \u0026#34;(archive%d: %s seconds, archive%d: %s seconds)\u0026#34; % (i, retention, i + 1, nextRetention)) archivePoints = archive[1] pointsPerConsolidation = nextArchive[0] // archive[0] if not archivePoints \u0026gt;= pointsPerConsolidation: raise InvalidConfiguration(\u0026#34;Each archive must have at least enough points \u0026#34; \u0026#34;to consolidate to the next archive (archive%d consolidates %d of \u0026#34; \u0026#34;archive%d\u0026#39;s points but it has only %d total points)\u0026#34; % (i + 1, pointsPerConsolidation, i, archivePoints)) ç»“æ„ Archiveså¯¹åº”ç€ä¸åŒç²¾åº¦çš„å­˜å‚¨å®ç°ï¼Œå…¶æœ‰ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼šoffset, secondsPerPoint, points\noffset æ•°æ®ç±»å‹ï¼šLong intï¼ŒoffsetæŒ‡ç¤ºç›¸åº”çš„dataåŒºåŸŸåœ¨è¿™ä¸ªæ–‡ä»¶ä¸­çš„offset\nsecondsPerPoint æ•°æ®ç±»å‹ï¼šLong int, è¡¨ç¤ºæ¯ä¸ªç‚¹æ‰€ä»£è¡¨çš„é‡‡æ ·æ—¶é•¿ï¼Œe.g. archiveçš„ç²¾åº¦ï¼precisionï¼Œæ˜¾ç„¶æœ€é«˜ç²¾åº¦åªèƒ½æ˜¯1ç§’ä¸€æ¬¡\npoints æ•°æ®ç±»å‹ï¼šLong int, è¡¨ç¤ºæ•°æ®ç‚¹çš„æ•°é‡\nè¡ç”ŸæŒ‡æ ‡ è¿™äº›æŒ‡æ ‡æœ¬èº«ä¸å­˜åœ¨äºæ–‡ä»¶ä¸­ï¼Œç”±å…¶ä»–æŒ‡æ ‡è®¡ç®—å¾—åˆ°\n####### retention\n\u0026#39;retention\u0026#39;: secondsPerPoint * points è¡¨ç¤ºè¿™ä¸ªarchiveçš„ä¿å­˜æ—¶é•¿ï¼Œå•ä½ç§’\n####### size\n\u0026#39;size\u0026#39;: points * pointSize è¡¨ç¤ºdataéƒ¨åˆ†æ‰€å æ®çš„å­—èŠ‚é•¿åº¦\nData è¿™ä¸ªéƒ¨åˆ†è¡¨ç¤ºå…·ä½“çš„æ•°æ®ç‚¹ï¼Œæ•°æ®ç‚¹çº¿æ€§æ’åˆ—åœ¨æ–‡ä»¶ä¸­ï¼Œæ¯ä¸ªæ•°æ®ç‚¹æœ‰ä¸¤ä¸ªéƒ¨åˆ†æ„æˆï¼šInterval, data\nInterval æ•°æ®ç±»å‹ï¼šLong intï¼Œè¡¨ç¤ºæ—¶é—´æˆ³ï¼ˆä»UNIXçºªå…ƒ (aka 1970-01-01 00:00 UTC) å¼€å§‹çš„ç§’æ•°ï¼‰\ndata æ•°æ®ç±»å‹ï¼šdouble (aka \u0026rsquo;d\u0026rsquo; in struct format)ï¼Œè¡¨ç¤ºå…·ä½“çš„metricæ•°å€¼\næ€»ç»“ ASCII art å›¾è¡¨ +-------------------------------------------------------------------------+ |AT|MR|xff|AC|offset|SPP|points| ... |Interval|data| ... | +-------------------------------------------------------------------------+ | | Archive One | ... | Point One | ... | +-------------------------------------------------------------------------+ | Header | Archives | Data | +-------------------------------------------------------------------------+ | Whisper file | +-------------------------------------------------------------------------+ AT: aggregationType MR: maxRetention AC: archiveCount SPP: secondsPerPoint åˆ›å»ºæ•°æ®åº“ å‚æ•° å…³é”®å‚æ•°ï¼š\npath æ•°æ®åº“æ–‡ä»¶çš„è·¯å¾„ archiveList xFilesFactor=None aggregationMethod=None archiveList # Validate archive configurations... validateArchiveList(archiveList) æ£€æŸ¥æ¡ä»¶å‚è§ inline page\nå†™å…¥Header aggregationType = struct.pack(longFormat, aggregationMethodToType.get(aggregationMethod, 1)) oldest = max([secondsPerPoint * points for secondsPerPoint, points in archiveList]) maxRetention = struct.pack(longFormat, oldest) xFilesFactor = struct.pack(floatFormat, float(xFilesFactor)) archiveCount = struct.pack(longFormat, len(archiveList)) packedMetadata = aggregationType + maxRetention + xFilesFactor + archiveCount fh.write(packedMetadata) å†™å…¥ArchiveList å…¶ä¸­æ¯”è¾ƒé‡è¦çš„æ˜¯offsetçš„è®¡ç®—\nheaderSize = metadataSize + (archiveInfoSize * len(archiveList)) archiveOffsetPointer = headerSize for secondsPerPoint, points in archiveList: archiveInfo = struct.pack(archiveInfoFormat, archiveOffsetPointer, secondsPerPoint, points) fh.write(archiveInfo) archiveOffsetPointer += (points * pointSize) DataåŒºåŸŸå¡«å…… \\x00 if CAN_FALLOCATE and useFallocate: remaining = archiveOffsetPointer - headerSize fallocate(fh, headerSize, remaining) elif sparse: fh.seek(archiveOffsetPointer - 1) fh.write(b\u0026#39;\\x00\u0026#39;) else: remaining = archiveOffsetPointer - headerSize chunksize = 16384 zeroes = b\u0026#39;\\x00\u0026#39; * chunksize while remaining \u0026gt; chunksize: fh.write(zeroes) remaining -= chunksize fh.write(zeroes[:remaining]) è¿™é‡Œçš„å­˜åœ¨å‡ ç§ä¼˜åŒ–çš„ IOæ–¹æ³• fallocate è¿™ä¸ªä¸€ä¸ªLinuxç‹¬æœ‰çš„ç³»ç»Ÿè°ƒç”¨ï¼Œå‡½æ•°åŸå‹æ˜¯int fallocate(int fd, int mode, off_t offset, off_t len);ã€‚è¯¥å‡½æ•°å…è®¸è°ƒç”¨è€…ç›´æ¥åˆ†é…æ–‡ä»¶ä¸­èŒƒå›´åœ¨offsetåˆ°lençš„åŒºæ®µçš„ç£ç›˜ç©ºé—´ï¼Œé€Ÿåº¦æ¯”å†™å…¥æ–‡ä»¶åˆ†é…çš„æ›´å¿«ã€‚\næ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ fallocateæ‰‹å†Œ\nsparse file æ–‡ä»¶å¹¶æ²¡æœ‰çœŸæ­£åˆ†é…åœ¨ç£ç›˜ä¸Šï¼Œè€Œæ˜¯è®°å½•è¯¥æ–‡ä»¶æœ‰è¿™ä¸ªå°ºå¯¸ï¼Œç­‰åˆ°çœŸæ­£å†™å…¥æ—¶ï¼Œæ‰ä¼šåˆ†é…ç£ç›˜ç©ºé—´ï¼Œå› æ­¤è¿™ä¸ªæ–‡ä»¶æ—¶ç¨€ç–çš„ã€‚ä¼˜ç‚¹æ˜¯åˆ›å»ºæ—¶éå¸¸å¿«ï¼Œä½†çœŸæ­£å†™å…¥æ—¶å­˜åœ¨ç£ç›˜ç¢ç‰‡çš„å¯èƒ½ï¼Œå¯¼è‡´å†™å…¥å’Œè¯»å–æ¯”æ™®é€šæ–¹å¼æ›´æ…¢ã€‚\næ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ ç¨€ç–æ–‡ä»¶çš„ç»´åŸºç™¾ç§‘\nwrite by chunk ç³»ç»Ÿåº•å±‚çš„ç£ç›˜æ—¶æŒ‰ç…§æ‰‡åŒºå·¥ä½œçš„ï¼Œå¦‚æœå†™å…¥æ•°æ®å’Œæ‰‡åŒºå¤§å°ä¸€è‡´ï¼Œé‚£ä¹ˆå°±ä¼šå‡å°‘ä¸å¿…è¦çš„è°ƒæ•´æ—¶é—´ã€‚ç°ä»£ç£ç›˜çš„æ‰‡åŒºå¤§å°é€šå¸¸ä¸º4Kï¼Œå› æ­¤æŒ‰ç…§4Kæˆ–è€…4Kçš„æ•´æ•°å€å†™å…¥éƒ½å¯ä»¥è·å¾—æ€§èƒ½æå‡ã€‚\næ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ ç£ç›˜æ‰‡åŒºçš„ç»´åŸºç™¾ç§‘\nå®ç°æ–¹é¢çš„é™·é˜± ä»£ç çš„å®ç°éƒ¨åˆ†æœ‰ä¸€ä¸ªé™·é˜±ï¼š\nvalidateArchiveList(archiveList)\nåœ¨å‡½æ•°å†…å¯¹ archiveList åšäº†æ’åº archiveList.sort(key=lambda a: a[0]) , å¦‚æœä¸é˜…è¯»å†…éƒ¨ä»£ç ï¼Œå®¹æ˜“è®©äººä¸¢å¤±é‡è¦çš„ç»†èŠ‚\næŸ¥è¯¢æ•°æ®åº“ æ ¹æ®æœ€å¤§Retention,ä¿®æ­£æŸ¥è¯¢æ—¶é—´èŒƒå›´ if now is None: now = int(time.time()) if untilTime is None: untilTime = now fromTime = int(fromTime) untilTime = int(untilTime) # Here we try and be flexible and return as much data as we can. # If the range of data is from too far in the past or fully in the future, we # return nothing if fromTime \u0026gt; untilTime: raise InvalidTimeInterval(\u0026#34;Invalid time interval: from time \u0026#39;%s\u0026#39; is after until time \u0026#39;%s\u0026#39;\u0026#34; % (fromTime, untilTime)) oldestTime = now - header[\u0026#39;maxRetention\u0026#39;] # Range is in the future if fromTime \u0026gt; now: return None # Range is beyond retention if untilTime \u0026lt; oldestTime: return None # Range requested is partially beyond retention, adjust if fromTime \u0026lt; oldestTime: fromTime = oldestTime # Range is partially in the future, adjust if untilTime \u0026gt; now: untilTime = now æŸ¥æ‰¾èƒ½å¤Ÿè¦†ç›–æŸ¥è¯¢èŒƒå›´çš„æœ€é«˜ç²¾åº¦çš„archive diff = now - fromTime for archive in header[\u0026#39;archives\u0026#39;]: if archive[\u0026#39;retention\u0026#39;] \u0026gt;= diff: break æ—¶é—´èŒƒå›´å¯¹é½åˆ°Interval fromInterval = int(fromTime - (fromTime % archive[\u0026#39;secondsPerPoint\u0026#39;])) + archive[\u0026#39;secondsPerPoint\u0026#39;] untilInterval = int(untilTime - (untilTime % archive[\u0026#39;secondsPerPoint\u0026#39;])) + archive[\u0026#39;secondsPerPoint\u0026#39;] æ¦‚æ‹¬è¯´æ¥ï¼Œæ€»æ˜¯å¯»æ‰¾å’Œæ—¶é—´ç‚¹æœ€æ¥è¿‘çš„ä¸‹ä¸€ä¸ªInterval\nç‰¹åˆ«çš„ï¼Œç›¸åŒæ—¶é—´çš„å¼€å§‹å’Œç»“æŸçš„æŸ¥è¯¢èŒƒå›´è¢«è°ƒæ•´æˆä¸ºæ€»æ˜¯åŒ…å«ä¸‹ä¸€ä¸ªstepï¼š\nif fromInterval == untilInterval: # Zero-length time range: always include the next point untilInterval += archive[\u0026#39;secondsPerPoint\u0026#39;] è®¡ç®—offset # Determine fromOffset timeDistance = fromInterval - baseInterval pointDistance = timeDistance // archive[\u0026#39;secondsPerPoint\u0026#39;] byteDistance = pointDistance * pointSize fromOffset = archive[\u0026#39;offset\u0026#39;] + (byteDistance % archive[\u0026#39;size\u0026#39;]) # Determine untilOffset timeDistance = untilInterval - baseInterval pointDistance = timeDistance // archive[\u0026#39;secondsPerPoint\u0026#39;] byteDistance = pointDistance * pointSize untilOffset = archive[\u0026#39;offset\u0026#39;] + (byteDistance % archive[\u0026#39;size\u0026#39;]) python % è¿ç®— çš„ä¸€ä¸ªtrick byteDistance % archive[\u0026#39;size\u0026#39;] èƒ½å¤Ÿè¾¾åˆ°wrapçš„æ•ˆæœï¼Œç­‰ä»·äº\nif byteDistance \u0026gt;= 0: return byteDistance else: return archive[\u0026#39;size\u0026#39;] + byteDistance åŸå› æ˜¯pythonçš„æ±‚ä½™è¿ç®— % çš„ç‰¹æ€§\nprint(-3 % 5) # è¾“å‡º 2 print(3 % 5) # è¾“å‡º 3 è¯»å–æ•°æ® # Now we unpack the series data we just read (anything faster than unpack?) byteOrder, pointTypes = pointFormat[0], pointFormat[1:] points = len(seriesString) // pointSize seriesFormat = byteOrder + (pointTypes * points) unpackedSeries = struct.unpack(seriesFormat, seriesString) # And finally we construct a list of values (optimize this!) valueList = [None] * points # Pre-allocate entire list for speed currentInterval = fromInterval step = archive[\u0026#39;secondsPerPoint\u0026#39;] for i in xrange(0, len(unpackedSeries), 2): pointTime = unpackedSeries[i] if pointTime == currentInterval: pointValue = unpackedSeries[i + 1] valueList[i // 2] = pointValue # In-place reassignment is faster than append() currentInterval += step timeInfo = (fromInterval, untilInterval, step) return (timeInfo, valueList) å…¶ä¸­æ¯”è¾ƒé‡è¦çš„ä¿¡æ¯æ˜¯ï¼Œè¯»å–æ•°æ®æ—¶ä¼šåˆ¤æ–­æ—¶é—´æˆ³ï¼ˆIntervalï¼‰æ˜¯å¦ç­‰äºæœŸæœ›çš„æ—¶é—´æˆ³ï¼Œå¦‚æœä¸ç›¸åŒå°±è®¤ä¸ºæ²¡æœ‰å€¼ï¼Œè®¾ä¸ºNone, è¿™æ˜¯ä¸€ç§é‡è¦çš„è¡Œä¸ºï¼Œè¿™æ ·å†™çš„æ—¶å€™å°±å¯ä»¥ç¦»æ•£å†™ï¼Œä¸ç”¨è¿ç»­å†™æ•°æ®ï¼Œç»“æœçš„æ­£ç¡®æ€§å¾—åˆ°ä¿éšœã€‚\næ•°æ®åº“æ›´æ–° Whisperæ•°æ®åº“æœ¬èº«è™½ç„¶æ”¯æŒå•ä¸ªæ•°æ®ç‚¹æ›´æ–°API update()ä¹Ÿæ”¯æŒå¤šä¸ªæ•°æ®ç‚¹æ›´æ–°API update_many()ï¼Œä½†æ˜¯åœ¨carbonçš„ä½¿ç”¨ä¸­ï¼Œæ˜¯ä½¿ç”¨å¤šæ•°æ®ç‚¹æ›´æ–°çš„API,ä¸¤è€…å®ç°ä¸Šç±»ä¼¼ï¼Œåªæ˜¯åè€…æ‰¹é‡æ›´æ–°ï¼ŒIOæ•ˆç‡æ›´é«˜ï¼Œæœ¬æ–‡å°†è®¨è®º update_many()\nå‚æ•° path ä»£è¡¨æ–‡ä»¶è·¯å¾„ points is a list of (timestamp,value) points æ’åº å°†åˆ—è¡¨ä¸­çš„ç‚¹æŒ‰ç…§æ—¶é—´æˆ³ä»å¤§åˆ°å°é™åºæ’åˆ—ï¼Œå®Œæˆåè¾ƒæ–°çš„æ•°æ®ç‚¹åœ¨å‰é¢\npoints = [(int(t), float(v)) for (t, v) in points] points.sort(key=lambda p: p[0], reverse=True) # Order points by timestamp, newest first è¯»å–æ–‡ä»¶å¤´ è¯»å–æ–‡ä»¶å¤´è¿”å›æ•°æ®ç»“æ„\ninfo = { \u0026#39;aggregationMethod\u0026#39;: aggregationTypeToMethod.get(aggregationType, \u0026#39;average\u0026#39;), \u0026#39;maxRetention\u0026#39;: maxRetention, \u0026#39;xFilesFactor\u0026#39;: xff, \u0026#39;archives\u0026#39;: archives, } å°†æ•°æ®ç‚¹æŒ‰ç…§Archive\u0026rsquo;s Retentionåˆ†ç»„è¿›è¡Œå†™å…¥ for point in points: age = now - point[0] while currentArchive[\u0026#39;retention\u0026#39;] \u0026lt; age: # We can\u0026#39;t fit any more points in this archive if currentPoints: # Commit all the points we\u0026#39;ve found that it can fit currentPoints.reverse() # Put points in chronological order __archive_update_many(fh, header, currentArchive, currentPoints) currentPoints = [] try: currentArchive = next(archives) except StopIteration: currentArchive = None break if not currentArchive: break # Drop remaining points that don\u0026#39;t fit in the database currentPoints.append(point) if currentArchive and currentPoints: # Don\u0026#39;t forget to commit after we\u0026#39;ve checked all the archives currentPoints.reverse() __archive_update_many(fh, header, currentArchive, currentPoints) å€¼å¾—æ³¨æ„çš„æ˜¯æ•°æ®åœ¨ä¼ å…¥å…·ä½“å‡½æ•°å†™å…¥æ—¶ï¼ŒPointséƒ½åšäº†order reverseï¼Œå˜æˆäº†oldestæ•°æ®åœ¨æœ€å‰é¢\nPSï¼šè¿™å—ä»£ç ä¸å®¹æ˜“ç†è§£\nåˆ†ç»„å†™å…¥æ“ä½œ å…·ä½“å®ç°å‡½æ•° __archive_update_many(fh, header, archive, points)\næ•°æ®ç‚¹å¯¹é½ step = archive[\u0026#39;secondsPerPoint\u0026#39;] alignedPoints = [(timestamp - (timestamp % step), value) for (timestamp, value) in points] æ•°æ®ç‚¹æŒ‰ç…§è¿ç»­æ€§åˆ†ç»„ # Create a packed string for each contiguous sequence of points packedStrings = [] previousInterval = None currentString = b\u0026#34;\u0026#34; lenAlignedPoints = len(alignedPoints) for i in xrange(0, lenAlignedPoints): # Take last point in run of points with duplicate intervals if i + 1 \u0026lt; lenAlignedPoints and alignedPoints[i][0] == alignedPoints[i + 1][0]: continue (interval, value) = alignedPoints[i] # å¦‚æœæ˜¯å¼€å¤´æˆ–è€…æ—¶é—´ç‚¹æ˜¯è¿ç»­çš„ if (not previousInterval) or (interval == previousInterval + step): currentString += struct.pack(pointFormat, interval, value) previousInterval = interval else: # å¦‚æœæ—¶é—´ç‚¹æ–­å¼€äº† numberOfPoints = len(currentString) // pointSize startInterval = previousInterval - (step * (numberOfPoints - 1)) packedStrings.append((startInterval, currentString)) currentString = struct.pack(pointFormat, interval, value) previousInterval = interval if currentString: numberOfPoints = len(currentString) // pointSize startInterval = previousInterval - (step * (numberOfPoints - 1)) packedStrings.append((startInterval, currentString)) å…¶ä¸­éœ€è¦æ³¨æ„çš„ç‚¹ï¼š\nå¯¹é½åçš„æ—¶é—´ç‚¹åšäº†å»é‡å¤æ“ä½œï¼Œåªä¿ç•™æ—¶é—´ä¸Šæœ€åä¸€ä¸ªç‚¹ï¼Œè¿™æ˜¯å¾ˆé‡è¦çš„ç‰¹æ€§\næ•°æ®å†™å…¥ # Read base point and determine where our writes will start fh.seek(archive[\u0026#39;offset\u0026#39;]) packedBasePoint = fh.read(pointSize) (baseInterval, baseValue) = struct.unpack(pointFormat, packedBasePoint) if baseInterval == 0: # This file\u0026#39;s first update baseInterval = packedStrings[0][0] # Use our first string as the base, so we start at the start # Write all of our packed strings in locations determined by the baseInterval for (interval, packedString) in packedStrings: timeDistance = interval - baseInterval pointDistance = timeDistance // step byteDistance = pointDistance * pointSize myOffset = archive[\u0026#39;offset\u0026#39;] + (byteDistance % archive[\u0026#39;size\u0026#39;]) fh.seek(myOffset) archiveEnd = archive[\u0026#39;offset\u0026#39;] + archive[\u0026#39;size\u0026#39;] bytesBeyond = (myOffset + len(packedString)) - archiveEnd if bytesBeyond \u0026gt; 0: fh.write(packedString[:-bytesBeyond]) assert fh.tell() == archiveEnd, \u0026#34;archiveEnd=%d fh.tell=%d bytesBeyond=%d len(packedString)=%d\u0026#34; % ( archiveEnd, fh.tell(), bytesBeyond, len(packedString)) fh.seek(archive[\u0026#39;offset\u0026#39;]) fh.write( packedString[-bytesBeyond:]) # Safe because it can\u0026#39;t exceed the archive (retention checking logic above) else: fh.write(packedString) æ³¨æ„ï¼šè¿™é‡Œçš„æ–‡ä»¶å†™å…¥æœ‰warpçš„ç°è±¡\nèšåˆåˆ°ä¸‹ä¸€çº§Archive # Now we propagate the updates to lower-precision archives higher = archive lowerArchives = [arc for arc in header[\u0026#39;archives\u0026#39;] if arc[\u0026#39;secondsPerPoint\u0026#39;] \u0026gt; archive[\u0026#39;secondsPerPoint\u0026#39;]] for lower in lowerArchives: fit = lambda i: i - (i % lower[\u0026#39;secondsPerPoint\u0026#39;]) lowerIntervals = [fit(p[0]) for p in alignedPoints] uniqueLowerIntervals = set(lowerIntervals) propagateFurther = False for interval in uniqueLowerIntervals: if __propagate(fh, header, interval, higher, lower): propagateFurther = True if not propagateFurther: break higher = lower å•ç‚¹èšåˆ def __propagate(fh, header, timestamp, higher, lower): aggregationMethod = header[\u0026#39;aggregationMethod\u0026#39;] xff = header[\u0026#39;xFilesFactor\u0026#39;] lowerIntervalStart = timestamp - (timestamp % lower[\u0026#39;secondsPerPoint\u0026#39;]) lowerIntervalEnd = lowerIntervalStart + lower[\u0026#39;secondsPerPoint\u0026#39;] fh.seek(higher[\u0026#39;offset\u0026#39;]) packedPoint = fh.read(pointSize) (higherBaseInterval, higherBaseValue) = struct.unpack(pointFormat, packedPoint) if higherBaseInterval == 0: higherFirstOffset = higher[\u0026#39;offset\u0026#39;] else: timeDistance = lowerIntervalStart - higherBaseInterval pointDistance = timeDistance // higher[\u0026#39;secondsPerPoint\u0026#39;] byteDistance = pointDistance * pointSize higherFirstOffset = higher[\u0026#39;offset\u0026#39;] + (byteDistance % higher[\u0026#39;size\u0026#39;]) higherPoints = lower[\u0026#39;secondsPerPoint\u0026#39;] // higher[\u0026#39;secondsPerPoint\u0026#39;] higherSize = higherPoints * pointSize relativeFirstOffset = higherFirstOffset - higher[\u0026#39;offset\u0026#39;] relativeLastOffset = (relativeFirstOffset + higherSize) % higher[\u0026#39;size\u0026#39;] higherLastOffset = relativeLastOffset + higher[\u0026#39;offset\u0026#39;] fh.seek(higherFirstOffset) if higherFirstOffset \u0026lt; higherLastOffset: # We don\u0026#39;t wrap the archive seriesString = fh.read(higherLastOffset - higherFirstOffset) else: # We do wrap the archive higherEnd = higher[\u0026#39;offset\u0026#39;] + higher[\u0026#39;size\u0026#39;] seriesString = fh.read(higherEnd - higherFirstOffset) fh.seek(higher[\u0026#39;offset\u0026#39;]) seriesString += fh.read(higherLastOffset - higher[\u0026#39;offset\u0026#39;]) # Now we unpack the series data we just read byteOrder, pointTypes = pointFormat[0], pointFormat[1:] points = len(seriesString) // pointSize seriesFormat = byteOrder + (pointTypes * points) unpackedSeries = struct.unpack(seriesFormat, seriesString) # And finally we construct a list of values neighborValues = [None] * points currentInterval = lowerIntervalStart step = higher[\u0026#39;secondsPerPoint\u0026#39;] for i in xrange(0, len(unpackedSeries), 2): pointTime = unpackedSeries[i] if pointTime == currentInterval: neighborValues[i // 2] = unpackedSeries[i + 1] currentInterval += step # Propagate aggregateValue to propagate from neighborValues if we have enough known points knownValues = [v for v in neighborValues if v is not None] if not knownValues: return False knownPercent = float(len(knownValues)) / float(len(neighborValues)) if knownPercent \u0026gt;= xff: # We have enough data to propagate a value! aggregateValue = aggregate(aggregationMethod, knownValues, neighborValues) myPackedPoint = struct.pack(pointFormat, lowerIntervalStart, aggregateValue) fh.seek(lower[\u0026#39;offset\u0026#39;]) packedPoint = fh.read(pointSize) (lowerBaseInterval, lowerBaseValue) = struct.unpack(pointFormat, packedPoint) if lowerBaseInterval == 0: # First propagated update to this lower archive fh.seek(lower[\u0026#39;offset\u0026#39;]) fh.write(myPackedPoint) else: # Not our first propagated update to this lower archive timeDistance = lowerIntervalStart - lowerBaseInterval pointDistance = timeDistance // lower[\u0026#39;secondsPerPoint\u0026#39;] byteDistance = pointDistance * pointSize lowerOffset = lower[\u0026#39;offset\u0026#39;] + (byteDistance % lower[\u0026#39;size\u0026#39;]) fh.seek(lowerOffset) fh.write(myPackedPoint) return True else: return False å¦‚æœä¸Šä¸€ä¸ªç²¾åº¦çš„aggrigationçš„xffè¿‡ä½å¯¼è‡´èšåˆå¤±è´¥ï¼Œé‚£ä¹ˆåç»­çº§åˆ«çš„aggrigationå°±ä¼šå–æ¶ˆ\nTrick åœ¨æ‰“å¼€æ–‡ä»¶æ—¶ï¼ŒWhisper ä½¿ç”¨äº† Linux ä¸Šçš„ fadvise æ¥å»ºè®®æ“ä½œç³»ç»Ÿå¯¹æ–‡ä»¶è®¿é—®è¿›è¡ŒæŸä¸ªç­–ç•¥çš„ä¼˜åŒ–ã€‚\nif CAN_FADVISE and FADVISE_RANDOM: posix_fadvise(fh.fileno(), 0, 0, POSIX_FADV_RANDOM) fadvise åœ¨å…¶æ‰‹å†Œä¸­çš„ä»‹ç»ç¿»è¯‘æˆä¸­æ–‡å¤§æ„æ˜¯ï¼š\nå…è®¸åº”ç”¨ç¨‹åºå‘ŠçŸ¥æ“ä½œç³»ç»Ÿå®ƒä¼šå¦‚ä½•ä½¿ç”¨æ–‡ä»¶æè¿°ç¬¦ï¼Œè¿™æ ·æ“ä½œç³»ç»Ÿå°±èƒ½é€‰ç”¨æœ€åˆé€‚çš„è¯»å–å’Œç¼“å­˜ç­–ç•¥æ¥è®¿é—®ç›¸åº”çš„æ–‡ä»¶\nfadvise æœ‰å¤šä¸ªé€‰é¡¹ï¼š\nFADV_NORMAL ï¼šä¸éœ€è¦ç‰¹æ®Šå¯¹å¾… FADV_RANDOM : æœŸæœ›é¡µé¢ä»¥éšæœºè®¿é—®è¿›è¡Œ FADV_SEQUENTIAL : æœŸæœ›é¡µé¢è®¿é—®ä»¥é¡ºåºè®¿é—®è¿›è¡Œ FADV_WILLNEED : æœŸæœ›åœ¨è¿‘æœŸå†æ¬¡è®¿é—® FADV_DONTNEED : ä¸æœŸæœ›åœ¨è¿‘æœŸå†æ¬¡è®¿é—® FADV_NOREUSE : åªä¼šè®¿é—®æ•°æ®ä¸€æ¬¡ å…³äºfadviseçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ man fadvise\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/introduce-to-the-implement-of-whisper/","summary":"\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e æœ¬æ–‡ä»ä»£ç çº§åˆ«è¯¦ç»†ä»‹ç»äº† Whisper çš„å®ç°å’Œä¸€äº›å…¶ä¸­ç”¨åˆ°çš„ç¼–ç¨‹æŠ€å·§\u003c/p\u003e","title":"æ—¶é—´æ•°æ®åº“Whisperçš„å®ç°ç®€ä»‹"},{"content":"åœ¨ä½¿ç”¨ Python çš„ iterator æ—¶ï¼Œé‡åˆ°ä¸€ä¸ªå¾ˆæ„šè ¢çš„é”™è¯¯ï¼Œæµªè´¹çš„å¾ˆå¤šæ—¶é—´æ‰æ‰¾åˆ°åŸå› ã€‚ç‰¹æ­¤è®°å½•ä¸€ä¸‹ï¼Œæé†’è‡ªå·±ï¼Œæç¤ºä»–äººã€‚ Bug å¤ç° åŸæ¥çš„é—®é¢˜æ¯”è¾ƒå¤æ‚ï¼Œå¯¼è‡´å‡ºé”™éš¾ä»¥è°ƒè¯•ï¼Œç»è¿‡å°†é—®é¢˜ä¸æ–­ç®€åŒ–ï¼Œæœ€åç®€åŒ–åçš„ä»£ç å¦‚ä¸‹ï¼š\næ‰“å° iterator çš„å‡½æ•° æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç”¨äºæ‰“å° iterator çš„å‡½æ•°\ndef print_iterator(iterator): while True: try: element = next(iterator) except StopIteration: break else: print(element) æµ‹è¯•ä¸€ä¸‹\nprint_iterator(iter([1, 2, 3])) è¾“å‡ºï¼š\n1 2 3 ä»£ç å·¥ä½œæ­£å¸¸\nå®šä¹‰ä¸€ä¸ªè®¡ç®— iterable é•¿åº¦çš„å‡½æ•° def counter_iterable(iterable): iterator = iter(iterable) iterator_length = sum(1 for _ in iterator) print(iterator_length) æµ‹è¯•ä¸€ä¸‹\ncounter_iterable([1, 2, 3]) è¾“å‡ºï¼š\n3 ä»£ç å·¥ä½œæ­£å¸¸\næ•´åˆåœ¨ä¸€èµ· å°† æ”¾åœ¨ ä¸­è°ƒç”¨ï¼š\ndef counter_iterable_and_print(iterable): iterator = iter(iterable) iterator_length = sum(1 for _ in iterator) print(iterator_length) print_iterator(iterator) æµ‹è¯•ä¸€ä¸‹\ncounter_iterable_and_print([1, 2, 3]) æœŸæœ›çš„è¾“å‡ºåº”è¯¥æœ‰é•¿åº¦å’Œæ‰“å°å†…å®¹ä¸¤ä¸ªéƒ¨åˆ†æ„æˆï¼š\n3 1 2 3 ä½†å®é™…ä¸Šè¾“å‡ºæ˜¯ï¼š\n3 ä»£ç å·¥ä½œä¸æ­£å¸¸\nbug åŸå›  è¿™ä¸ª bug çš„\u0008äº§ç”Ÿå’Œæˆ‘å¯¹ä¸¤ä¸ªæ¦‚å¿µçš„ç†è§£å’Œè®°å¿†é”™è¯¯æœ‰å…³ï¼š ç¬¬ä¸€ä¸ªæ˜¯æ²¡æœ‰å……åˆ†ç†è§£å’Œè®°å¿† iterator çš„å·¥ä½œæœºåˆ¶ã€‚\niterator æ˜¯ä»€ä¹ˆ æ ¹æ® Iterator on Python wiki :\nAn iterator is an object that implements next (in python3, it is __next__) method, which is expected to return the next element of the iterable object that returned it, and raise a StopIteration exception when no more elements are available.\nIterator will typically need to maintain some kind of position state information (like the index of the last element returned or the like). If the iterable maintained that state itself, it would become inherently non-reentrant (meaning you could use it only one loop at a time).\nä¸Šè¿° bug äº§ç”Ÿçš„åŸå› ï¼šä¸Šé¢çš„ä»£ç ä¸­å…±äº«äº†ä¸€ä¸ª iterator å¯¹è±¡ï¼Œç”±äº iterator å…·æœ‰è®°å¿†å†…éƒ¨çŠ¶æ€çš„èƒ½åŠ›ï¼Œæ‰€ä»¥å½“\niterator_length = sum(1 for _ in iterator) æ‰§è¡Œå®Œæ¯•åï¼Œå®é™…è¿™ä¸ª iterator å¯¹è±¡å·²ç»å®Œæˆäº†å…¨éƒ¨å…ƒç´ çš„è¿­ä»£ã€‚åç»­å†æ¬¡è°ƒç”¨è¿™ä¸ªå¯¹è±¡çš„ __next__() æ–¹æ³•æ—¶ï¼Œç›´æ¥æŠ›å‡º StopIteration \u0008å¼‚å¸¸ã€‚å› æ­¤è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåç»­çš„\nprint_iterator(iterator) å¹¶æ²¡æœ‰ä»»ä½•è¾“å‡ºçš„åŸå› ï¼Œå› ä¸ºå‡½æ•°æ”¶åˆ°çš„å‚æ•°å·²ç»æ˜¯ä¸€ä¸ªèµ°åˆ°æœ€åçš„\u0008 iterator å¯¹è±¡äº†ã€‚\niterator å†…æœ‰æœ‰çŠ¶æ€ä¿¡æ¯ï¼Œå…·æœ‰ä¸å¯é‡å…¥ï¼ˆnon-reentrantï¼‰çš„ç‰¹æ€§ï¼Œè¿™ä¸ªå’Œ list, tuple, dict ç­‰å®¹å™¨ä¸ä¸€æ ·ï¼Œå®¹å™¨é€šè¿‡ __getitem__ æ¥è¿­ä»£ã€‚\nå¦å¤–ä¸€ä¸ªæ˜¯æ²¡æœ‰ææ¸…æ¥š iterable å’Œ iterator çš„åŒºåˆ«ã€‚æ­£ç¡®çš„ç†è§£æ˜¯ï¼šiterable æ˜¯ä¸€ä¸ªå·¥å‚å‡½æ•°ï¼Œé€šè¿‡æ˜¾å¼çš„è°ƒç”¨ iter å‡½æ•°æˆ–è€…è°ƒç”¨å…¶ __iter__() æ–¹æ³•æˆ–è€…ä½¿ç”¨\u0008 for å¾ªç¯æ¥è·å¾—è¿™ä¸ªå·¥å‚çš„äº§å“ï¼šä¸€ä¸ª iterator å¯¹è±¡ã€‚\nè¿™é‡Œéœ€è¦ç®€å•è¯´æ˜çš„æ˜¯ï¼šæ— è®ºæ˜¯ä½¿ç”¨ iter å‡½æ•°è¿˜æ˜¯åœ¨ for å¾ªç¯ä¸­ä½¿ç”¨ï¼Œéƒ½æ˜¯é—´æ¥çš„è°ƒç”¨ iterable å¯¹è±¡çš„ __iter__ æ–¹æ³•ã€‚\n\u0008iterator è¢«è¦æ±‚éœ€è¦æ”¯æŒ iterable åè®®çš„ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œå¯¹ iterator è°ƒç”¨ __iter__ æ–¹æ³•ï¼Œè¿”å›çš„ iterator å°±æ˜¯å®ƒè‡ªå·±ã€‚ è¿™æ · iterator å¯¹è±¡å°±èƒ½å¤Ÿåœ¨ for-loop ä¸­ä½¿ç”¨äº†ã€‚\nå…³äº iterator çš„ PEP åœ¨ PEP 234 \u0026ndash; Iterators\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/a-pitfall-of-python-iterator/","summary":"\u003cp\u003eåœ¨ä½¿ç”¨ Python çš„ iterator æ—¶ï¼Œé‡åˆ°ä¸€ä¸ªå¾ˆæ„šè ¢çš„é”™è¯¯ï¼Œæµªè´¹çš„å¾ˆå¤šæ—¶é—´æ‰æ‰¾åˆ°åŸå› ã€‚ç‰¹æ­¤è®°å½•ä¸€ä¸‹ï¼Œæé†’è‡ªå·±ï¼Œæç¤ºä»–äººã€‚\n\u003ca href=\"https://mybinder.org/v2/gh/howl-anderson/howl-anderson.github.io/master?filepath=python-iterator-%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91%2Fproof-of-concept.ipynb\"\u003e\u003cimg loading=\"lazy\" src=\"https://mybinder.org/badge.svg\" alt=\"Binder\"  /\u003e\n\u003c/a\u003e\u003c/p\u003e","title":"python iterator é‡åˆ°çš„ä¸€ä¸ªå‘"},{"content":"ä¿®æ”¹ä¸€ä¸ªé¡¹ç›®çš„ Unit Test ä»£ç æ—¶ï¼Œé‡åˆ°ä¸€ä¸ªå…³äº mock çš„é—®é¢˜ç‚¹ï¼ŒèŠ±äº†æˆ‘å¾ˆä¹…æ—¶é—´æ‰ï¼Œæ‰¾åˆ°è§£å†³æ–¹æ¡ˆã€‚ç‰¹æ­¤è®°å½•ä¸€ä¸‹ï¼Œæé†’è‡ªå·±ï¼Œæç¤ºä»–äººã€‚ æˆ‘ç»™ä¸€ä¸ªå¼€æºè½¯ä»¶è´¡çŒ® PR æ—¶ï¼Œé‡åˆ°ä¸€ä¸ªå¤§çš„é—®é¢˜æ˜¯æˆ‘æ€»æ˜¯è¦ç»™æˆ‘çš„ä»£ç å†™å•å…ƒæµ‹è¯•ï¼Œä¼šå‡ºç°ä¸€äº›å¥‡æ€ªçš„é—®é¢˜ï¼ˆæˆ‘ä»¥ä¸ºçš„ï¼Œå®é™…æœ€åå¾€å¾€è¯æ˜æ˜¯æˆ‘è ¢ :( ï¼Œæœ¬ä¾‹å°±æ˜¯)\nç»è¿‡ç®€åŒ–ï¼Œæœ€å°å¯å¤ç°é—®é¢˜ä»£ç é›†å¦‚ä¸‹ï¼š\næ–‡ä»¶ dependency.py def some_funny_func(): return \u0026#39;funny\u0026#39; æ–‡ä»¶ module.py from dependency import some_funny_func def call_func(): return some_funny_func() æ–‡ä»¶ tester.py from unittest.mock import patch from module import call_func def test_call_func(): def mocked_funny_func(): return \u0026#34;not funny at all\u0026#34; with patch(\u0026#34;dependency.some_funny_func\u0026#34;, mocked_funny_func): return_value = call_func() assert return_value == \u0026#34;not funny at all\u0026#34; ä¸€åˆ‡çœ‹ä¼¼åˆæƒ…åˆç†ï¼ˆæœ‰äº›é«˜æ‰‹ï¼Œå¯èƒ½å·²ç»å‘ç°é—®é¢˜äº†ï¼Œä½†æˆ‘å½“æ—¶æ²¡æœ‰çœ‹å‡ºæ¥é—®é¢˜ï¼‰ï¼Œä½†æ˜¯å°±æ˜¯é€šè¿‡ä¸äº†æµ‹è¯•ã€‚\nè¿™é‡Œçš„é”™è¯¯æ˜¯ï¼Œæ²¡æœ‰æ·±å…¥ç†è§£ patch çš„å·¥ä½œåŸç†ï¼Œpatch é€šè¿‡ä¿®æ”¹ module å±æ€§çš„æ–¹å¼å·¥ä½œã€‚è¿™é‡Œ from module import call_func æ‰§è¡Œçš„æ—¶å€™å·²ç»ç» dependency.some_funny_func å¯¼å…¥äº† moduleï¼Œ æ¢è¨€ä¹‹ï¼šmodule.some_funny_func å·²ç»æŒ‡å‘äº† dependency.some_funny_func, æ­¤æ—¶é€šè¿‡ patch(\u0026quot;dependency.some_funny_func\u0026quot;, mocked_funny_func) åªæ˜¯ä¿®æ”¹äº† dependency.some_funny_func è‡³æ–°çš„ mocked_funny_func. ä½†ä¸èƒ½ä¿®æ”¹ module.some_funny_func, å› ä¸ºè¿™ä¸ªæ˜¯ä¿®æ”¹å‰èµ‹å€¼çš„ï¼Œå®ƒç°åœ¨ä¾æ—§æŒ‡å‘åŸæ¥çš„å‡½æ•°ã€‚\nå°†ä¸Šè¿°æ”¹å†™æˆ python ä»£ç ï¼ŒåŸç†å¤§æ¦‚å¦‚ä¸‹ï¼š\n# æ¨¡æ‹Ÿ dependency.some_funny_func dependency = {} dependency[\u0026#34;some_funny_func\u0026#34;] = \u0026#34;some_value\u0026#34; # æ¨¡æ‹Ÿ module.some_funny_func module = {} module[\u0026#34;some_funny_func\u0026#34;] = dependency[\u0026#34;some_funny_func\u0026#34;] # æ¨¡æ‹Ÿ mock dependency[\u0026#34;some_funny_func\u0026#34;] = \u0026#34;some_other_value\u0026#34; # æŸ¥çœ‹ç»“æœ print(dependency[\u0026#34;some_funny_func\u0026#34;]) print(module[\u0026#34;some_funny_func\u0026#34;]) åœ¨çº¿æ¼”ç¤º åœ¨çº¿æ¼”ç¤ºåœ°å€\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/a-pitfall-of-python-mock-module/","summary":"\u003cp\u003eä¿®æ”¹ä¸€ä¸ªé¡¹ç›®çš„ Unit Test ä»£ç æ—¶ï¼Œé‡åˆ°ä¸€ä¸ªå…³äº \u003ccode\u003emock\u003c/code\u003e çš„é—®é¢˜ç‚¹ï¼ŒèŠ±äº†æˆ‘å¾ˆä¹…æ—¶é—´æ‰ï¼Œæ‰¾åˆ°è§£å†³æ–¹æ¡ˆã€‚ç‰¹æ­¤è®°å½•ä¸€ä¸‹ï¼Œæé†’è‡ªå·±ï¼Œæç¤ºä»–äººã€‚\u003ca href=\"https://mybinder.org/v2/gh/howl-anderson/howl-anderson.github.io/master?filepath=python-mock-%25E9%2581%2587%25E5%2588%25B0%25E7%259A%2584%25E4%25B8%2580%25E4%25B8%25AA%25E5%259D%2591%2Fmain.py.ipynb\"\u003e\u003cimg loading=\"lazy\" src=\"https://mybinder.org/badge.svg\" alt=\"Binder\"  /\u003e\n\u003c/a\u003e\u003c/p\u003e","title":"python mock é‡åˆ°çš„ä¸€ä¸ªå‘"},{"content":"æœ€å¤§åŒ¹é…æ¯æ¬¡å¯»æ‰¾å’Œç¡®å®šæœ€ä½³åˆ†è¯çš„æ—¶å€™æŒ‰ç…§æœ€é•¿ï¼ˆæœ€å¤§ï¼‰åŒ¹é…ä½œä¸ºä¾æ®ï¼Œä»å­—ç¬¦ä¸²çš„å³è¾¹åˆ°å·¦è¾¹ï¼ˆåå‘ï¼‰ä¾æ¬¡å¯»æ‰¾æœ€å¤§åŒ¹é…ã€‚\nè§£é‡Š ä»è§£é‡Šçš„è§’åº¦ï¼Œå¯ä»¥\u0008ç†è§£ä¸ºï¼š\u0008åˆ¤æ–­å¾…åˆ†è¯å­—ç¬¦ä¸²çš„å N ä¸ªå­—ç¬¦æ„æˆçš„å­—ç¬¦ä¸²æ˜¯å¦åœ¨å­—å…¸ä¸­ï¼Œå¦‚æœåœ¨ï¼Œåˆ™åŒ¹é…ç»“æŸã€‚å¦‚æœæ²¡æœ‰åŒ¹é…æˆåŠŸï¼Œåˆ™ä¾æ¬¡ç¼©å‡ N ç›´åˆ°åŒ¹é…æˆåŠŸã€‚\nç¤ºä¾‹ ä»¥ ä¸­å›½çš„é¦–éƒ½æ˜¯åŒ—äº¬ ä¸ºä¾‹, å‡è®¾ N åˆå§‹åŒ–ä¸º 4ï¼š\n\u0008åŒ¹é… éƒ½æ˜¯åŒ—äº¬ï¼Œ å­—å…¸ä¸­æ— æ­¤è¯è¯­ï¼ŒåŒ¹é…å¤±è´¥ï¼Œç¼©å‡ N ä¸º 3 åŒ¹é… æ˜¯åŒ—äº¬ï¼Œ å­—å…¸ä¸­æ— æ­¤è¯è¯­ï¼ŒåŒ¹é…å¤±è´¥ï¼Œç¼©å‡ N ä¸º 2 åŒ¹é… åŒ—äº¬ï¼Œ å­—å…¸ä¸­æœ‰æ­¤è¯è¯­ï¼ŒåŒ¹é…æˆåŠŸï¼Œç»“æŸåŒ¹é… ç»§ç»­åŒ¹é…å‰©ä½™æœªåˆ†è¯å­—ç¬¦ä¸² ä¸­å›½çš„é¦–éƒ½æ˜¯ï¼Œç›´è‡³å­—ç¬¦ä¸²å…¨éƒ¨è¢«åˆ†è¯ã€‚\nå±€é™ å› ä¸ºåªè€ƒè™‘äº†èƒ½å¦æ„æˆè¯æ±‡ï¼Œå®Œå…¨æ²¡æœ‰è€ƒè™‘ä¸Šä¸‹æ–‡ï¼Œæ‰€ä»¥éƒ¨åˆ†æƒ…å†µä¸‹ä¼šå‡ºç°é—®é¢˜ã€‚ ä¾‹å¦‚ ä¸­å›½çš„é¦–éƒ½æ˜¯åŒ—äº¬ åˆ™ä¼šè¢«åˆ†æˆ ä¸­å›½ / çš„ / é¦– / éƒ½æ˜¯ / åŒ—äº¬\nä¼˜åŒ–æ–¹æ¡ˆ æœ¬ç®—æ³•\u0008è€—æ—¶æœ€å¤§çš„éƒ¨åˆ†åœ¨äºæ‰«æè¯å…¸ï¼Œå› æ­¤å¯ä»¥é€šè¿‡ç‰¹å®šçš„æ•°æ®ç»“æ„ä¼˜åŒ–åŠ é€Ÿå­—å…¸æŸ¥æ‰¾è¿‡ç¨‹ï¼š\næŒ‰ç…§é•¿åº¦åˆ†åˆ«æ„å»ºå¤šä¸ªå­—å…¸ï¼Œèƒ½å¤Ÿä¸€å®šç¨‹åº¦çš„åŠ é€Ÿå­—å…¸æ‰«æçš„é€Ÿåº¦ ä½¿ç”¨\u0008 Trie-Tree èƒ½å¤Ÿ\u0008æå¤§çš„åŠ é€ŸæŸ¥æ‰¾è¿‡ç¨‹ \u0008å…³è”ç®—æ³• å’Œ æœ€å¤§æ­£å‘åŒ¹é…æ³• æ€æƒ³å®Œå…¨ä¸€æ ·ï¼Œ\u0008ç”¨äºè§£å†³ æœ€å¤§æ­£å‘åŒ¹é…æ³• çš„æŸäº›é—®é¢˜ã€‚æ¯”å¦‚ï¼šæˆ‘ä»¬åœ¨é‡ç”ŸåŠ¨ç‰©å›­ç© åœ¨ æœ€å¤§æ­£å‘åŒ¹é…æ³• ä¸­æ— æ³•æ­£ç¡®åˆ†è¯ï¼Œä½† åå‘æœ€å¤§åŒ¹é…æ³• èƒ½å¤Ÿæ­£ç¡®åˆ†è¯ã€‚\nå‚è€ƒæ–‡çŒ® ä¸­æ–‡åˆ†è¯åŸºç¡€åŸåˆ™åŠæ­£å‘æœ€å¤§åŒ¹é…æ³•ã€é€†å‘æœ€å¤§åŒ¹é…æ³•ã€åŒå‘æœ€å¤§åŒ¹é…æ³•çš„åˆ†æ ","permalink":"https://blog.xiaoquankong.ai/zh/posts/creating-a-chinese-tokenizer-using-the-maximum-reverse-matching-method/","summary":"\u003cp\u003eæœ€å¤§åŒ¹é…æ¯æ¬¡å¯»æ‰¾å’Œç¡®å®šæœ€ä½³åˆ†è¯çš„æ—¶å€™æŒ‰ç…§æœ€é•¿ï¼ˆæœ€å¤§ï¼‰åŒ¹é…ä½œä¸ºä¾æ®ï¼Œä»å­—ç¬¦ä¸²çš„å³è¾¹åˆ°å·¦è¾¹ï¼ˆåå‘ï¼‰ä¾æ¬¡å¯»æ‰¾æœ€å¤§åŒ¹é…ã€‚\u003c/p\u003e","title":"æ„å»ºä¸­æ–‡åˆ†è¯å™¨ - åå‘æœ€å¤§åŒ¹é…æ³•"},{"content":"å°†æ‰€æœ‰å¯èƒ½çš„åˆ†è¯ç»“æœæŒ‰ç…§è¯è¯­æ„å»ºæˆä¸€ä¸ªæœ‰å‘æ— ç¯å›¾ï¼Œå¯»æ‰¾å…¶ä¸­è”åˆæ¦‚ç‡æœ€å¤§çš„è·¯å¾„ã€‚\nè§£é‡Š æ‰€éœ€çš„è¯­æ–™æ˜¯ä¸€ä¸ªåŒ…å«è¯è¯­é¢‘ç‡çš„å­—å…¸ã€‚æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„åˆ†è¯ç»“æœå¯ä»¥é€šè¿‡æŸ¥æ‰¾å­—å…¸ä¸­çš„è¯æ˜¯å¦åœ¨ä¸€ä¸ªå­—ç¬¦ä¸²çš„å¼€å§‹ä½ç½®æ¥å®Œæˆã€‚\næ„å»ºæˆæœ‰å‘æ— ç¯å›¾åï¼Œæˆ‘ä»¬æ‰¾å‡ºæ‰€æœ‰è·¯å¾„ä¸­è”åˆæ¦‚ç‡ï¼ˆæœ´ç´ è§‚ç‚¹ä¸ºï¼šå„ä¸ª\u0008è¯è¯­æ¦‚ç‡ç›¸ä¹˜ï¼‰æœ€å¤§çš„è·¯å¾„ã€‚ä½†ä¸€èˆ¬æƒ…å†µä¸‹å›¾ç†è®ºå’Œå›¾ç›¸å…³çš„åº“éƒ½æ˜¯ç”¨æ¥æ±‚è§£æœ€çŸ­è·¯å¾„ï¼ˆæ‰€æœ‰è·¯å¾„ä¸­æƒé‡ä¹‹å’Œæœ€å°çš„è·¯å¾„ï¼‰ï¼Œå› æ­¤è¿™é‡Œåšæ•°å­¦ä¸Šçš„å˜æ¢ï¼Œèƒ½å¤ŸæŒ‰ç…§æœ€å°è·¯å¾„æ±‚è§£çš„æ–¹å¼ï¼Œæ‰¾åˆ°è”åˆæ¦‚ç‡æœ€å¤§çš„è·¯å¾„ã€‚\u0008å…·ä½“å˜åŠ¨å¦‚ä¸‹:\nä½¿ç”¨ log å‡½æ•°å°†æ±‚è§£ç›¸ä¹˜é—®é¢˜è½¬æ¢æˆç›¸åŠ é—®é¢˜ log(a * b) = log(a) + log(b) ä½¿ç”¨å€’æ•°å‡½æ•°å°†æ±‚è§£æœ€å¤§é—®é¢˜å˜æˆæ±‚è§£æœ€å°é—®é¢˜ a \u0026gt; b then 1/a \u0026lt; 1/b ç¤ºä¾‹ ä»¥ æˆ‘ä»¬åœ¨é‡ç”ŸåŠ¨ç‰©å›­ç© ä¸ºä¾‹ï¼Œå‡è®¾æˆ‘ä»¬çš„è¯å…¸é‡ŒåªåŒ…å«å¦‚ä¸‹è¯æ±‡\nè¯æ±‡ é¢‘æ•° æ¦‚ç‡ æ¦‚ç‡çš„å€’æ•° log(æ¦‚ç‡çš„å€’æ•°) æˆ‘ä»¬ 30 0.30 3.3 1.19 åœ¨ 40 0.40 2.5 3.69 åœ¨é‡ 2 0.02 50 3.91 é‡ç”ŸåŠ¨ç‰©å›­ 8 0.08 12.5 2.53 ç‰© 1 0.01 100 4.61 å›­ 1 0.01 100 4.61 ç© 18 0.18 5.6 1.72 NOTE : log å‡½æ•°åœ¨è¿™é‡Œæ˜¯ä»¥è‡ªç„¶å¯¹æ•° e ä¸ºä½çš„\u0008ï¼Œç­‰åŒäºå‡½æ•° ln\nä» æˆ‘ä»¬åœ¨é‡ç”ŸåŠ¨ç‰©å›­ç© å¼€å§‹ï¼Œæ‰«æè¯æ±‡è¡¨ï¼Œæ‰¾åˆ°åŒ¹é…çš„å‰ç¼€è¯æ±‡ã€‚\nç¬¬ä¸€è½®æ‰¾åˆ°è¯æ±‡ æˆ‘ä»¬ï¼Œå‰©ä½™æœªåˆ†è¯\u0008\u0008å­—ç¬¦ä¸²ä¸º åœ¨é‡ç”ŸåŠ¨ç‰©å›­ç© ç¬¬äºŒè½®æ‰¾åˆ°è¯æ±‡ åœ¨ å’Œ åœ¨é‡ï¼Œå‰©ä½™æœªåˆ†è¯å­—ç¬¦ä¸²ä¸º é‡ç”ŸåŠ¨ç‰©å›­ç© å’Œ ç”ŸåŠ¨ç‰©å›­ç© ç¬¬ä¸‰è½®åˆ™å¯¹ä¸Šé¢ä¸¤ä¸ªæœªåˆ†è¯å­—ç¬¦ä¸²ï¼Œåº”ç”¨ç›¸åŒçš„è§„åˆ™åˆ†è¯ï¼Œå¾—åˆ°è¯æ±‡ é‡ç”ŸåŠ¨ç‰©å›­ å’Œ ç”ŸåŠ¨ å¦‚æ­¤é‡å¤ç›´åˆ°æ‰€æœ‰çš„æœªåˆ†è¯å­—ç¬¦ä¸²ä¸ºç©ºã€‚ ç»è¿‡ä¸Šè¿°æ­¥éª¤ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸¤ç§åˆ†è¯å¯èƒ½\næˆ‘ä»¬ / åœ¨ / é‡ç”ŸåŠ¨ç‰©å›­ / ç© æˆ‘ä»¬ / åœ¨é‡ / ç”ŸåŠ¨ / ç‰© / å›­ / ç© æ·»åŠ å¼€å§‹èŠ‚ç‚¹ \u0026lt;start\u0026gt; å’Œ ç»“æŸèŠ‚ç‚¹ \u0026lt;end\u0026gt; åï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºä¸€ä¸ª æœ‰å‘æ— ç¯å›¾, èŠ‚ç‚¹ä¹‹é—´çš„è¾¹çš„æƒé‡ä¸ºä¸Šä¸€ä¸ªèŠ‚ç‚¹å¯¹åº”çš„ log(æ¦‚ç‡çš„å€’æ•°)ã€‚\nåˆ™å¾—åˆ°ç±»ä¼¼å¦‚ä¸‹çš„æœ‰å‘æ— ç¯å›¾ï¼š\né€šè¿‡æ±‚è§£æœ€å°è·¯å¾„çš„æ–¹æ³•å¯ä»¥å¾—åˆ°æœ€çŸ­è·¯å¾„ä¸º æˆ‘ä»¬ / åœ¨ / é‡ç”ŸåŠ¨ç‰©å›­ / ç©\nå±€é™ å› ä¸ºåŸºäºè¯å…¸ï¼Œå› æ­¤ä¸å…·å¤‡æ–°è¯å‘ç°çš„èƒ½åŠ›ï¼ŒåŒæ—¶ä¹Ÿå¾ˆéš¾å¤„ç†æ­§ä¹‰é—®é¢˜ã€‚\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/implementing-a-dag-based-chinese-tokenizer/","summary":"\u003cp\u003eå°†æ‰€æœ‰å¯èƒ½çš„åˆ†è¯ç»“æœæŒ‰ç…§è¯è¯­æ„å»ºæˆä¸€ä¸ªæœ‰å‘æ— ç¯å›¾ï¼Œå¯»æ‰¾å…¶ä¸­è”åˆæ¦‚ç‡æœ€å¤§çš„è·¯å¾„ã€‚\u003c/p\u003e","title":"æ„å»ºä¸­æ–‡åˆ†è¯å™¨ - æœ‰å‘æ— ç¯å›¾æ³•"},{"content":"æœ€å¤§åŒ¹é…æ¯æ¬¡å¯»æ‰¾å’Œç¡®å®šæœ€ä½³åˆ†è¯çš„æ—¶å€™æŒ‰ç…§æœ€é•¿ï¼ˆæœ€å¤§ï¼‰åŒ¹é…ä½œä¸ºä¾æ®ï¼Œä»å­—ç¬¦ä¸²çš„å·¦è¾¹åˆ°å³è¾¹ï¼ˆæ­£å‘ï¼‰ä¾æ¬¡å¯»æ‰¾æœ€å¤§åŒ¹é…ã€‚\nè§£é‡Š ä»è§£é‡Šçš„è§’åº¦ï¼Œå¯ä»¥\u0008ç†è§£ä¸ºï¼š\u0008åˆ¤æ–­å¾…åˆ†è¯å­—ç¬¦ä¸²çš„å‰ N ä¸ªå­—ç¬¦æ„æˆçš„å­—ç¬¦ä¸²æ˜¯å¦åœ¨å­—å…¸ä¸­ï¼Œå¦‚æœåœ¨ï¼Œåˆ™åŒ¹é…ç»“æŸã€‚å¦‚æœæ²¡æœ‰åŒ¹é…æˆåŠŸï¼Œåˆ™ä¾æ¬¡ç¼©å‡ N ç›´åˆ°åŒ¹é…æˆåŠŸã€‚\nç¤ºä¾‹ ä»¥ æˆ‘ä»¬åœ¨é‡ç”ŸåŠ¨ç‰©å›­ç© ä¸ºä¾‹, å‡è®¾ N åˆå§‹åŒ–ä¸º 4ï¼š\n\u0008åŒ¹é… æˆ‘ä»¬åœ¨é‡ï¼Œ å­—å…¸ä¸­æ— æ­¤è¯è¯­ï¼ŒåŒ¹é…å¤±è´¥ï¼Œç¼©å‡ N ä¸º 3 åŒ¹é… æˆ‘ä»¬åœ¨ï¼Œ å­—å…¸ä¸­æ— æ­¤è¯è¯­ï¼ŒåŒ¹é…å¤±è´¥ï¼Œç¼©å‡ N ä¸º 2 åŒ¹é… æˆ‘ä»¬ï¼Œ å­—å…¸ä¸­æœ‰æ­¤è¯è¯­ï¼ŒåŒ¹é…æˆåŠŸï¼Œç»“æŸåŒ¹é… ç»§ç»­åŒ¹é…å‰©ä½™æœªåˆ†è¯å­—ç¬¦ä¸² åœ¨é‡ç”ŸåŠ¨ç‰©å›­ç©ï¼Œç›´è‡³å­—ç¬¦ä¸²å…¨éƒ¨è¢«åˆ†è¯ã€‚\nå±€é™ å› ä¸ºåªè€ƒè™‘äº†èƒ½å¦æ„æˆè¯æ±‡ï¼Œå®Œå…¨æ²¡æœ‰è€ƒè™‘ä¸Šä¸‹æ–‡ï¼Œæ‰€ä»¥éƒ¨åˆ†æƒ…å†µä¸‹ä¼šå‡ºç°é—®é¢˜ã€‚ ä¾‹å¦‚ æˆ‘ä»¬åœ¨é‡ç”ŸåŠ¨ç‰©å›­ç© åˆ™ä¼šè¢«åˆ†æˆ æˆ‘ä»¬ / åœ¨é‡ / ç”ŸåŠ¨ / ç‰© / å›­ / ç©\nä¼˜åŒ–æ–¹æ¡ˆ æœ¬ç®—æ³•\u0008è€—æ—¶æœ€å¤§çš„éƒ¨åˆ†åœ¨äºæ‰«æè¯å…¸ï¼Œå› æ­¤å¯ä»¥é€šè¿‡ç‰¹å®šçš„æ•°æ®ç»“æ„ä¼˜åŒ–åŠ é€Ÿå­—å…¸æŸ¥æ‰¾è¿‡ç¨‹ï¼š\næŒ‰ç…§é•¿åº¦åˆ†åˆ«æ„å»ºå¤šä¸ªå­—å…¸ï¼Œèƒ½å¤Ÿä¸€å®šç¨‹åº¦çš„åŠ é€Ÿå­—å…¸æ‰«æçš„é€Ÿåº¦ ä½¿ç”¨\u0008 Trie-Tree èƒ½å¤Ÿ\u0008æå¤§çš„åŠ é€ŸæŸ¥æ‰¾è¿‡ç¨‹ \u0008å…³è”ç®—æ³• åå‘æœ€å¤§åŒ¹é…æ³• å’Œ æœ€å¤§æ­£å‘åŒ¹é…æ³• æ€æƒ³å®Œå…¨ä¸€æ ·ï¼Œ\u0008ç”¨äºè§£å†³ æœ€å¤§æ­£å‘åŒ¹é…æ³• çš„æŸäº›é—®é¢˜ã€‚æ¯”å¦‚ï¼šæˆ‘ä»¬åœ¨é‡ç”ŸåŠ¨ç‰©å›­ç© åœ¨ æœ€å¤§æ­£å‘åŒ¹é…æ³• ä¸­æ— æ³•æ­£ç¡®åˆ†è¯ï¼Œä½† åå‘æœ€å¤§åŒ¹é…æ³• èƒ½å¤Ÿæ­£ç¡®åˆ†è¯ã€‚\nå‚è€ƒæ–‡çŒ® ä¸­æ–‡åˆ†è¯åŸºç¡€åŸåˆ™åŠæ­£å‘æœ€å¤§åŒ¹é…æ³•ã€é€†å‘æœ€å¤§åŒ¹é…æ³•ã€åŒå‘æœ€å¤§åŒ¹é…æ³•çš„åˆ†æ ","permalink":"https://blog.xiaoquankong.ai/zh/posts/creating-a-chinese-tokenizer-using-the-maximum-forward-matching-method/","summary":"\u003cp\u003eæœ€å¤§åŒ¹é…æ¯æ¬¡å¯»æ‰¾å’Œç¡®å®šæœ€ä½³åˆ†è¯çš„æ—¶å€™æŒ‰ç…§æœ€é•¿ï¼ˆæœ€å¤§ï¼‰åŒ¹é…ä½œä¸ºä¾æ®ï¼Œä»å­—ç¬¦ä¸²çš„å·¦è¾¹åˆ°å³è¾¹ï¼ˆæ­£å‘ï¼‰ä¾æ¬¡å¯»æ‰¾æœ€å¤§åŒ¹é…ã€‚\u003c/p\u003e","title":"æ„å»ºä¸­æ–‡åˆ†è¯å™¨ - æ­£å‘æœ€å¤§åŒ¹é…æ³•"},{"content":" TL;DR ä»é›¶å¼€å§‹å®ç° Q-learning ç®—æ³•ï¼Œåœ¨ OpenAI Gym çš„ç¯å¢ƒä¸­æ¼”ç¤ºï¼šå¦‚ä½•ä¸€æ­¥æ­¥å®ç°å¢å¼ºå­¦ä¹ ã€‚\nå‰é¢çš„åšæ–‡é‡Œå·²ç»ä»‹ç»è¿‡ Q-learning çš„ä¸€äº›åŸºæœ¬æƒ…å†µäº†ï¼Œå¦‚æœä½ æ²¡è§è¿‡å‰é¢çš„åšæ–‡æˆ–è€…å·²ç»å¿˜è®°çš„å·®ä¸å¤šäº†ï¼Œé‚£ä¹ˆå¯ä»¥ä½¿ç”¨è¿™ä¸ª Reinforcement Learning: åˆæ¬¡äº¤æ‰‹ï¼Œå¤šå¤šæŒ‡æ•™ è®¿é—®ã€‚\nä½†æ˜¯æ€»çš„æ¥è¯´ï¼Œå¦‚æœæ²¡æœ‰å®é™…ä»£ç è·‘ä¸€ç•ªï¼Œä¼°è®¡ä½ å¯¹è¿™ä¸ªç®—æ³•çš„æ­£ç¡®æ€§è¿˜æ˜¯æœ‰ç–‘è™‘çš„ã€‚æœ¬æ–‡å°†ä»å¤´æ„å»ºä¸€ä¸ª Q-learning ç®—æ³•ï¼Œæ¥è§£å†³ä¸€ä¸ª toy çº§åˆ«çš„å¼ºåŒ–å­¦ä¹ åœºæ™¯çš„å­¦ä¹ å·¥ä½œã€‚å¸Œæœ›èƒ½åŠ æ·±ä½ å¯¹ Q-learning çš„ç†è§£å’Œå¯¹å¼ºåŒ–å­¦ä¹ çš„è®¤çŸ¥ã€‚\næºä»£ç  æ¯”è¾ƒç²¾ç¾çš„ï¼Œä½†æ˜¯åšäº†ä¸€å®šæ‰©å±•çš„å®ç°åœ¨ q_learning_demo å’Œæœ¬æ–‡ä»£ç ç›¸å¯¹åº”çš„ï¼Œç¨æœ‰æ”¹åŠ¨çš„ Jupyter Notebook åœ¨ proof-of-concept åœºæ™¯ æˆ‘ä»¬è¦ç”¨ Q-learning è§£å†³ä»€ä¹ˆé—®é¢˜å‘¢ï¼Ÿæˆ‘ä»¬ä½¿ç”¨ OpenAI Gym é‡Œæä¾›çš„ä¸€ä¸ªç¯å¢ƒï¼šFrozenLake-v0.\nFrozenLake-v0 ç¯å¢ƒçš„ä¸­æ–‡æè¿°å¤§æ¦‚æ˜¯è¿™æ ·çš„ï¼š\nå†¬å¤©çš„æ—¶å€™ï¼Œä½ å’Œä½ çš„æœ‹å‹ä»¬åœ¨å…¬å›­æ‰”é£ç›˜ã€‚ ä½ ä¸å°å¿ƒæŠŠé£ç›˜æ‰”åˆ°äº†å…¬å›­çš„æ¹–ä¸­é—´ã€‚ æ¹–é¢å·²ç»ç»“å†°ï¼Œä½†æ˜¯æœ‰äº›åœ°æ–¹çš„æ²¡æœ‰ç»“å†°ï¼Œå½¢æˆä¸€ä¸ªå†°æ´ï¼Œæœ‰äººè¸©ä¸Šå»ä¼šæ‰ä¸‹å»ã€‚ è¿™ä¸ªé£ç›˜å¯¹ä½ æ¥è¯´éå¸¸å®è´µï¼Œä½ è§‰å¾—éå¸¸æœ‰å¿…è¦æŠŠé£ç›˜æ‹¿å›æ¥ã€‚ ä½†æ˜¯å†°é¢å¾ˆæ»‘ï¼Œä½ ä¸èƒ½æ€»æ˜¯æƒ³å»ä»€ä¹ˆæ–¹å‘å°±å»ä»€ä¹ˆæ–¹å‘ï¼Œæ»‘æ»‘çš„å†°é¢å¯èƒ½ä¼šå¸¦ä½ èµ°å‘åˆ«çš„æ–¹å‘ã€‚ å†°é¢ç”¨å¦‚ä¸‹çš„å­—ç¬¦å—è¡¨ç¤ºï¼š SFFF FHFH FFFH HFFG S : Safeï¼Œå¼€å§‹ç‚¹ï¼Œå®‰å…¨ F : frozen surface, å†»ç»“çš„è¡¨é¢ï¼Œå®‰å…¨ H : hole, æ‰ä¸‹å»å°±æ­»å®šäº† G : goal, é£ç›˜æ‰€åœ¨çš„åœ°æ–¹ æ¯ä¸ªè½®å›ï¼Œä»¥ä½ æ‹¿å›é£ç›˜æˆ–è€…æ‰è¿›æ´é‡Œè€Œç»“æŸã€‚ åªæœ‰å½“ä½ æ‹¿åˆ°é£ç›˜æ‰èƒ½è·å¾—1ä¸ªå¥–åŠ±ï¼Œå…¶ä»–æƒ…å†µéƒ½ä¸º0 OpenAI Gym OpenAI æ˜¯ Elon Musk åˆ›å»ºçš„ä¸€å®¶è‡´åŠ›äºéç›ˆåˆ©çš„é€šç”¨äººå·¥æ™ºèƒ½çš„å…¬å¸ã€‚ å…¶å¼€æºäº§å“ Gym æ˜¯æä¾›äº†ä¸€ç§å¢å¼ºå­¦ä¹ çš„å®ç°æ¡†æ¶ï¼Œä¸»è¦ç”¨äºæä¾›ä¸€äº›æ¨¡æ‹Ÿå™¨ä¾›ç ”ç©¶ä½¿ç”¨ã€‚\nä¹‹å‰çš„åšå®¢æåˆ°è¿‡ï¼Œå¢å¼ºå­¦ä¹ æ˜¯ Agent å’Œ Environment ç›´æ¥çš„äº¤äº’æ„æˆçš„ã€‚Gym æä¾›äº†å¾ˆå¤šå¸¸è§çš„ Environment å¯¹è±¡ã€‚åˆ©ç”¨è¿™äº› Environmentï¼Œç ”ç©¶è€…å¯ä»¥å¾ˆå¿«æ„å»ºå¢å¼ºå­¦ä¹ çš„åº”ç”¨ã€‚\nGym è¿è¡Œæ¨¡å¼ # å¯¼å…¥gym import gym # æ„å»ºç¯å¢ƒ env = gym.make(\u0026#34;Taxi-v1\u0026#34;) # è·å–ç¬¬ä¸€æ¬¡çš„è§‚å¯Ÿç»“æœ observation = env.reset() # å¼€å§‹æ¢ç´¢ç¯å¢ƒ for _ in range(1000): env.render() # æ¸²æŸ“è§‚å¯Ÿç»“æœ # ä½ çš„ Agent åº”è¯¥ä¼šæ ¹æ®è§‚å¯Ÿç»“æœï¼Œé€‰æ‹©æœ€åˆé€‚çš„åŠ¨ä½œï¼Œä½†è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨éšæœºé€‰æ‹©çš„åŠ¨ä½œ action = env.action_space.sample() # your agent here (this takes random actions) # å°†åŠ¨ä½œå‘é€ç»™ç¯å¢ƒï¼Œè·å–æ–°çš„è§‚å¯Ÿç»“æœã€å¥–åŠ±å’Œæ˜¯å¦ç»“æŸçš„æ ‡å¿—ç­‰ observation, reward, done, info = env.step(action) if done: # æ¸¸æˆç»“æŸ break é€šè¿‡ä¸Šé¢çš„ç¤ºä¾‹ï¼Œä½ åº”è¯¥äº†è§£OpenAI gymçš„å·¥ä½œæ¨¡å¼ã€‚\nè®­ç»ƒæµç¨‹ å¯¼å…¥ä¾èµ–\nimport gym import numpy as np from collections import defaultdict import functools å®šä¹‰ä¸¤ä¸ªä¸»è¦ç»„ä»¶\n# æ„å»º Environment env = gym.make(\u0026#39;FrozenLake-v0\u0026#39;) env.seed(0) # ç¡®ä¿ç»“æœå…·æœ‰å¯é‡ç°æ€§ # æ„å»º Agent tabular_q_agent = TabularQAgent(env.observation_space, env.action_space) # å¼€å§‹è®­ç»ƒ train(tabular_q_agent, env) tabular_q_agent.test(env) è®­ç»ƒå¾ªç¯\ndef train(tabular_q_agent, env): for episode in range(100000): # è®­ç»ƒ 100000 æ¬¡ all_reward, step_count = tabular_q_agent.learn(env) TabularQAgent çš„å®ç°\nclass TabularQAgent(object): def __init__(self, observation_space, action_space): self.observation_space = observation_space self.action_space = action_space self.action_n = action_space.n self.config = { \u0026#34;learning_rate\u0026#34;: 0.5, \u0026#34;eps\u0026#34;: 0.05, # Epsilon in epsilon greedy policies \u0026#34;discount\u0026#34;: 0.99, \u0026#34;n_iter\u0026#34;: 10000} # Number of iterations self.q = defaultdict(functools.partial(generate_zeros, n=self.action_n)) def act(self, observation, eps=None): if eps is None: eps = self.config[\u0026#34;eps\u0026#34;] # epsilon greedy. action = np.argmax(self.q[observation]) if np.random.random() \u0026gt; eps else self.action_space.sample() return action def learn(self, env): obs = env.reset() rAll = 0 step_count = 0 for t in range(self.config[\u0026#34;n_iter\u0026#34;]): action = self.act(obs) obs2, reward, done, _ = env.step(action) future = 0.0 if not done: future = np.max(self.q[obs2]) self.q[obs][action] = (1 - self.config[\u0026#34;learning_rate\u0026#34;]) * self.q[obs][action] + self.config[\u0026#34;learning_rate\u0026#34;] * (reward + self.config[\u0026#34;discount\u0026#34;] * future) obs = obs2 rAll += reward step_count += 1 if done: break return rAll, step_count def test(self, env): obs = env.reset() env.render(mode=\u0026#39;human\u0026#39;) for t in range(self.config[\u0026#34;n_iter\u0026#34;]): env.render(mode=\u0026#39;human\u0026#39;) action = self.act(obs, eps=0) obs2, reward, done, _ = env.step(action) env.render(mode=\u0026#39;human\u0026#39;) if done: break obs = obs2 æ ¸å¿ƒä»£ç  æˆ‘ä»¬é‡ç‚¹å…³æ³¨æ ¸å¿ƒä»£ç ï¼ŒQ-learning æ˜¯å¦‚ä½•å­¦ä¹ çš„ï¼Œç›¸å…³ä»£ç ç®€åŒ–åå¾—åˆ°ï¼š\nå¦‚ä½•æ›´æ–° Q table # è·å–ç¬¬ä¸€æ¬¡è§‚å¯Ÿç»“æœ obs = env.reset() while True: # ä¸€ç›´å¾ªç¯ï¼Œç›´åˆ°æ¸¸æˆç»“æŸ action = self.act(obs) # æ ¹æ®ç­–ç•¥ï¼Œé€‰æ‹© action obs2, reward, done, _ = env.step(action) future = 0.0 if not done: future = np.max(self.q[obs2]) # è·å–åä¸€æ­¥æœŸæœ›çš„æœ€å¤§å¥–åŠ± # æ›´æ–° Q è¡¨æ ¼ï¼Œä¿ç•™éƒ¨åˆ†å½“å‰å€¼ åŠ ä¸Š éƒ¨åˆ†å½“å‰å¥–åŠ±å’Œæœªæ¥ä¸€æ­¥çš„æœ€å¤§å¥–åŠ± self.q[obs][action] = (1 - self.config[\u0026#34;learning_rate\u0026#34;]) * self.q[obs][action] + self.config[\u0026#34;learning_rate\u0026#34;] * (reward + self.config[\u0026#34;discount\u0026#34;] * future) # æ›´æ–° obs = obs2 # æ¸¸æˆç»“æŸï¼Œé€€å‡ºå¾ªç¯ if done: break explore / exploit é—®é¢˜ ä¸Šé¢çš„ä»£ç æˆ‘åªæåˆ°äº† self.act ä¼šæ ¹æ®ç­–ç•¥é€‰æ‹© actionï¼Œé‚£ä¹ˆè¯¥å¦‚ä½•é€‰æ‹©å‘¢ï¼Ÿè¿™é‡Œå°±æ¶‰åŠåˆ°äº† explore exploit tradeoff çš„é—®é¢˜äº†ã€‚æˆ‘ä»¬ç†æƒ³ä¸­çš„ action é€‰æ‹©ç­–ç•¥æ˜¯æ—¢èƒ½å……åˆ†åˆ©ç”¨ç°æœ‰å­¦ä¹ åˆ°çš„çŸ¥è¯†ï¼Œæ¯æ¬¡éƒ½å»æœ€å¤§åŒ–çš„æœ€ç»ˆçš„rewardï¼Œè¿™å°±æ˜¯ exploitã€‚ä½†æ˜¯åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå¸Œæœ›æˆ‘ä»¬çš„é€‰æ‹©ç­–ç•¥èƒ½é€‚å½“çš„å»æ¢ç´¢ä¸€ä¸‹å…¶ä»–è·¯å¾„ï¼Œä¸èƒ½å›ºå®šåœ¨å·²ç»çŸ¥é“çš„æœ€ä¼˜é€‰æ‹©ï¼Œé¿å…å±€éƒ¨æœ€ä¼˜è§£ï¼Œé€‚å½“æ—¶å€™ä¹Ÿå»æ¢ç´¢å…¶ä»–è·¯å¾„ï¼Œå¯èƒ½èƒ½å‘ç°æ›´åŠ ä¼˜ç§€çš„è·¯å¾„ï¼Œä¹Ÿå°±æ˜¯å…¨å±€æœ€ä¼˜è§£ï¼Œè¿™å°±æ˜¯ explore é—®é¢˜ã€‚\næˆ‘ä»¬é‡‡å–äº†ä¸€ä¸ªæ¦‚ç‡æ–¹æ¡ˆï¼Œæœ‰ä¸€å®šæ¦‚ç‡å»é€šè¿‡éšæœºé€‰æ‹©çš„æ–¹å¼ï¼Œæ¢ç´¢æ–°è·¯å¾„ã€‚\n# eps æ•°å€¼åœ¨ [0, 1] ï¼Œæ§åˆ¶æ¢ç´¢çš„åŠ›åº¦ï¼Œè¶Šå¤§æ¢ç´¢çš„è¶Šå¤š if eps is None: eps = self.config[\u0026#34;eps\u0026#34;] # epsilon greedy. action = np.argmax(self.q[observation]) if np.random.random() \u0026gt; eps else self.action_space.sample() return action å…¶ä»–æ²¡æœ‰äº¤ä»£çš„ç‚¹ ç”±äºæœ¬ç¯‡æ˜¯ç§‘æ™®æ€§è´¨ï¼Œæ‰€ä»¥æ²¡æœ‰coverå¾ˆå¤šå…¶ä»–çš„é—®é¢˜ç‚¹ï¼Œæ¯”å¦‚å­¦ä¹ å’Œæ¢ç´¢çš„å› å­å¯ä»¥æ˜¯decayçš„ï¼Œåˆšå¼€å§‹è®­ç»ƒçš„æ—¶å€™å­¦ä¹ å’Œæ¢ç´¢å¼ºåº¦æ¯”è¾ƒå¤§ï¼Œåç»­æ…¢æ…¢ç¼©å°ï¼Œè¿™æ ·æ¨¡å‹å°±ä¼šæ…¢æ…¢æ”¶æ•›ã€‚\n","permalink":"https://blog.xiaoquankong.ai/zh/posts/demo-of-q-learning-in-openai-gym/","summary":"\u003cp\u003e\u003ca href=\"https://mybinder.org/v2/gh/howl-anderson/q_learning_demo/master?filepath=jupyter_notebooks%2Fproof-of-concept.ipynb\"\u003e\u003cimg loading=\"lazy\" src=\"https://mybinder.org/badge.svg\" alt=\"Binder\"  /\u003e\n\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTL;DR\u003c/strong\u003e ä»é›¶å¼€å§‹å®ç° Q-learning ç®—æ³•ï¼Œåœ¨ OpenAI Gym çš„ç¯å¢ƒä¸­æ¼”ç¤ºï¼šå¦‚ä½•ä¸€æ­¥æ­¥å®ç°å¢å¼ºå­¦ä¹ ã€‚\u003c/p\u003e","title":"åŸºäº OpenAI Gym çš„ Q-Learning ç®—æ³•æ¼”ç¤º"}]