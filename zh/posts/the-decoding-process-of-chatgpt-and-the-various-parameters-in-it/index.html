<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>ChatGPT 的解码过程和其中的各种参数 | Xiaoquan Kong&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="TL:DR OpenAI 的 ChatGPT 在其官方文档（https://platform.openai.com/docs/api-reference/chat/create）中给出了各种参数的范围和含义。我们将讨论 ChatGPT 的生成过程和这些参数是如何实现其生成的效果的。
ChatGPT 的解码过程 我们假设 minGPT （等同于 GPT-2） 和 ChatGPT 拥有一样的解码过程：https://github.com/karpathy/minGPT/blob/master/mingpt/model.py#LL283C12-L283C12 。
总体过程可以概括为以下几个步骤：
将用户的请求，从 1 个扩充成 num_samples 大小的 batch 进行模型推理，得到 logits 进行 temperature 映射：logits = logits / temperature [可选] 进行 topk 处理：logits = topk_func(logits, top_k) logits 到 概率的转换：probs = softmax(logits) 是否 sample： 进行 sample：idx_next = multinomial_sample(probs, num_samples=1) 不进行 sample：idx_next = topk_func(probs, k=1) 重复上述过程 max_new_tokens 次 ChatGPT 的解码参数 temperature temperature 参数的官方定义如下：
temperature number Optional Defaults to 1">
<meta name="author" content="Xiaoquan Kong">
<link rel="canonical" href="https://blog.xiaoquankong.ai/zh/posts/the-decoding-process-of-chatgpt-and-the-various-parameters-in-it/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.bf26bdb49ef54e8a3512e42be7571296309f9c383b1f25e7afb4355f5c9b5381.css" integrity="sha256-vya9tJ71Too1EuQr51cSljCfnDg7HyXnr7Q1X1ybU4E=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://blog.xiaoquankong.ai/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://blog.xiaoquankong.ai/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://blog.xiaoquankong.ai/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://blog.xiaoquankong.ai/apple-touch-icon.png">
<link rel="mask-icon" href="https://blog.xiaoquankong.ai/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://blog.xiaoquankong.ai/posts/the-decoding-process-of-chatgpt-and-the-various-parameters-in-it/">
<link rel="alternate" hreflang="zh" href="https://blog.xiaoquankong.ai/zh/posts/the-decoding-process-of-chatgpt-and-the-various-parameters-in-it/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-105150423-2', 'auto');
	
	ga('send', 'pageview');
}
</script><meta property="og:title" content="ChatGPT 的解码过程和其中的各种参数" />
<meta property="og:description" content="TL:DR OpenAI 的 ChatGPT 在其官方文档（https://platform.openai.com/docs/api-reference/chat/create）中给出了各种参数的范围和含义。我们将讨论 ChatGPT 的生成过程和这些参数是如何实现其生成的效果的。
ChatGPT 的解码过程 我们假设 minGPT （等同于 GPT-2） 和 ChatGPT 拥有一样的解码过程：https://github.com/karpathy/minGPT/blob/master/mingpt/model.py#LL283C12-L283C12 。
总体过程可以概括为以下几个步骤：
将用户的请求，从 1 个扩充成 num_samples 大小的 batch 进行模型推理，得到 logits 进行 temperature 映射：logits = logits / temperature [可选] 进行 topk 处理：logits = topk_func(logits, top_k) logits 到 概率的转换：probs = softmax(logits) 是否 sample： 进行 sample：idx_next = multinomial_sample(probs, num_samples=1) 不进行 sample：idx_next = topk_func(probs, k=1) 重复上述过程 max_new_tokens 次 ChatGPT 的解码参数 temperature temperature 参数的官方定义如下：
temperature number Optional Defaults to 1" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.xiaoquankong.ai/zh/posts/the-decoding-process-of-chatgpt-and-the-various-parameters-in-it/" /><meta property="og:image" content="https://blog.xiaoquankong.ai/papermod-cover.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-07T22:10:18+08:00" />
<meta property="article:modified_time" content="2023-08-07T22:10:18+08:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://blog.xiaoquankong.ai/papermod-cover.png"/>

<meta name="twitter:title" content="ChatGPT 的解码过程和其中的各种参数"/>
<meta name="twitter:description" content="TL:DR OpenAI 的 ChatGPT 在其官方文档（https://platform.openai.com/docs/api-reference/chat/create）中给出了各种参数的范围和含义。我们将讨论 ChatGPT 的生成过程和这些参数是如何实现其生成的效果的。
ChatGPT 的解码过程 我们假设 minGPT （等同于 GPT-2） 和 ChatGPT 拥有一样的解码过程：https://github.com/karpathy/minGPT/blob/master/mingpt/model.py#LL283C12-L283C12 。
总体过程可以概括为以下几个步骤：
将用户的请求，从 1 个扩充成 num_samples 大小的 batch 进行模型推理，得到 logits 进行 temperature 映射：logits = logits / temperature [可选] 进行 topk 处理：logits = topk_func(logits, top_k) logits 到 概率的转换：probs = softmax(logits) 是否 sample： 进行 sample：idx_next = multinomial_sample(probs, num_samples=1) 不进行 sample：idx_next = topk_func(probs, k=1) 重复上述过程 max_new_tokens 次 ChatGPT 的解码参数 temperature temperature 参数的官方定义如下：
temperature number Optional Defaults to 1"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://blog.xiaoquankong.ai/zh/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "ChatGPT 的解码过程和其中的各种参数",
      "item": "https://blog.xiaoquankong.ai/zh/posts/the-decoding-process-of-chatgpt-and-the-various-parameters-in-it/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "ChatGPT 的解码过程和其中的各种参数",
  "name": "ChatGPT 的解码过程和其中的各种参数",
  "description": "TL:DR OpenAI 的 ChatGPT 在其官方文档（https://platform.openai.com/docs/api-reference/chat/create）中给出了各种参数的范围和含义。我们将讨论 ChatGPT 的生成过程和这些参数是如何实现其生成的效果的。\nChatGPT 的解码过程 我们假设 minGPT （等同于 GPT-2） 和 ChatGPT 拥有一样的解码过程：https://github.com/karpathy/minGPT/blob/master/mingpt/model.py#LL283C12-L283C12 。\n总体过程可以概括为以下几个步骤：\n将用户的请求，从 1 个扩充成 num_samples 大小的 batch 进行模型推理，得到 logits 进行 temperature 映射：logits = logits / temperature [可选] 进行 topk 处理：logits = topk_func(logits, top_k) logits 到 概率的转换：probs = softmax(logits) 是否 sample： 进行 sample：idx_next = multinomial_sample(probs, num_samples=1) 不进行 sample：idx_next = topk_func(probs, k=1) 重复上述过程 max_new_tokens 次 ChatGPT 的解码参数 temperature temperature 参数的官方定义如下：\ntemperature number Optional Defaults to 1",
  "keywords": [
    
  ],
  "articleBody": "TL:DR OpenAI 的 ChatGPT 在其官方文档（https://platform.openai.com/docs/api-reference/chat/create）中给出了各种参数的范围和含义。我们将讨论 ChatGPT 的生成过程和这些参数是如何实现其生成的效果的。\nChatGPT 的解码过程 我们假设 minGPT （等同于 GPT-2） 和 ChatGPT 拥有一样的解码过程：https://github.com/karpathy/minGPT/blob/master/mingpt/model.py#LL283C12-L283C12 。\n总体过程可以概括为以下几个步骤：\n将用户的请求，从 1 个扩充成 num_samples 大小的 batch 进行模型推理，得到 logits 进行 temperature 映射：logits = logits / temperature [可选] 进行 topk 处理：logits = topk_func(logits, top_k) logits 到 概率的转换：probs = softmax(logits) 是否 sample： 进行 sample：idx_next = multinomial_sample(probs, num_samples=1) 不进行 sample：idx_next = topk_func(probs, k=1) 重复上述过程 max_new_tokens 次 ChatGPT 的解码参数 temperature temperature 参数的官方定义如下：\ntemperature number Optional Defaults to 1\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or top_p but not both.\n这一部分对应着解码过程的步骤 3.\n下面我们将结合模型解码过程，使用数据示例来演示其效果（为了简化逻辑过程，我们不进行 topk 处理）：\n假设某个模型的 vocabulary 的大小为 2，在某个时刻，模型的输出为 logits = [0.8, 0.2]。 如果不进行 temperature 映射（等价于将 temperature 设置为 1， 也就是默认值）： 概率转换：probs = softmax(logits) = [0.65, 0.35] 如果 temperature 设置为 1.8，那么 logits = logits / temperature = [0.44, 0.11], 下一步进行概率转换：probs = softmax(logits) = [0.58, 0.42] 如果 temperature 设置为 0.2，那么 logits = logits / temperature = [4, 1], 下一步进行概率转换：probs = softmax(logits) = [0.95, 0.05] 总结：从上面的数据可以看出，temperature 越大，logits 数值不同的 token 经过映射后其概率差异越小，从而越有可能会被后续的 sample 部分\n值得注意的是，GPT模型的 temperature 取值范围是 0（包含） 到 2（包含）。但是 temperature=0，这个在数值上是无法作为被除数的，ChatGPT 必然采用了某种 trick 或者变换以解决这个问题。\n我们画一张图用来演示，不同 temperature 在不同 logits 上的表现：\n# importing package import matplotlib.pyplot as plt import numpy as np import math # x axis index and values data = list(enumerate(zip(np.arange(0.1, 0.6, 0.1), np.arange(0.9, 0.4, -0.1)))) # colors for each temperature, from low to high temperature, from yellow to dark red # reference: https://colorbrewer2.org/#type=sequential\u0026scheme=YlOrRd\u0026n=5 colors = [\"#ffffb2\", \"#fecc5c\", \"#fd8d3c\", \"#f03b20\", \"#bd0026\"] for t_idx, temperature in enumerate(np.arange(0.4, 1.6 + 0.0001, 0.3)): # each line for each temperature # get x and y values x = [] y = [] for x_idx, (a, b) in data: logits = np.array([a, b]) probs = softmax(logits / temperature) x.append(x_idx) y.append(probs[1] / probs[0]) # max prob / min prob # plot circle_color = colors[t_idx] if math.isclose(temperature, 1.0): # plot the line for temperature 1.0 with black circles plt.scatter(x, y, label=f\"{temperature:.1f}\", facecolors=\"black\", edgecolors=\"black\") else: # other lines with colorful lines plt.scatter(x, y, label=f\"{temperature:.1f}\", facecolors=circle_color, edgecolors=\"gray\") plt.legend() # set x and y axis plt.xlabel('logits') plt.xticks([x for x, _ in data], [f\"[{a:.1f}, {b:.1f}]\" for _, (a, b) in data]) plt.ylabel('ratio of max/min prob') plt.show() 将会输出如下的图：\n在上图中，横坐标为 logits（由两个类别构成），纵坐标为 max prob / min prob，也就是概率最大的 token 的概率与概率最小的 token 的概率的比值，这个比值可以用于衡量差异的大小。\n在没有引入 temperature 时，概率的比值和 logits 存在严格相关的，logits 的值通过 Logistic 函数可以映射得到概率值。在上图中，temperature = 0 的情况，等价于没有引入 temperature 的情况，在图中使用空心圆圈 ◯ 表示。。\n通过观察，可知无论我们选择哪一个 logits，我们都可以看到：temperature 越大，概率之间的差异（也就是 max prob / min prob 比值）越小，也就是概率差异越小。反之亦然。因此，可以得出结论：temperature 越大，模型生成的结果越随机，temperature 越小，模型生成的结果越确定。\ntop_p top_p 参数的官方定义如下：\ntop_p number Optional Defaults to 1\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\nWe generally recommend altering this or temperature but not both.\n这一部分对应着解码过程的步骤 4.\n与 minGPT 不同的是，minGPT 使用绝对值（top_n）来进行选择，而 OpenAI GPT 使用百分比（top_p）。\n这一部分会将不合格（比在 top_n 以内的，或者 top_p 比例以外的）的 token 清理掉，通过将其 logits 值设置为 float(‘Inf’) 来实现。\nstop stop 参数的官方定义如下：\nstop string or array Optional Defaults to null\nUp to 4 sequences where the API will stop generating further tokens.\n这一部分在 MinGPT 中没有对应的步骤。 这一部分所要表达的含义也是清晰明了，在监测到输出中存在某些定义的字符串后，将会停止生成。这一特性可能在有些软件中得到了应用。比如 https://github.com/microsoft/guidance 中的 {{gen 'rewrite' stop=\"\\\\n-\"}}\nn n 参数的官方定义如下：\nn integer Optional Defaults to 1\nHow many chat completion choices to generate for each input message.\n这一部分对应着解码过程的步骤1。\n由于大小为 n 的 batch 中每一个文本都是独立采样的，因此在同一位置可能会选择不同的 token，这些文本上的变异随着位置的不断延伸而进一步扩大，最终生成了不同的文本。当然了，也有一定概率生成完全一样的文本。\nmax_tokens max_tokens 参数的官方定义如下：\nmax_tokens integer Optional Defaults to inf\nThe maximum number of tokens to generate in the chat completion.\nThe total length of input tokens and generated tokens is limited by the model’s context length.\n这一部分对应着解码过程中的步骤7.\n这一部分决定了解码的最高运行次数。在 minGPT 中，这一解码次数是确定的，模型一定会生成 max_tokens 个 token。而在 OpenAI GPT 中则不一定了，有几个因素：\nstop 参数的设置，详情请见上文。 可能的特殊的休止符 token。通过实际使用 ChatGPT，可以发现 ChatGPT 并不会机械的输出指定的文本长度，在充分回答问题后，就会自行停止。 实验代码如下： import openai openai.api_key = \"sk-xxx\" completion = openai.ChatCompletion.create( model=\"gpt-4\", messages=[{\"role\": \"user\", \"content\": \"你帮我输出1到10之间的偶数，输出时，每个数字之间用一个空格隔开。除了数字，其他的都不要输出。\"}], temperature=0, max_tokens=100, ) response = completion.choices[0].message[\"content\"] print(\"length: \", len(response)) # 将会输出：length: 10 print(response) # 将会输出：2 4 6 8 10 presence_penalty presence_penalty 参数的官方定义如下：\nfrequency_penalty number Optional Defaults to 0\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model’s likelihood to repeat the same line verbatim.\n这一部分在 MinGPT 中没有对应的步骤。\n这一部分的详尽解释在 https://platform.openai.com/docs/api-reference/parameter-details 中有提及。\n具体来说，就是在解码的某个时刻，token j 的 logit 值为 mu[j] ，c[j] 表示在当前已经生成的文本中，出现过多少个 j 这个 token。c[j] \u003e 0 这个表达式的值只能为1（之前 j 出现过至少一次）或者0（没有出现过）。在 OpenAI 的解释中，它使用了 alpha_presence 来指代 presence_penalty，两者完全是同一事物的不同符号而已。为了保持和文档一致，这里都使用文档中的符号。在加入 presence_penalty 机制后，其值修订为 mu[j] - float(c[j] \u003e 0) * alpha_presence 。这就意味着在 alpha_presence 为正的情况下，j 这个 token 的 logit 会因为之前文本中生成过 j 而有所降低。logit 的降低也意味着被 sample 的概率降低。因此通过提供正值 presence_penalty，就会使模型生成重复 token 的概率降低，换言之，进行了惩罚。如果 alpha_presence 为负值，那么同理可得，会对模型生成重复 token 的行为进行奖励。\npresence_penalty 名字中虽然带着 penalty，但由于其取值范围可能是正数也可能是负数，因此并不一定是惩罚 token 的反复出现，也有可能是鼓励反复出现。\nfrequency_penalty frequency_penalty 参数的官方定义如下：\nfrequency_penalty number Optional Defaults to 0\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model’s likelihood to repeat the same line verbatim.\n这一部分在 MinGPT 中没有对应的步骤。\n这个参数和 presence_penalty 高度相似。同样在 https://platform.openai.com/docs/api-reference/parameter-details 中有详细的解释。\n具体来说，token j 的 logit 值为 mu[j] ，在加入 frequency_penalty 会修订成 mu[j] -\u003e mu[j] - c[j] * alpha_frequency 。其中 c[j] 是当前已经生成的文本中，出现过多少个 j 这个 token。而 alpha_frequency 就是 frequency_penalty 。这就意味着在 frequency_penalty 为正的情况下，j 这个 token 的 logit 会因为之前文本中生成过 j 而有所降低，而且之前生成过的 j 越多（也就是c[j] 数值越大），惩罚越严重。这里可以看出 frequency_penalty 和 presence_penalty 的不同点在于 frequency_penalty 的惩罚会随着 token 出现的次数增加而不断加强，而 presence_penalty 则只会区分是否出现，这样的区别充分体现在了其名字差异上：frequency 和 presence。\n和 presence 类似，frequency_penalty 的取值可正可负，从而实现惩罚或者奖励反复出现的 token。\nlogit_bias logit_bias 参数的官方定义如下：\nlogit_bias map Optional Defaults to null\nModify the likelihood of specified tokens appearing in the completion.\nAccepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.\n这一部分在 MinGPT 中没有对应的步骤。\n这一参数用于无条件的修改某个或者多个 token 的 logit，从而增加或者减少其出现的可能性。具体来说，对于变量 token j ，其 logit 值为 mu[j] ，那么在使用 logit_bias 后，其值将会被修改成：mu[j] -\u003e mu[j] + logit_bias[j] .\n",
  "wordCount" : "938",
  "inLanguage": "zh",
  "datePublished": "2023-08-07T22:10:18+08:00",
  "dateModified": "2023-08-07T22:10:18+08:00",
  "author":{
    "@type": "Person",
    "name": "Xiaoquan Kong"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://blog.xiaoquankong.ai/zh/posts/the-decoding-process-of-chatgpt-and-the-various-parameters-in-it/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Xiaoquan Kong's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://blog.xiaoquankong.ai/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://blog.xiaoquankong.ai/zh/" accesskey="h" title="Xiaoquan Kong&#39;s Blog (Alt + H)">Xiaoquan Kong&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="https://blog.xiaoquankong.ai/" title="English"
                            aria-label="English">English</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://blog.xiaoquankong.ai/zh/archives/" title="时间线">
                    <span>时间线</span>
                </a>
            </li>
            <li>
                <a href="https://blog.xiaoquankong.ai/zh/categories" title="分类">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="https://blog.xiaoquankong.ai/zh/tags/" title="标签">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="https://www.xiaoquankong.ai" title="关于我">
                    <span>关于我</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://blog.xiaoquankong.ai/zh/">主页</a>&nbsp;»&nbsp;<a href="https://blog.xiaoquankong.ai/zh/posts/">Posts</a></div>
    <h1 class="post-title">
      ChatGPT 的解码过程和其中的各种参数
    </h1>
    <div class="post-meta"><span title='2023-08-07 22:10:18 +0800 CST'>八月 7, 2023</span>&nbsp;·&nbsp;5 分钟&nbsp;·&nbsp;Xiaoquan Kong&nbsp;|&nbsp;语言:
<ul class="i18n_list">
    <li>
        <a href="https://blog.xiaoquankong.ai/posts/the-decoding-process-of-chatgpt-and-the-various-parameters-in-it/">English</a>
    </li>
</ul>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#chatgpt-%e7%9a%84%e8%a7%a3%e7%a0%81%e8%bf%87%e7%a8%8b" aria-label="ChatGPT 的解码过程">ChatGPT 的解码过程</a></li>
                <li>
                    <a href="#chatgpt-%e7%9a%84%e8%a7%a3%e7%a0%81%e5%8f%82%e6%95%b0" aria-label="ChatGPT 的解码参数">ChatGPT 的解码参数</a><ul>
                        
                <li>
                    <a href="#temperature" aria-label="temperature">temperature</a></li>
                <li>
                    <a href="#top_p" aria-label="top_p">top_p</a></li>
                <li>
                    <a href="#stop" aria-label="stop">stop</a></li>
                <li>
                    <a href="#n" aria-label="n">n</a></li>
                <li>
                    <a href="#max_tokens" aria-label="max_tokens">max_tokens</a></li>
                <li>
                    <a href="#presence_penalty" aria-label="presence_penalty">presence_penalty</a></li>
                <li>
                    <a href="#frequency_penalty" aria-label="frequency_penalty">frequency_penalty</a></li>
                <li>
                    <a href="#logit_bias" aria-label="logit_bias">logit_bias</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p><strong>TL:DR</strong> OpenAI 的 ChatGPT 在其官方文档（<a href="https://platform.openai.com/docs/api-reference/chat/create">https://platform.openai.com/docs/api-reference/chat/create</a>）中给出了各种参数的范围和含义。我们将讨论 ChatGPT 的生成过程和这些参数是如何实现其生成的效果的。</p>
<h2 id="chatgpt-的解码过程">ChatGPT 的解码过程<a hidden class="anchor" aria-hidden="true" href="#chatgpt-的解码过程">#</a></h2>
<p>我们假设 minGPT （等同于 GPT-2） 和 ChatGPT 拥有一样的解码过程：<a href="https://github.com/karpathy/minGPT/blob/master/mingpt/model.py#LL283C12-L283C12">https://github.com/karpathy/minGPT/blob/master/mingpt/model.py#LL283C12-L283C12</a> 。</p>
<p>总体过程可以概括为以下几个步骤：</p>
<ol>
<li>将用户的请求，从 1 个扩充成 num_samples 大小的 batch</li>
<li>进行模型推理，得到 logits</li>
<li>进行 temperature 映射：logits = logits / temperature</li>
<li>[可选] 进行 topk 处理：logits = topk_func(logits, top_k)</li>
<li>logits 到 概率的转换：probs = softmax(logits)</li>
<li>是否 sample：
<ol>
<li>进行 sample：idx_next = multinomial_sample(probs, num_samples=1)</li>
<li>不进行 sample：idx_next = topk_func(probs, k=1)</li>
</ol>
</li>
<li>重复上述过程 max_new_tokens 次</li>
</ol>
<h2 id="chatgpt-的解码参数">ChatGPT 的解码参数<a hidden class="anchor" aria-hidden="true" href="#chatgpt-的解码参数">#</a></h2>
<h3 id="temperature">temperature<a hidden class="anchor" aria-hidden="true" href="#temperature">#</a></h3>
<p>temperature 参数的官方定义如下：</p>
<blockquote>
<p>temperature number Optional Defaults to 1</p>
<p>What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.</p>
<p>We generally recommend altering this or <strong><code>top_p</code></strong> but not both.</p>
</blockquote>
<p>这一部分对应着解码过程的步骤 3.</p>
<p>下面我们将结合模型解码过程，使用数据示例来演示其效果（为了简化逻辑过程，我们不进行 topk 处理）：</p>
<ol>
<li>假设某个模型的 vocabulary 的大小为 2，在某个时刻，模型的输出为 logits = [0.8, 0.2]。</li>
<li>如果不进行 temperature 映射（等价于将 temperature 设置为 1， 也就是默认值）： 概率转换：probs = softmax(logits) = [0.65, 0.35]</li>
<li>如果 temperature 设置为 1.8，那么 logits = logits / temperature = [0.44, 0.11], 下一步进行概率转换：probs = softmax(logits) = [0.58, 0.42]</li>
<li>如果 temperature 设置为 0.2，那么 logits = logits / temperature = [4, 1], 下一步进行概率转换：probs = softmax(logits) = [0.95, 0.05]</li>
</ol>
<p>总结：从上面的数据可以看出，temperature 越大，logits 数值不同的 token 经过映射后其概率差异越小，从而越有可能会被后续的 sample 部分</p>
<p>值得注意的是，GPT模型的 temperature 取值范围是 0（包含） 到 2（包含）。但是 temperature=0，这个在数值上是无法作为被除数的，ChatGPT 必然采用了某种 trick 或者变换以解决这个问题。</p>
<p>我们画一张图用来演示，不同 temperature 在不同 logits 上的表现：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># importing package</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">math</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># x axis index and values</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">))))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># colors for each temperature, from low to high temperature, from yellow to dark red</span>
</span></span><span class="line"><span class="cl"><span class="c1"># reference: https://colorbrewer2.org/#type=sequential&amp;scheme=YlOrRd&amp;n=5</span>
</span></span><span class="line"><span class="cl"><span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;#ffffb2&#34;</span><span class="p">,</span> <span class="s2">&#34;#fecc5c&#34;</span><span class="p">,</span> <span class="s2">&#34;#fd8d3c&#34;</span><span class="p">,</span> <span class="s2">&#34;#f03b20&#34;</span><span class="p">,</span> <span class="s2">&#34;#bd0026&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">t_idx</span><span class="p">,</span> <span class="n">temperature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">1.6</span> <span class="o">+</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># each line for each temperature</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># get x and y values</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="n">y</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">x_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">probs</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">logits</span> <span class="o">/</span> <span class="n">temperature</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_idx</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># max prob / min prob</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># plot</span>
</span></span><span class="line"><span class="cl">    <span class="n">circle_color</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="n">t_idx</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">temperature</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># plot the line for temperature 1.0 with black circles</span>
</span></span><span class="line"><span class="cl">        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">temperature</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="s2">&#34;black&#34;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&#34;black&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># other lines with colorful lines</span>
</span></span><span class="line"><span class="cl">        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">temperature</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="n">circle_color</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&#34;gray&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># set x and y axis</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">data</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">           <span class="p">[</span><span class="sa">f</span><span class="s2">&#34;[</span><span class="si">{</span><span class="n">a</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">b</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">]&#34;</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="ow">in</span> <span class="n">data</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;ratio of max/min prob&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p>将会输出如下的图：</p>
<p><img loading="lazy" src="output.png" alt="output.png"  />
</p>
<p>在上图中，横坐标为 logits（由两个类别构成），纵坐标为 max prob / min prob，也就是概率最大的 token 的概率与概率最小的 token 的概率的比值，这个比值可以用于衡量差异的大小。</p>
<p>在没有引入 temperature 时，概率的比值和 logits 存在严格相关的，logits 的值通过 Logistic 函数可以映射得到概率值。在上图中，temperature = 0 的情况，等价于没有引入 temperature 的情况，在图中使用空心圆圈 ◯ 表示。。</p>
<p>通过观察，可知无论我们选择哪一个 logits，我们都可以看到：temperature 越大，概率之间的差异（也就是 max prob / min prob 比值）越小，也就是概率差异越小。反之亦然。因此，可以得出结论：temperature 越大，模型生成的结果越随机，temperature 越小，模型生成的结果越确定。</p>
<h3 id="top_p">top_p<a hidden class="anchor" aria-hidden="true" href="#top_p">#</a></h3>
<p>top_p 参数的官方定义如下：</p>
<blockquote>
<p>top_p number Optional Defaults to 1</p>
<p>An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.</p>
<p>We generally recommend altering this or <strong><code>temperature</code></strong> but not both.</p>
</blockquote>
<p>这一部分对应着解码过程的步骤 4.</p>
<p>与 minGPT 不同的是，minGPT 使用绝对值（top_n）来进行选择，而 OpenAI GPT 使用百分比（top_p）。</p>
<p>这一部分会将不合格（比在 top_n 以内的，或者 top_p 比例以外的）的 token 清理掉，通过将其 logits 值设置为 float(&lsquo;Inf&rsquo;) 来实现。</p>
<h3 id="stop">stop<a hidden class="anchor" aria-hidden="true" href="#stop">#</a></h3>
<p>stop 参数的官方定义如下：</p>
<blockquote>
<p>stop string or array Optional Defaults to null</p>
<p>Up to 4 sequences where the API will stop generating further tokens.</p>
</blockquote>
<p>这一部分在 MinGPT 中没有对应的步骤。
这一部分所要表达的含义也是清晰明了，在监测到输出中存在某些定义的字符串后，将会停止生成。这一特性可能在有些软件中得到了应用。比如 <a href="https://github.com/microsoft/guidance">https://github.com/microsoft/guidance</a> 中的 <code>{{gen 'rewrite' stop=&quot;\\n-&quot;}}</code></p>
<h3 id="n">n<a hidden class="anchor" aria-hidden="true" href="#n">#</a></h3>
<p>n 参数的官方定义如下：</p>
<blockquote>
<p>n integer Optional Defaults to 1</p>
<p>How many chat completion choices to generate for each input message.</p>
</blockquote>
<p>这一部分对应着解码过程的步骤1。</p>
<p>由于大小为 n 的 batch 中每一个文本都是独立采样的，因此在同一位置可能会选择不同的 token，这些文本上的变异随着位置的不断延伸而进一步扩大，最终生成了不同的文本。当然了，也有一定概率生成完全一样的文本。</p>
<h3 id="max_tokens">max_tokens<a hidden class="anchor" aria-hidden="true" href="#max_tokens">#</a></h3>
<p>max_tokens 参数的官方定义如下：</p>
<blockquote>
<p>max_tokens integer Optional Defaults to inf</p>
<p>The maximum number of <strong><a href="https://platform.openai.com/tokenizer">tokens</a></strong> to generate in the chat completion.</p>
<p>The total length of input tokens and generated tokens is limited by the model&rsquo;s context length.</p>
</blockquote>
<p>这一部分对应着解码过程中的步骤7.</p>
<p>这一部分决定了解码的最高运行次数。在 minGPT 中，这一解码次数是确定的，模型一定会生成 max_tokens 个 token。而在 OpenAI GPT 中则不一定了，有几个因素：</p>
<ul>
<li>stop 参数的设置，详情请见上文。</li>
<li>可能的特殊的休止符 token。通过实际使用 ChatGPT，可以发现 ChatGPT 并不会机械的输出指定的文本长度，在充分回答问题后，就会自行停止。</li>
<li>实验代码如下：</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">openai</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">openai</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="s2">&#34;sk-xxx&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">completion</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">=</span><span class="s2">&#34;gpt-4&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="s2">&#34;你帮我输出1到10之间的偶数，输出时，每个数字之间用一个空格隔开。除了数字，其他的都不要输出。&#34;</span><span class="p">}],</span>
</span></span><span class="line"><span class="cl">    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">response</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="s2">&#34;content&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;length: &#34;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="p">))</span>  <span class="c1"># 将会输出：length:  10</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>  <span class="c1"># 将会输出：2 4 6 8 10</span>
</span></span></code></pre></div><h3 id="presence_penalty">presence_penalty<a hidden class="anchor" aria-hidden="true" href="#presence_penalty">#</a></h3>
<p>presence_penalty 参数的官方定义如下：</p>
<blockquote>
<p>frequency_penalty number Optional Defaults to 0</p>
<p>Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model&rsquo;s likelihood to repeat the same line verbatim.</p>
</blockquote>
<p>这一部分在 MinGPT 中没有对应的步骤。</p>
<p>这一部分的详尽解释在 <a href="https://platform.openai.com/docs/api-reference/parameter-details">https://platform.openai.com/docs/api-reference/parameter-details</a> 中有提及。</p>
<p>具体来说，就是在解码的某个时刻，token <code>j</code> 的 logit 值为 <code>mu[j]</code> ，c[j] 表示在当前已经生成的文本中，出现过多少个 j 这个 token。<code>c[j] &gt; 0</code> 这个表达式的值只能为1（之前 j 出现过至少一次）或者0（没有出现过）。在 OpenAI 的解释中，它使用了 <code>alpha_presence</code> 来指代 presence_penalty，两者完全是同一事物的不同符号而已。为了保持和文档一致，这里都使用文档中的符号。在加入 presence_penalty 机制后，其值修订为 <code>mu[j] - float(c[j] &gt; 0) * alpha_presence</code> 。这就意味着在 <code>alpha_presence</code> 为正的情况下，j 这个 token 的 logit 会因为之前文本中生成过 j 而有所降低。logit 的降低也意味着被 sample 的概率降低。因此通过提供正值 presence_penalty，就会使模型生成重复 token 的概率降低，换言之，进行了惩罚。如果 <code>alpha_presence</code> 为负值，那么同理可得，会对模型生成重复 token 的行为进行奖励。</p>
<p>presence_penalty 名字中虽然带着 penalty，但由于其取值范围可能是正数也可能是负数，因此并不一定是惩罚 token 的反复出现，也有可能是鼓励反复出现。</p>
<h3 id="frequency_penalty">frequency_penalty<a hidden class="anchor" aria-hidden="true" href="#frequency_penalty">#</a></h3>
<p>frequency_penalty 参数的官方定义如下：</p>
<blockquote>
<p>frequency_penalty number Optional Defaults to 0</p>
<p>Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model&rsquo;s likelihood to repeat the same line verbatim.</p>
</blockquote>
<p>这一部分在 MinGPT 中没有对应的步骤。</p>
<p>这个参数和 presence_penalty 高度相似。同样在 <a href="https://platform.openai.com/docs/api-reference/parameter-details">https://platform.openai.com/docs/api-reference/parameter-details</a> 中有详细的解释。</p>
<p>具体来说，token <code>j</code> 的 logit 值为 <code>mu[j]</code> ，在加入 frequency_penalty 会修订成 <code>mu[j] -&gt; mu[j] - c[j] * alpha_frequency</code> 。其中 <code>c[j]</code> 是当前已经生成的文本中，出现过多少个 j 这个 token。而 <code>alpha_frequency</code> 就是 frequency_penalty 。这就意味着在 frequency_penalty 为正的情况下，j 这个 token 的 logit 会因为之前文本中生成过 j 而有所降低，而且之前生成过的 j 越多（也就是<code>c[j]</code> 数值越大），惩罚越严重。这里可以看出 frequency_penalty 和 presence_penalty 的不同点在于 frequency_penalty 的惩罚会随着 token 出现的次数增加而不断加强，而 presence_penalty 则只会区分是否出现，这样的区别充分体现在了其名字差异上：frequency 和 presence。</p>
<p>和 presence 类似，frequency_penalty 的取值可正可负，从而实现惩罚或者奖励反复出现的 token。</p>
<h3 id="logit_bias">logit_bias<a hidden class="anchor" aria-hidden="true" href="#logit_bias">#</a></h3>
<p>logit_bias 参数的官方定义如下：</p>
<blockquote>
<p>logit_bias map Optional Defaults to null</p>
<p>Modify the likelihood of specified tokens appearing in the completion.</p>
<p>Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.</p>
</blockquote>
<p>这一部分在 MinGPT 中没有对应的步骤。</p>
<p>这一参数用于无条件的修改某个或者多个 token 的 logit，从而增加或者减少其出现的可能性。具体来说，对于变量 token <code>j</code> ，其 logit 值为 <code>mu[j]</code> ，那么在使用 logit_bias 后，其值将会被修改成：<code>mu[j] -&gt; mu[j] + logit_bias[j]</code> .</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="next" href="https://blog.xiaoquankong.ai/zh/posts/creating-a-weather-query-bot-using-rasa/">
    <span class="title">下一页 »</span>
    <br>
    <span>使用 Rasa 构建天气查询机器人</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT 的解码过程和其中的各种参数 on twitter"
        href="https://twitter.com/intent/tweet/?text=ChatGPT%20%e7%9a%84%e8%a7%a3%e7%a0%81%e8%bf%87%e7%a8%8b%e5%92%8c%e5%85%b6%e4%b8%ad%e7%9a%84%e5%90%84%e7%a7%8d%e5%8f%82%e6%95%b0&amp;url=https%3a%2f%2fblog.xiaoquankong.ai%2fzh%2fposts%2fthe-decoding-process-of-chatgpt-and-the-various-parameters-in-it%2f&amp;hashtags=">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT 的解码过程和其中的各种参数 on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fblog.xiaoquankong.ai%2fzh%2fposts%2fthe-decoding-process-of-chatgpt-and-the-various-parameters-in-it%2f&amp;title=ChatGPT%20%e7%9a%84%e8%a7%a3%e7%a0%81%e8%bf%87%e7%a8%8b%e5%92%8c%e5%85%b6%e4%b8%ad%e7%9a%84%e5%90%84%e7%a7%8d%e5%8f%82%e6%95%b0&amp;summary=ChatGPT%20%e7%9a%84%e8%a7%a3%e7%a0%81%e8%bf%87%e7%a8%8b%e5%92%8c%e5%85%b6%e4%b8%ad%e7%9a%84%e5%90%84%e7%a7%8d%e5%8f%82%e6%95%b0&amp;source=https%3a%2f%2fblog.xiaoquankong.ai%2fzh%2fposts%2fthe-decoding-process-of-chatgpt-and-the-various-parameters-in-it%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT 的解码过程和其中的各种参数 on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fblog.xiaoquankong.ai%2fzh%2fposts%2fthe-decoding-process-of-chatgpt-and-the-various-parameters-in-it%2f&title=ChatGPT%20%e7%9a%84%e8%a7%a3%e7%a0%81%e8%bf%87%e7%a8%8b%e5%92%8c%e5%85%b6%e4%b8%ad%e7%9a%84%e5%90%84%e7%a7%8d%e5%8f%82%e6%95%b0">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT 的解码过程和其中的各种参数 on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.xiaoquankong.ai%2fzh%2fposts%2fthe-decoding-process-of-chatgpt-and-the-various-parameters-in-it%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT 的解码过程和其中的各种参数 on whatsapp"
        href="https://api.whatsapp.com/send?text=ChatGPT%20%e7%9a%84%e8%a7%a3%e7%a0%81%e8%bf%87%e7%a8%8b%e5%92%8c%e5%85%b6%e4%b8%ad%e7%9a%84%e5%90%84%e7%a7%8d%e5%8f%82%e6%95%b0%20-%20https%3a%2f%2fblog.xiaoquankong.ai%2fzh%2fposts%2fthe-decoding-process-of-chatgpt-and-the-various-parameters-in-it%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT 的解码过程和其中的各种参数 on telegram"
        href="https://telegram.me/share/url?text=ChatGPT%20%e7%9a%84%e8%a7%a3%e7%a0%81%e8%bf%87%e7%a8%8b%e5%92%8c%e5%85%b6%e4%b8%ad%e7%9a%84%e5%90%84%e7%a7%8d%e5%8f%82%e6%95%b0&amp;url=https%3a%2f%2fblog.xiaoquankong.ai%2fzh%2fposts%2fthe-decoding-process-of-chatgpt-and-the-various-parameters-in-it%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://blog.xiaoquankong.ai/zh/">Xiaoquan Kong&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = '复制';

        function copyingDone() {
            copybutton.innerHTML = '已复制！';
            setTimeout(() => {
                copybutton.innerHTML = '复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
